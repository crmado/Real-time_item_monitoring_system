#!/usr/bin/env python3
"""
èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³• - åŸºæ–¼å‰å¾Œæ™¯åˆ†æçš„ç‰©ä»¶æª¢æ¸¬å’Œè¨ˆæ•¸
åƒè€ƒ partsCounts_v1.py çš„å¯¦ç¾æ–¹å¼
"""

import cv2
import numpy as np
import logging
from typing import List, Tuple, Optional, Dict, Any
from .detection_base import DetectionMethod


class BackgroundSubtractionDetection(DetectionMethod):
    """
    èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³• - åŸºæ–¼å‰å¾Œæ™¯åˆ†æ
    åƒè€ƒ partsCounts_v1.py çš„é«˜æ•ˆå¯¦ç¾
    """
    
    def __init__(self):
        """åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤æª¢æ¸¬"""
        # ğŸš€ é«˜é€Ÿæª¢æ¸¬æ¨¡å¼æ§åˆ¶
        self.ultra_high_speed_mode = False  # è¶…é«˜é€Ÿæ¨¡å¼ (206-376fps)
        self.target_fps = 280  # ç›®æ¨™FPSï¼Œæ ¹æ“šç›¸æ©Ÿè¦æ ¼å‹•æ…‹èª¿æ•´
        
        # ğŸ¯ æ¥µå°é›¶ä»¶æª¢æ¸¬ - å°ˆé–€ç‚ºå°é›¶ä»¶å„ªåŒ–åƒæ•¸
        self.min_area = 2    # ğŸ”§ é€²ä¸€æ­¥é™ä½ä»¥æ•ç²æ¥µå°é›¶ä»¶ (3â†’2)  
        self.max_area = 3000 # ğŸ”§ é©ä¸­çš„ä¸Šé™ (4000â†’3000)
        
        # ç‰©ä»¶å½¢ç‹€éæ¿¾åƒæ•¸ - å°ˆç‚ºå°é›¶ä»¶æ”¾å¯¬æ¢ä»¶
        self.min_aspect_ratio = 0.001 # æ¥µåº¦å¯¬é¬†çš„é•·å¯¬æ¯”é©æ‡‰å°é›¶ä»¶ (0.01â†’0.001)
        self.max_aspect_ratio = 100.0 # æ¥µåº¦æ”¾å¯¬æ¥µç«¯å½¢ç‹€é™åˆ¶ (50.0â†’100.0)
        self.min_extent = 0.001       # æ¥µåº¦é™ä½å¡«å……æ¯”ä¾‹è¦æ±‚ (0.01â†’0.001)
        self.max_solidity = 5.0       # æ¥µåº¦æ”¾å¯¬çµå¯¦æ€§é™åˆ¶ (2.0â†’5.0)
        
        # ğŸ¯ è¶…ç©©å®šèƒŒæ™¯æ¸›é™¤ - å°ˆç‚ºå°é›¶ä»¶é•·æœŸæª¢æ¸¬å„ªåŒ–
        self.bg_history = 1000   # å¤§å¹…å¢åŠ æ­·å²å¹€æ•¸é¿å…å¿«é€ŸèƒŒæ™¯æ›´æ–° (700â†’1000)
        self.bg_var_threshold = 3   # ğŸ”§ æ¥µä½é–¾å€¼ç¢ºä¿æœ€é«˜æ•æ„Ÿåº¦ (5â†’3)
        self.detect_shadows = False  # é—œé–‰é™°å½±æª¢æ¸¬
        self.bg_learning_rate = 0.001  # ğŸ†• æ¥µä½å­¸ç¿’ç‡é¿å…å°é›¶ä»¶è¢«ç´å…¥èƒŒæ™¯
        
        # ğŸš€ é«˜é€Ÿæ¨¡å¼ä¸‹çš„ç°¡åŒ–åƒæ•¸ - ä¹Ÿé‡å°å°é›¶ä»¶å„ªåŒ–
        self.high_speed_bg_history = 100      # é«˜é€Ÿæ¨¡å¼ä¸‹æ¸›å°‘æ­·å²å¹€æ•¸
        self.high_speed_bg_var_threshold = 8  # é«˜é€Ÿæ¨¡å¼ä¸‹ä¹Ÿé™ä½é–¾å€¼ (16â†’8)
        self.high_speed_min_area = 1          # é«˜é€Ÿæ¨¡å¼ä¸‹æœ€æ¥µé™é™ä½æœ€å°é¢ç© (2â†’1)
        self.high_speed_max_area = 2000       # é«˜é€Ÿæ¨¡å¼ä¸‹é™ä½æœ€å¤§é¢ç©
        self.high_speed_binary_threshold = 3  # é«˜é€Ÿæ¨¡å¼ä¸‹çš„äºŒå€¼åŒ–é–¾å€¼
        
        # ğŸ¯ æ¥µé«˜æ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬ - å°ˆç‚ºå°é›¶ä»¶æª¢æ¸¬å„ªåŒ–
        self.gaussian_blur_kernel = (1, 1)  # æœ€å°æ¨¡ç³Šä¿ç•™æœ€å¤šç´°ç¯€ (3â†’1)
        self.canny_low_threshold = 3         # ğŸ”§ æ¥µä½é—¾å€¼æé«˜æ•æ„Ÿåº¦ (8â†’3)
        self.canny_high_threshold = 10       # ğŸ”§ æ¥µä½é—¾å€¼æé«˜æ•æ„Ÿåº¦ (25â†’10) 
        self.binary_threshold = 1            # ğŸ”§ æ¥µä½é—¾å€¼æé«˜æ•æ„Ÿåº¦ (8â†’1)
        
        # ğŸ” åˆ†é›¢å„ªåŒ–çš„å½¢æ…‹å­¸è™•ç† - é¿å…ç²˜é€£åŒæ™‚ä¿ç•™å°é›¶ä»¶
        self.dilate_kernel_size = (1, 1)    # ğŸ”§ æœ€å°æ ¸é¿å…éåº¦è†¨è„¹
        self.dilate_iterations = 0           # ğŸ”§ ç¦ç”¨è†¨è„¹ä»¥ä¿ç•™å°é›¶ä»¶
        self.close_kernel_size = (1, 1)     # ğŸ”§ ç¦ç”¨é–‰åˆé¿å…é›¶ä»¶ç²˜é€£
        self.enable_watershed_separation = True  # ğŸ†• å•Ÿç”¨åˆ†æ°´å¶ºåˆ†é›¢ç®—æ³•
        
        # ğŸ¯ æœ€å°åŒ–é›œè¨Šéæ¿¾ - æœ€å¤§åŒ–ä¿ç•™å°é›¶ä»¶
        self.opening_kernel_size = (1, 1)   # ğŸ†• æœ€å°é–‹é‹ç®—æ ¸ (2â†’1)
        self.opening_iterations = 0          # ğŸ†• ç¦ç”¨é–‹é‹ç®—ä»¥ä¿ç•™å°é›¶ä»¶ (1â†’0)
        
        # é€£é€šçµ„ä»¶åƒæ•¸
        self.connectivity = 4  # 4-é€£é€šæˆ–8-é€£é€š
        
        # ğŸ¯ ROI æª¢æ¸¬å€åŸŸåƒæ•¸ (æ ¹æ“šå½±åƒåˆ†æçµæœå„ªåŒ–)
        self.roi_enabled = True
        self.roi_height = 120  # ğŸ”§ æ“´å¤§ROIå€åŸŸé«˜åº¦ (80â†’120ä»¥å¢åŠ æª¢æ¸¬é¢ç©)
        self.roi_position_ratio = 0.12  # ğŸ”§ èª¿æ•´ä½ç½®æ¯”ä¾‹ (0.15â†’0.12ï¼Œç¨å¾®ä¸Šç§»ä»¥é…åˆæ“´å¤§é«˜åº¦)
        self.current_roi_y = 0  # ç•¶å‰ROIçš„Yåº§æ¨™
        
        # ğŸ¯ ç‰©ä»¶è¿½è¹¤å’Œè¨ˆæ•¸åƒæ•¸ - ç‚ºå°é›¶ä»¶å„ªåŒ–
        self.enable_crossing_count = True
        self.crossing_tolerance_x = 40  # ğŸ”§ é©åº¦æ”¶ç·Šxæ–¹å‘å®¹å·® (50â†’40ï¼Œæ”¹å–„å¤šç‰©ä»¶åˆ†é›¢)
        self.crossing_tolerance_y = 80  # ğŸ”§ é©åº¦æ”¶ç·Šyæ–¹å‘å®¹å·® (120â†’80ï¼Œé¿å…å¤šç‰©ä»¶æ²–çª)
        
        # ğŸ¯ æå‡è¿½è¹¤ç©©å®šæ€§ - æ¸›å°‘èª¤æª¢åŒæ™‚ä¿æŒå°é›¶ä»¶æª¢æ¸¬èƒ½åŠ›
        self.track_lifetime = 20  # ğŸ”§ å»¶é•·è¿½è¹¤é€±æœŸé¿å…ä¸­æ–· (8â†’20)
        self.min_track_frames = 4 # ğŸ”§ æé«˜ç©©å®šæ€§è¦æ±‚ï¼Œæ¸›å°‘èª¤åˆ¤ (2â†’4)
        self.crossing_threshold = 0.15   # ğŸ”§ æé«˜ç©¿è¶Šé–¾å€¼ï¼Œæ¸›å°‘èª¤æª¢ (0.05â†’0.15)
        self.confidence_threshold = 0.12  # ğŸ”§ é©åº¦æé«˜ç½®ä¿¡åº¦è¦æ±‚ (0.05â†’0.12)
        
        # ğŸ›¡ï¸ å¢å¼·é˜²é‡è¤‡æ©Ÿåˆ¶ - é¿å…è¿½è¹¤ä¸­æ–·é€ æˆçš„é‡è¤‡è¨ˆç®—
        self.counted_objects_history = []  # å·²è¨ˆæ•¸ç‰©ä»¶çš„æ­·å²è¨˜éŒ„ [(position, frame_number), ...]
        self.history_length = 30  # ğŸ”§ å¢åŠ æ­·å²é•·åº¦ä»¥å¢å¼·é‡è¤‡æª¢æ¸¬ (10â†’30)
        self.duplicate_distance_threshold = 15  # ğŸ”§ æ”¶ç·Šé‡è¤‡æª¢æ¸¬è·é›¢æ¸›å°‘èª¤æª¢ (25â†’15)
        self.temporal_tolerance = 5  # ğŸ”§ é™ä½æ™‚é–“å®¹å¿åº¦æé«˜æª¢æ¸¬ç²¾åº¦ (10â†’5)
        
        # ğŸ§  æ™ºèƒ½å¤§å°çµ±è¨ˆæ¨¡å‹ - ç”¨æ–¼åˆ¤æ–·ç²˜é€£æƒ…æ³
        self.component_sizes = []  # è¨˜éŒ„æ‰€æœ‰æª¢æ¸¬åˆ°çš„é›¶ä»¶å¤§å°
        self.size_statistics = {
            'mean_size': 0,
            'std_size': 0,
            'median_size': 0,
            'size_range': (0, 0),
            'sample_count': 0
        }
        self.min_samples_for_stats = 50  # éœ€è¦å¤šå°‘æ¨£æœ¬æ‰é–‹å§‹çµ±è¨ˆåˆ†æ
        self.clustering_threshold_ratio = 2.5  # è¶…éå¹³å‡å¤§å°å¤šå°‘å€è¦–ç‚ºå¯èƒ½çš„ç²˜é€£
        
        # ğŸ¯ ç©ºé–“ç¶²æ ¼è¿½è¹¤ç³»çµ± - åŸºæ–¼XYä½ç½®çš„ç²¾ç¢ºè¿½è¹¤
        self.grid_cell_size = 30  # ç¶²æ ¼å–®å…ƒå¤§å° (pixels)
        self.position_based_tracking = True  # å•Ÿç”¨ä½ç½®åŸºç¤è¿½è¹¤
        self.spatial_grid = {}  # ç©ºé–“ç¶²æ ¼ï¼š{(grid_x, grid_y): track_id}
        
        # ğŸ§  æ¨æ–·å¼è¿½è¹¤ç³»çµ± - è™•ç†æª¢æ¸¬ä¸­æ–·
        self.enable_predictive_tracking = True  # å•Ÿç”¨æ¨æ–·è¿½è¹¤
        self.prediction_tolerance = 15  # æ¨æ–·ä½ç½®çš„å®¹å¿ç¯„åœ
        self.max_prediction_frames = 5  # æœ€å¤§é€£çºŒæ¨æ–·å¹€æ•¸
        
        # è¿½è¹¤ç‹€æ…‹
        self.object_tracks = {}
        self.lost_tracks = {}  # ğŸ†• å¤±å»çš„è¿½è¹¤ï¼ˆæš«æ™‚æ¶ˆå¤±ä½†å¯èƒ½æ¢å¾©çš„ç‰©ä»¶ï¼‰
        self.crossing_counter = 0
        self.frame_width = 640  # é è¨­å¯¬åº¦ï¼Œæœƒåœ¨ç¬¬ä¸€å¹€æ™‚æ›´æ–°
        self.frame_height = 480  # é è¨­é«˜åº¦ï¼Œæœƒåœ¨ç¬¬ä¸€å¹€æ™‚æ›´æ–°
        self.current_frame_count = 0  # ç•¶å‰å¹€è¨ˆæ•¸
        
        # åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤å™¨
        self.bg_subtractor = None
        self._reset_background_subtractor()
        
        # ğŸ¯ å°ˆæ³¨æ–¼æ ¸å¿ƒæª¢æ¸¬åŠŸèƒ½ï¼Œç§»é™¤å¤šé¤˜çµ±è¨ˆ
        
        # ğŸ“¸ åˆæˆèª¿è©¦åœ–ç‰‡åŠŸèƒ½ - æ•´åˆæ‰€æœ‰åˆ†æéšæ®µæ–¼ä¸€å¼µåœ–ç‰‡
        self.debug_save_enabled = True   # ğŸ¯ å•Ÿç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜
        self.debug_save_dir = "/Users/crmado/github/Real-time_item_monitoring_system/basler_mvc/recordings/composite_debug"
        self.debug_frame_counter = 0
        self.max_debug_frames = float('inf')  # ğŸ¯ ä¿å­˜å…¨éƒ¨ç…§ç‰‡ï¼Œä¸è¨­é™åˆ¶
        
        # ğŸ†• åˆæˆèª¿è©¦åœ–ç‰‡æ¨¡å¼ - é è¨­å•Ÿç”¨ 
        self.composite_debug_enabled = True  # åˆæˆèª¿è©¦åœ–ç‰‡é–‹é—œï¼ˆé è¨­å•Ÿç”¨ï¼‰
        
        # ğŸ¯ å‹•æ…‹ä¸­é–“æ®µè¨ˆç®—åƒæ•¸ - æ·»åŠ è‡ªå®šç¾©èµ·å§‹å¹€é¸é …
        self.total_video_frames = None   # å½±ç‰‡ç¸½å¹€æ•¸ï¼ˆç”±è¦–é »æ’­æ”¾å™¨æä¾›ï¼‰
        self.skip_start_ratio = 0.3      # è·³éå‰30%
        self.save_middle_ratio = 0.4     # ä¿å­˜ä¸­é–“40%ï¼ˆ30%-70%å€é–“ï¼‰
        self.custom_start_frame = None   # è‡ªå®šç¾©èµ·å§‹å¹€ï¼ˆå¦‚2500ï¼‰
        self.total_processed_frames = 0  # ç¸½è™•ç†å¹€æ•¸è¨ˆæ•¸å™¨
        self.current_session_dir = None  # ç•¶å‰æœƒè©±ç›®éŒ„
        self.manual_save_triggered = False  # æ‰‹å‹•è§¸ç™¼ä¿å­˜
        self.manual_trigger_active = False  # æ‰‹å‹•è§¸ç™¼ç‹€æ…‹
        self._temp_debug_data = None  # è‡¨æ™‚èª¿è©¦æ•¸æ“š
        
        logging.info("ğŸ” èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•åˆå§‹åŒ–å®Œæˆ (ğŸ¯ æ¥µåº¦é«˜éˆæ•åº¦ - è¶…ç´šå°é›¶ä»¶æª¢æ¸¬å„ªåŒ–)")
        logging.info(f"ğŸ”§ è¶…æ•æ„Ÿåƒæ•¸: min_area={self.min_area}, bg_var_threshold={self.bg_var_threshold}, min_aspect_ratio={self.min_aspect_ratio}, min_extent={self.min_extent}")
        logging.info(f"ğŸ”§ æœ€å°åŒ–å½¢æ…‹å­¸: opening={self.opening_kernel_size}x{self.opening_iterations}, dilate={self.dilate_kernel_size}x{self.dilate_iterations}, close={self.close_kernel_size}")
        logging.info(f"ğŸ”§ èƒŒæ™¯ç©©å®šæ€§: history={self.bg_history}, learning_rate={self.bg_learning_rate}, var_threshold={self.bg_var_threshold}")
        logging.info(f"ğŸ”§ é‚Šç·£æª¢æ¸¬: canny={self.canny_low_threshold}-{self.canny_high_threshold}, binary_thresh={self.binary_threshold}")
    
    def enable_ultra_high_speed_mode(self, enabled: bool = True, target_fps: int = 280):
        """å•Ÿç”¨è¶…é«˜é€Ÿæª¢æ¸¬æ¨¡å¼ (206-376fps)"""
        self.ultra_high_speed_mode = enabled
        self.target_fps = target_fps
        
        if enabled:
            # ğŸš€ è‡ªå‹•èª¿æ•´åƒæ•¸ä»¥é©æ‡‰ç›®æ¨™FPS
            if target_fps >= 350:
                # 376fpsæ¨¡å¼ - æ¥µåº¦ç°¡åŒ–ä½†ä¿æŒå°é›¶ä»¶æª¢æ¸¬èƒ½åŠ›
                self.high_speed_bg_history = 50
                self.high_speed_bg_var_threshold = 3  # ğŸ”§ å¤§å¹…é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (20â†’3)
                self.high_speed_min_area = 3          # ğŸ”§ å¤§å¹…é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (80â†’3)
                self.high_speed_binary_threshold = 2  # ğŸ”§ æ¥µä½äºŒå€¼åŒ–é–¾å€¼
                logging.info(f"ğŸš€ å•Ÿç”¨376fpsè¶…é«˜é€Ÿæ¨¡å¼ (å°é›¶ä»¶å„ªåŒ–)")
            elif target_fps >= 250:
                # 280fpsæ¨¡å¼ - å¹³è¡¡ç°¡åŒ–ä½†ä¿æŒå°é›¶ä»¶æª¢æ¸¬
                self.high_speed_bg_history = 100
                self.high_speed_bg_var_threshold = 4  # ğŸ”§ é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (16â†’4)
                self.high_speed_min_area = 4          # ğŸ”§ é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (50â†’4)
                self.high_speed_binary_threshold = 3  # ğŸ”§ ä½äºŒå€¼åŒ–é–¾å€¼
                logging.info(f"ğŸš€ å•Ÿç”¨280fpsé«˜é€Ÿæ¨¡å¼ (å°é›¶ä»¶å„ªåŒ–)")
            else:
                # 206fpsæ¨¡å¼ - é©åº¦ç°¡åŒ–ä½†ä¿æŒå°é›¶ä»¶æª¢æ¸¬
                self.high_speed_bg_history = 150
                self.high_speed_bg_var_threshold = 5  # ğŸ”§ é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (14â†’5)
                self.high_speed_min_area = 5          # ğŸ”§ é™ä½ä»¥æª¢æ¸¬å°é›¶ä»¶ (40â†’5)
                self.high_speed_binary_threshold = 4  # ğŸ”§ é©ä¸­äºŒå€¼åŒ–é–¾å€¼
                logging.info(f"ğŸš€ å•Ÿç”¨206fpsæ¨¡å¼ (å°é›¶ä»¶å„ªåŒ–)")
            
            # ğŸ”§ é‡ç½®èƒŒæ™¯æ¸›é™¤å™¨ä»¥æ‡‰ç”¨æ–°åƒæ•¸
            self._reset_background_subtractor()
            
            # ğŸ”§ ç¦ç”¨æ‰€æœ‰èª¿è©¦åŠŸèƒ½ä»¥æå‡æ€§èƒ½
            self.debug_save_enabled = False
            self.composite_debug_enabled = False
            
            logging.info(f"ğŸš€ è¶…é«˜é€Ÿæª¢æ¸¬æ¨¡å¼å·²å•Ÿç”¨ - ç›®æ¨™: {target_fps}fps")
        else:
            logging.info("ğŸ”§ è¶…é«˜é€Ÿæª¢æ¸¬æ¨¡å¼å·²ç¦ç”¨ï¼Œæ¢å¾©æ¨™æº–æ¨¡å¼")
    
    def _reset_background_subtractor(self):
        """é‡ç½®èƒŒæ™¯æ¸›é™¤å™¨ - æ”¯æ´é«˜é€Ÿæ¨¡å¼"""
        if self.ultra_high_speed_mode:
            # ğŸš€ é«˜é€Ÿæ¨¡å¼åƒæ•¸
            history = self.high_speed_bg_history
            var_threshold = self.high_speed_bg_var_threshold
            logging.debug(f"ğŸš€ é«˜é€Ÿæ¨¡å¼èƒŒæ™¯æ¸›é™¤å™¨: history={history}, threshold={var_threshold}")
        else:
            # ğŸ¯ æ¨™æº–æ¨¡å¼åƒæ•¸
            history = self.bg_history
            var_threshold = self.bg_var_threshold
            logging.debug(f"ğŸ¯ æ¨™æº–æ¨¡å¼èƒŒæ™¯æ¸›é™¤å™¨: history={history}, threshold={var_threshold}")
        
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=history,
            varThreshold=var_threshold,
            detectShadows=self.detect_shadows
        )
        # ğŸ¯ è¨­ç½®æ¥µä½å­¸ç¿’ç‡é˜²æ­¢å°é›¶ä»¶è¢«ç´å…¥èƒŒæ™¯æ¨¡å‹
        if hasattr(self, 'bg_learning_rate'):
            self.current_learning_rate = self.bg_learning_rate
        else:
            self.current_learning_rate = 0.001
        logging.debug("èƒŒæ™¯æ¸›é™¤å™¨å·²é‡ç½®")
    
    def process_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """åŸºæ–¼èƒŒæ™¯æ¸›é™¤çš„å½±åƒé è™•ç† - æ”¯æ´ROIå€åŸŸæª¢æ¸¬å’Œé«˜é€Ÿæ¨¡å¼"""
        if frame is None:
            return None
        
        try:
            # ğŸš€ğŸš€ å¼·åŒ–å¹€è¨ˆæ•¸å’Œè·³å¹€æª¢æ¸¬
            self.total_processed_frames += 1
            
            # ğŸ” æª¢æ¸¬è·³å¹€æƒ…æ³ - è¨˜éŒ„è™•ç†çš„æ¯ä¸€å¹€
            if hasattr(self, 'last_processed_frame'):
                frame_gap = self.total_processed_frames - self.last_processed_frame
                if frame_gap > 1:
                    logging.warning(f"âš ï¸ æª¢æ¸¬åˆ°è·³å¹€: å¾{self.last_processed_frame}è·³åˆ°{self.total_processed_frames}, è·³é{frame_gap-1}å¹€")
            self.last_processed_frame = self.total_processed_frames
            
            # æ›´æ–°å¹€å°ºå¯¸
            self.frame_height, self.frame_width = frame.shape[:2]
            
            # ğŸ¯ ROI å€åŸŸæå– (åƒè€ƒ partsCounts_v1.py)
            if self.roi_enabled:
                roi_y = int(self.frame_height * self.roi_position_ratio)
                roi = frame[roi_y:roi_y + self.roi_height, :]
                
                # å­˜å„²ROIä½ç½®ä¿¡æ¯ä¾›å¾ŒçºŒä½¿ç”¨
                self.current_roi_y = roi_y
                self.current_roi_height = self.roi_height
                
                # å°ROIå€åŸŸé€²è¡Œè™•ç†
                process_region = roi
            else:
                # å…¨åœ–æª¢æ¸¬
                process_region = frame
                self.current_roi_y = 0
                self.current_roi_height = self.frame_height
            
            # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šå¤§å¹…ç°¡åŒ–è™•ç†æµç¨‹
            if self.ultra_high_speed_mode:
                return self._ultra_high_speed_processing(process_region)
            
            # ğŸ¯ æ¨™æº–æ¨¡å¼ï¼šå®Œæ•´è™•ç†æµç¨‹
            # 1. èƒŒæ™¯æ¸›é™¤ç²å¾—å‰æ™¯é®ç½© - ä½¿ç”¨æ¥µä½å­¸ç¿’ç‡
            fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)
            
            # 2. é«˜æ–¯æ¨¡ç³Šæ¸›å°‘å™ªè²
            blurred = cv2.GaussianBlur(process_region, self.gaussian_blur_kernel, 0)
            
            # 3. Cannyé‚Šç·£æª¢æ¸¬
            edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
            
            # 4. ğŸš€ å¤šè§’åº¦æª¢æ¸¬ç­–ç•¥ - çµåˆå¤šç¨®æ–¹æ³•æé«˜æª¢æ¸¬ç‡
            
            # ğŸ”§ æ–¹æ³•1: å¢å¼·å‰æ™¯é®ç½©æ¿¾æ³¢ - æ¸›å°‘å™ªé»å¹²æ“¾åŒæ™‚ä¿ç•™å°é›¶ä»¶
            # Step 1: ä¸­å€¼æ¿¾æ³¢å»é™¤æ¤’é¹½å™ªé»
            fg_median = cv2.medianBlur(fg_mask, 5)
            
            # Step 2: å¢å¼·å½¢æ…‹å­¸é–‹é‹ç®—å»é™¤ç¨ç«‹å™ªé»
            enhanced_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # å¾(2,2)å¢åŠ åˆ°(5,5)
            fg_step1 = cv2.morphologyEx(fg_median, cv2.MORPH_OPEN, enhanced_kernel, iterations=1)
            
            # Step 3: é–‰é‹ç®—å¡«è£œç‰©ä»¶å…§éƒ¨ç©ºæ´
            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            fg_step2 = cv2.morphologyEx(fg_step1, cv2.MORPH_CLOSE, close_kernel, iterations=1)
            
            # Step 4: æœ€çµ‚å¾®èª¿é–‹é‹ç®—ï¼Œç§»é™¤å‰©é¤˜å°å™ªé»ä½†ä¿ç•™çœŸå¯¦å°é›¶ä»¶
            final_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            fg_cleaned = cv2.morphologyEx(fg_step2, cv2.MORPH_OPEN, final_kernel, iterations=1)
            
            # ğŸ”§ æ–¹æ³•2: å¤šæ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
            # ä½¿ç”¨å…©ç¨®ä¸åŒæ•æ„Ÿåº¦çš„é‚Šç·£æª¢æ¸¬
            strong_edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
            sensitive_edges = cv2.Canny(blurred, self.canny_low_threshold//2, self.canny_high_threshold//2)
            
            # ğŸ”§ æ–¹æ³•3: è‡ªé©æ‡‰é–¾å€¼æª¢æ¸¬ - è£œå¼·å°é›¶ä»¶æª¢æ¸¬
            gray_roi = cv2.cvtColor(process_region, cv2.COLOR_BGR2GRAY) if len(process_region.shape) == 3 else process_region
            adaptive_thresh = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            
            # ğŸš€ æ™ºèƒ½åŒ–æª¢æ¸¬ç­–ç•¥ - å‰æ™¯é®ç½© + è¼•å¾®é‚Šç·£å¢å¼·
            # èƒŒæ™¯æ¸›é™¤ä½œç‚ºä¸»è¦æª¢æ¸¬ï¼Œé‚Šç·£æª¢æ¸¬ä½œç‚ºè£œå¼·
            
            # 5. è¼•å¾®é‚Šç·£å¢å¼·è™•ç†
            binary_thresh = self.high_speed_binary_threshold if self.ultra_high_speed_mode else self.binary_threshold
            
            # ç‚ºå‰æ™¯é®ç½©ä¸­çš„å°é»é€²è¡Œå¤šé‡å¢å¼·
            # æ–¹æ³•A: é‚Šç·£å¢å¼·
            edge_enhanced = cv2.bitwise_and(sensitive_edges, sensitive_edges, mask=fg_cleaned)
            _, edge_thresh = cv2.threshold(edge_enhanced, 1, 255, cv2.THRESH_BINARY)
            
            # æ–¹æ³•B: è‡ªé©æ‡‰é–¾å€¼å¢å¼·
            adaptive_enhanced = cv2.bitwise_and(adaptive_thresh, adaptive_thresh, mask=fg_cleaned)
            _, adaptive_thresh_clean = cv2.threshold(adaptive_enhanced, 127, 255, cv2.THRESH_BINARY)
            
            # 6. ğŸš€ ä¸‰é‡è¯åˆæª¢æ¸¬ - å‰æ™¯é®ç½© + é‚Šç·£å¢å¼· + è‡ªé©æ‡‰é–¾å€¼
            temp_combined = cv2.bitwise_or(fg_cleaned, edge_thresh)
            combined = cv2.bitwise_or(temp_combined, adaptive_thresh_clean)
            
            # 7. ğŸ”§ æ¥µåº¦ç°¡åŒ–å½¢æ…‹å­¸è™•ç† - æœ€å¤§åŒ–ä¿ç•™å°é›¶ä»¶
            # ä½¿ç”¨æœ€å°åŒ–çš„å½¢æ…‹å­¸æ“ä½œï¼Œé¿å…éåº¦éæ¿¾
            
            # ç¬¬ä¸€éšæ®µï¼šæœ€å°åŒ–é–‹é‹ç®—åƒ…å»é™¤1åƒç´ é›œè¨Š
            if self.opening_kernel_size == (1, 1):
                # å¦‚æœæ˜¯1x1æ ¸ï¼Œå®Œå…¨è·³éé–‹é‹ç®—
                opened_stage1 = combined.copy()
            else:
                opening_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.opening_kernel_size)
                opened_stage1 = cv2.morphologyEx(combined, cv2.MORPH_OPEN, opening_kernel, iterations=self.opening_iterations)
            
            # è·³éç¬¬äºŒéšæ®µé–‹é‹ç®—ä»¥ä¿ç•™æ›´å¤šå°é›¶ä»¶
            
            # æœ€å°åŒ–è†¨è„¹ - åªé€£æ¥ç›¸è¿‘åƒç´ 
            if self.dilate_kernel_size != (1, 1) and self.dilate_iterations > 0:
                dilate_kernel = np.ones(self.dilate_kernel_size, np.uint8)
                dilated = cv2.dilate(opened_stage1, dilate_kernel, iterations=self.dilate_iterations)
            else:
                dilated = opened_stage1.copy()
            
            # æœ€å°åŒ–é–‰åˆé‹ç®—
            if self.close_kernel_size != (1, 1):
                close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.close_kernel_size)
                processed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, close_kernel, iterations=1)
            else:
                processed = dilated.copy()
            
            # ğŸ“¸ å¼·åˆ¶å‰µå»ºèª¿è©¦æ•¸æ“šä»¥ä¾¿åˆ†æ
            if self.debug_save_enabled:
                self._temp_debug_data = {
                    'frame': frame.copy(),
                    'process_region': process_region.copy(),
                    'fg_mask': fg_mask.copy(),
                    'fg_cleaned': combined.copy(),  # ä½¿ç”¨å¢å¼·å¾Œçš„combinedçµæœ
                    'processed': processed.copy()
                }
            else:
                self._temp_debug_data = None
            
            # ğŸ”§ æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶
            self._check_manual_trigger_file()
            
            return processed
            
        except Exception as e:
            logging.error(f"èƒŒæ™¯æ¸›é™¤é è™•ç†éŒ¯èª¤: {str(e)}")
            return None
    
    def _ultra_high_speed_processing(self, process_region: np.ndarray) -> Optional[np.ndarray]:
        """ğŸš€ è¶…é«˜é€Ÿè™•ç†æ¨¡å¼ - å°ˆç‚º206-376fpsè¨­è¨ˆ"""
        try:
            # ğŸš€ æ­¥é©Ÿ1: æ¥µç°¡èƒŒæ™¯æ¸›é™¤ - é«˜é€Ÿæ¨¡å¼ä¹Ÿä½¿ç”¨å­¸ç¿’ç‡æ§åˆ¶
            fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)
            
            # ğŸš€ æ­¥é©Ÿ2: å–®ä¸€è¼•é‡ç´šå½¢æ…‹å­¸è™•ç† (å»é™¤æœ€å°é›œè¨Š)
            kernel = np.ones((3, 3), np.uint8)
            processed = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel, iterations=1)
            
            # ğŸš€ æ­¥é©Ÿ3: ç°¡å–®è†¨è„¹é€£æ¥ç›¸è¿‘å€åŸŸ (æœ€å°‘è™•ç†)
            processed = cv2.dilate(processed, kernel, iterations=1)
            
            # ğŸš€ å®Œå…¨è·³éæ‰€æœ‰å…¶ä»–è™•ç†ï¼š
            # - ç„¡é«˜æ–¯æ¨¡ç³Š
            # - ç„¡Cannyé‚Šç·£æª¢æ¸¬
            # - ç„¡å¤šéšæ®µå½¢æ…‹å­¸è™•ç†
            # - ç„¡èª¿è©¦åœ–ç‰‡ä¿å­˜
            # - æœ€å°‘çš„logging
            
            return processed
            
        except Exception as e:
            # ğŸš€ é«˜é€Ÿæ¨¡å¼ä¸‹æœ€ç°¡åŒ–çš„éŒ¯èª¤è™•ç†
            logging.error(f"é«˜é€Ÿè™•ç†éŒ¯èª¤: {str(e)}")
            return None
    
    def detect_objects(self, processed_frame: np.ndarray, min_area: int = None, max_area: int = None) -> List[Tuple]:
        """åŸºæ–¼é€£é€šçµ„ä»¶çš„ç‰©ä»¶æª¢æ¸¬ - æ”¯æ´ç©¿è¶Šè¨ˆæ•¸å’Œé«˜é€Ÿæ¨¡å¼"""
        if processed_frame is None:
            return []
        
        try:
            # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šç°¡åŒ–åƒæ•¸é¸æ“‡
            if self.ultra_high_speed_mode:
                # ä½¿ç”¨é«˜é€Ÿæ¨¡å¼çš„é¢ç©åƒæ•¸ï¼Œå¿½ç•¥å¤–éƒ¨åƒæ•¸ä»¥ç¢ºä¿ä¸€è‡´æ€§
                min_a = self.high_speed_min_area
                max_a = self.high_speed_max_area
            else:
                # ğŸ¯ æ¨™æº–æ¨¡å¼ï¼šå¼·åˆ¶ä½¿ç”¨æ¥µå°é›¶ä»¶æª¢æ¸¬åƒæ•¸ï¼Œé¿å…è¢«å¤–éƒ¨è¦†è“‹
                # åªæœ‰ç•¶å¤–éƒ¨åƒæ•¸æ›´å°æ™‚æ‰æ¡ç”¨ï¼Œç¢ºä¿æ•ç²æ¥µå°é›¶ä»¶
                min_a = min(min_area if min_area is not None else float('inf'), self.min_area)
                max_a = max(max_area if max_area is not None else 0, self.max_area)
            
            # ğŸ”§ å°é›¶ä»¶å°ˆç”¨å¢å¼·é è™•ç†
            enhanced_frame = processed_frame.copy()
            
            # å°æ–¼æ¥µå°é›¶ä»¶ï¼Œé€²è¡Œè¼•å¾®è†¨è„¹ä½¿å…¶æ›´å®¹æ˜“è¢«æª¢æ¸¬
            if not self.ultra_high_speed_mode:
                # ä½¿ç”¨æ¥µå°çš„è†¨è„¹æ ¸ä¾†è¼•å¾®å¢å¼·å°é›¶ä»¶
                tiny_kernel = np.ones((2, 2), np.uint8)
                enhanced_frame = cv2.dilate(enhanced_frame, tiny_kernel, iterations=1)
            
            # é€£é€šçµ„ä»¶æ¨™è¨˜ (Connected Component Labeling)
            # åƒè€ƒ partsCounts_v1.py çš„å¯¦ç¾
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                enhanced_frame, connectivity=self.connectivity
            )
            
            current_objects = []
            
            # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šæ¸›å°‘èª¿è©¦è¨Šæ¯é »ç‡
            debug_interval = 100 if self.ultra_high_speed_mode else 20
            
            # ğŸ” èª¿è©¦ï¼šå¼·åˆ¶è¨˜éŒ„ç¸½çµ„ä»¶æ•¸å’Œé¢ç©ä¿¡æ¯
            logging.info(f"ğŸ” ç¸½é€£é€šçµ„ä»¶æ•¸: {num_labels-1}, é¢ç©ç¯„åœ: {min_a}-{max_a}")
            
            # ğŸ” è¨˜éŒ„æ‰€æœ‰çµ„ä»¶é¢ç©
            if num_labels > 1:
                all_areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]
                logging.info(f"ğŸ” æ‰€æœ‰çµ„ä»¶é¢ç©: {sorted(all_areas)}")
            
            # éæ­·æ‰€æœ‰é€£é€šçµ„ä»¶ (è·³éèƒŒæ™¯ï¼Œå¾1é–‹å§‹)
            for i in range(1, num_labels):
                area = stats[i, cv2.CC_STAT_AREA]
                
                # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„é¢ç©éæ¿¾ (è©³ç´°èª¿è©¦)
                area_valid = area >= min_a  # æ”¹ç‚ºåªæª¢æŸ¥ä¸‹é™ï¼Œä¸é™åˆ¶ä¸Šé™
                if i <= 5:  # åªè¨˜éŒ„å‰5å€‹çµ„ä»¶
                    logging.info(f"ğŸ” çµ„ä»¶{i}: é¢ç©={area}, æœ€å°é¢ç©={min_a}, é€šéé¢ç©ç¯©é¸={area_valid}")
                
                # ğŸ”§ å¢å¼·é¢ç©ç¯©é¸ - åŠ å…¥ç‰©ä»¶å¤§å°é©—è­‰æ¸›å°‘å™ªé»èª¤æª¢
                area_valid = self._validate_object_size(area, min_a, max_a)
                if area_valid:
                    # æå–é‚Šç•Œæ¡†ä¿¡æ¯ (ROIåº§æ¨™)
                    x = stats[i, cv2.CC_STAT_LEFT]
                    y = stats[i, cv2.CC_STAT_TOP]
                    w = stats[i, cv2.CC_STAT_WIDTH]
                    h = stats[i, cv2.CC_STAT_HEIGHT]
                    
                    # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šè·³éå½¢ç‹€éæ¿¾ä»¥æå‡æ€§èƒ½
                    if self.ultra_high_speed_mode:
                        # é«˜é€Ÿæ¨¡å¼ï¼šåªè¦é€šéé¢ç©ç¯©é¸å°±æ¥å—ï¼Œè·³éæ‰€æœ‰å½¢ç‹€è¨ˆç®—
                        shape_valid = True
                    else:
                        # ğŸ”§ æ¨™æº–æ¨¡å¼ï¼šå®Œæ•´å½¢ç‹€éæ¿¾ - æ¸›å°‘é›œè¨Šèª¤åˆ¤
                        # è¨ˆç®—é•·å¯¬æ¯”
                        aspect_ratio = w / h if h > 0 else 0
                        
                        # è¨ˆç®—å¡«å……æ¯”ä¾‹ (ç‰©ä»¶é¢ç© / é‚Šç•Œæ¡†é¢ç©)
                        bbox_area = w * h
                        extent = area / bbox_area if bbox_area > 0 else 0
                        
                        # è¨ˆç®—å‡¸åŒ…çµå¯¦æ€§ (éœ€è¦æå–è¼ªå»“)
                        try:
                            # æå–ç•¶å‰çµ„ä»¶çš„é®ç½©
                            component_mask = (labels == i).astype(np.uint8) * 255
                            contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                            
                            if contours:
                                contour = contours[0]  # å–æœ€å¤§è¼ªå»“
                                hull = cv2.convexHull(contour)
                                hull_area = cv2.contourArea(hull)
                                solidity = area / hull_area if hull_area > 0 else 0
                            else:
                                solidity = 1.0  # å¦‚æœç„¡æ³•è¨ˆç®—ï¼Œçµ¦äºˆé è¨­å€¼
                        except:
                            solidity = 1.0  # éŒ¯èª¤æ™‚çµ¦äºˆé è¨­å€¼
                        
                        # ğŸ” æ¥µåº¦å¯¬é¬†çš„å½¢ç‹€éæ¿¾ - å„ªå…ˆæ•ç²å°é›¶ä»¶
                        shape_valid = (
                            aspect_ratio > 0.001 and              # æ¥µåº¦å¯¬é¬†çš„é•·å¯¬æ¯” (0.005â†’0.001)
                            extent > 0.001 and                    # æ¥µåº¦å¯¬é¬†çš„å¡«å……æ¯”ä¾‹ (0.005â†’0.001)
                            solidity <= self.max_solidity and     # 5.0
                            area >= 2                             # æ¥µåº¦é™ä½é¢ç©è¦æ±‚ (5â†’2)
                        )
                        
                        # ğŸ” è©³ç´°èª¿è©¦ä¿¡æ¯ï¼šè¨˜éŒ„æ‰€æœ‰å½¢ç‹€åˆ†æçµæœ
                        logging.info(f"ğŸ” çµ„ä»¶{i} å½¢ç‹€åˆ†æ: é¢ç©={area}, é•·å¯¬æ¯”={aspect_ratio:.4f}, å¡«å……æ¯”ä¾‹={extent:.4f}, çµå¯¦æ€§={solidity:.3f}")
                        
                        if not shape_valid:
                            reasons = []
                            if aspect_ratio <= self.min_aspect_ratio:
                                reasons.append(f"é•·å¯¬æ¯”å¤ªå°({aspect_ratio:.4f} <= {self.min_aspect_ratio})")
                            if extent <= self.min_extent:
                                reasons.append(f"å¡«å……æ¯”ä¾‹å¤ªå°({extent:.4f} <= {self.min_extent})")
                            if solidity > self.max_solidity:
                                reasons.append(f"çµå¯¦æ€§å¤ªå¤§({solidity:.3f} > {self.max_solidity})")
                            
                            logging.info(f"ğŸš« çµ„ä»¶{i}è¢«å½¢ç‹€éæ¿¾: é¢ç©={area}, åŸå› ={'; '.join(reasons)}")
                        
                        # ğŸ” è¨˜éŒ„é€šéæª¢æ¸¬çš„ç‰©ä»¶
                        if shape_valid:
                            logging.info(f"âœ… çµ„ä»¶{i}é€šéæª¢æ¸¬: é¢ç©={area}, é•·å¯¬æ¯”={aspect_ratio:.3f}, ä½ç½®=({x},{y})")
                    
                    if shape_valid:
                        # ç²å–è³ªå¿ƒ (ROIåº§æ¨™)
                        roi_centroid = tuple(map(int, centroids[i]))
                        
                        # è½‰æ›ç‚ºå…¨åœ–åº§æ¨™
                        global_centroid = (roi_centroid[0], roi_centroid[1] + self.current_roi_y)
                        global_y = y + self.current_roi_y
                        
                        # è¨ˆç®—ç­‰æ•ˆåœ“åŠå¾‘
                        radius = np.sqrt(area / np.pi)
                        
                        # ğŸ§  æ›´æ–°å¤§å°çµ±è¨ˆæ¨¡å‹
                        self._update_size_statistics(area)
                        
                        # ğŸ”§ æ™ºèƒ½ç²˜é€£æª¢æ¸¬èˆ‡åˆ†é›¢
                        should_separate = False
                        separation_reason = ""
                        
                        # æ–¹æ³•1: åŸºæ–¼çµ±è¨ˆå¤§å°çš„æ™ºèƒ½åˆ¤æ–·
                        if self._is_clustered_component(area):
                            should_separate = True
                            estimated_count = self._estimate_component_count(area)
                            separation_reason = f"çµ±è¨ˆåˆ†æ(ä¼°ç®—{estimated_count}å€‹é›¶ä»¶)"
                            
                        # æ–¹æ³•2: å‚³çµ±æ–¹æ³•ä½œç‚ºå¾Œå‚™ (é¢ç©è¶…éåˆç†é–¾å€¼)
                        elif (self.enable_watershed_separation and 
                              self.size_statistics['sample_count'] < self.min_samples_for_stats and 
                              area > 500):  # ğŸ”§ èª¿æ•´ç‚ºæ›´åˆç†çš„é–¾å€¼ï¼Œåªåœ¨çµ±è¨ˆä¸è¶³æ™‚ä½¿ç”¨
                            should_separate = True
                            separation_reason = f"çµ±è¨ˆä¸è¶³æ™‚çš„ä¿å®ˆåˆ†é›¢(é¢ç©>{500})"
                        
                        if should_separate:
                            logging.info(f"ğŸ”§ å˜—è©¦åˆ†é›¢ç²˜é€£é›¶ä»¶: é¢ç©={area:.0f}, åŸå› ={separation_reason}")
                            separated_objects = self._separate_clustered_components(
                                enhanced_frame, labels, i, x, y, w, h, area
                            )
                            
                            if separated_objects:  # å¦‚æœæˆåŠŸåˆ†é›¢
                                logging.info(f"âœ… æˆåŠŸåˆ†é›¢å‡º{len(separated_objects)}å€‹é›¶ä»¶")
                                for sep_obj in separated_objects:
                                    sep_x, sep_y, sep_w, sep_h, sep_area, sep_radius = sep_obj
                                    # è½‰æ›ç‚ºå…¨åœ–åº§æ¨™
                                    global_sep_y = sep_y + self.current_roi_y
                                    global_sep_centroid = (sep_x + sep_w//2, global_sep_y + sep_h//2)
                                    current_objects.append((sep_x, global_sep_y, sep_w, sep_h, global_sep_centroid, sep_area, sep_radius))
                                    # ç‚ºåˆ†é›¢å‡ºçš„é›¶ä»¶ä¹Ÿæ›´æ–°çµ±è¨ˆ
                                    self._update_size_statistics(sep_area)
                                continue  # è·³éåŸå§‹å¤§ç‰©ä»¶ï¼Œä½¿ç”¨åˆ†é›¢å¾Œçš„çµæœ
                            else:
                                logging.warning(f"âŒ åˆ†é›¢å¤±æ•—ï¼Œä¿ç•™åŸå§‹ç‰©ä»¶: é¢ç©={area:.0f}")
                        
                        # æ·»åŠ åˆ°ç•¶å‰ç‰©ä»¶åˆ—è¡¨ (ä½¿ç”¨å…¨åœ–åº§æ¨™)
                        # æ ¼å¼: (x, global_y, w, h, global_centroid, area, radius)
                        current_objects.append((x, global_y, w, h, global_centroid, area, radius))
            
            # ğŸ¯ åŸ·è¡Œç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸ (åƒè€ƒ partsCounts_v1.py)
            if self.enable_crossing_count:
                # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šç°¡åŒ–è¿½è¹¤æˆ–å®Œå…¨è·³é
                if self.ultra_high_speed_mode:
                    # é«˜é€Ÿæ¨¡å¼é¸é …1ï¼šç°¡åŒ–è¨ˆæ•¸ (ç›´æ¥ä½¿ç”¨ç‰©ä»¶æ•¸é‡)
                    self.crossing_counter += len(current_objects)
                    # è·³éè¤‡é›œçš„è¿½è¹¤é‚è¼¯ä»¥æå‡æ€§èƒ½
                else:
                    # ğŸ” æ¨™æº–æ¨¡å¼ï¼šå®Œæ•´è¿½è¹¤é‚è¼¯
                    # èª¿è©¦ï¼šè¨˜éŒ„è¿½è¹¤ç‹€æ…‹ (æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡)
                    if self.current_frame_count % 20 == 0:
                        logging.debug(f"ğŸ” é–‹å§‹è¿½è¹¤: æª¢æ¸¬ç‰©ä»¶æ•¸={len(current_objects)}, å•Ÿç”¨è¨ˆæ•¸={self.enable_crossing_count}")
                    self._update_object_tracking(current_objects)
            
            # ğŸ’¾ ä¿å­˜æª¢æ¸¬çµæœä¾›èª¿è©¦ä½¿ç”¨
            self.last_detected_objects = current_objects.copy()
            
            # ğŸ“¸ ä¿å­˜èª¿è©¦åœ–ç‰‡çš„æ¢ä»¶ - åªåœ¨è¦–é »å›æ”¾æ¨¡å¼ä¸‹å•Ÿç”¨
            # ğŸš€ é«˜é€Ÿæ¨¡å¼ï¼šå®Œå…¨ç¦ç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜
            # ğŸ” å¼·åˆ¶ä¿å­˜æ‰€æœ‰å¹€ä»¥ä¾¿åˆ†æ - æš«æ™‚ç§»é™¤æ¢ä»¶é™åˆ¶
            should_save = (
                not self.ultra_high_speed_mode and  # é«˜é€Ÿæ¨¡å¼ä¸‹å¼·åˆ¶ç¦ç”¨
                self._temp_debug_data is not None and 
                self.debug_frame_counter < self.max_debug_frames and
                self.debug_save_enabled and
                self.composite_debug_enabled
                # æš«æ™‚ç§»é™¤æ‰€æœ‰æ¢ä»¶é™åˆ¶ï¼Œä¿å­˜æ¯ä¸€å¹€
            )
            
            # ğŸ¯ åœ¨å‰›é€²å…¥ä¸­é–“æ®µä¿å­˜çª—å£æ™‚è¨˜éŒ„æ—¥èªŒ
            if self.total_video_frames is not None:
                start_frame = int(self.total_video_frames * self.skip_start_ratio)
                if (self.total_processed_frames == start_frame + 1 and self.debug_save_enabled):
                    end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
                    logging.info(f"ğŸ“¸ é–‹å§‹ä¿å­˜å½±ç‰‡ä¸­é–“æ®µèª¿è©¦åœ–ç‰‡")
                    logging.info(f"   ä¿å­˜ç¯„åœ: ç¬¬{start_frame}å¹€ - ç¬¬{end_frame}å¹€")
                    logging.info(f"   é è¨ˆä¿å­˜ç´„ {end_frame - start_frame} å¹€çš„æ•¸æ“š")
            
            # ğŸ” å¼·åˆ¶æ›´æ–°èª¿è©¦å¹€è¨ˆæ•¸å™¨ç¢ºä¿é€£çºŒæ€§
            self.debug_frame_counter += 1
            
            if should_save:
                save_reason = f"ç¬¬{self.debug_frame_counter}å¹€ (æª¢æ¸¬åˆ° {len(current_objects)} å€‹ç‰©ä»¶)"
                
                # ğŸ–¼ï¸ ä½¿ç”¨æ–°çš„åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜æ–¹æ³•
                self._save_composite_debug_image(
                    self._temp_debug_data['frame'],           # åŸå§‹å¹€
                    self._temp_debug_data['process_region'],  # ROIå€åŸŸ
                    self._temp_debug_data['fg_mask'],         # å‰æ™¯é®ç½©
                    self._temp_debug_data['fg_cleaned'],      # åˆä½µæª¢æ¸¬çµæœ
                    self._temp_debug_data['processed'],       # æœ€çµ‚è™•ç†çµæœ
                    current_objects                           # æª¢æ¸¬åˆ°çš„ç‰©ä»¶
                )
                
                # æ¯50å¹€è¨˜éŒ„ä¸€æ¬¡é€²åº¦
                if self.debug_frame_counter % 50 == 0:
                    logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ {save_reason}ï¼Œå·²ä¿å­˜ {self.debug_frame_counter}/{self.max_debug_frames}")
                
                # é‡ç½®æ‰‹å‹•è§¸ç™¼æ¨™è¨˜
                self.manual_save_triggered = False
            
            # æ¸…ç†è‡¨æ™‚æ•¸æ“šï¼Œå¼·åˆ¶é‡‹æ”¾è¨˜æ†¶é«”
            if self._temp_debug_data is not None:
                del self._temp_debug_data
            self._temp_debug_data = None
            
            # ğŸš€ğŸš€ 206fpsæ¨¡å¼ï¼šç§»é™¤å¼·åˆ¶åƒåœ¾å›æ”¶ä»¥æå‡æ€§èƒ½
            # import gc  # å·²ç¦ç”¨
            # if self.debug_frame_counter % 10 == 0:  # å·²ç¦ç”¨
            #     gc.collect()  # å·²ç¦ç”¨
            
            # ğŸ” èª¿è©¦ï¼šå¼·åˆ¶è¨˜éŒ„æ¯å¹€è™•ç†çµæœä»¥åˆ†æå•é¡Œ
            logging.info(f"ğŸ¯ å¹€{self.total_processed_frames}: çµ„ä»¶{num_labels-1}â†’ç‰©ä»¶{len(current_objects)}, èª¿è©¦å¹€è™Ÿ{self.debug_frame_counter}")
            
            return current_objects
            
        except Exception as e:
            logging.error(f"èƒŒæ™¯æ¸›é™¤æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return []
    
    def _update_object_tracking(self, current_objects: List[Tuple]):
        """æ”¹é€²çš„ç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸é‚è¼¯"""
        try:
            self.current_frame_count += 1
            
            # ROIå€åŸŸé‚Šç•Œ
            roi_top = self.current_roi_y
            roi_bottom = self.current_roi_y + self.roi_height
            roi_center = self.current_roi_y + self.roi_height // 2
            
            # ğŸ”§ æ”¹é€²çš„è¿½è¹¤åŒ¹é…é‚è¼¯ï¼šå¯¦ç¾ä¸€å°ä¸€åŒ¹é…ï¼Œé¿å…å¤šç‰©ä»¶æ²–çª
            new_tracks = {}
            used_track_ids = set()  # è¨˜éŒ„å·²ç¶“åŒ¹é…çš„è¿½è¹¤ID
            
            # ğŸ¯ æ¸…ç†ç©ºé–“ç¶²æ ¼ä¸¦é‡å»º (æ¯å¹€é‡æ–°è¨ˆç®—ç¶²æ ¼ä½”ç”¨)
            self.spatial_grid.clear()
            
            # ğŸ§  æ¨æ–·å¼è¿½è¹¤ï¼šç‚ºå¯èƒ½å¤±å»æª¢æ¸¬çš„ç‰©ä»¶ç”Ÿæˆè™›æ“¬æª¢æ¸¬
            virtual_objects = []
            if self.enable_predictive_tracking:
                # ç•¶æª¢æ¸¬è¼ƒå°‘æˆ–æœ‰å¤±å»çš„è¿½è¹¤æ™‚ï¼Œå˜—è©¦æ¨æ–·
                virtual_objects = self._generate_predictive_objects()
                if virtual_objects:
                    logging.debug(f"ğŸ”® ç”Ÿæˆ{len(virtual_objects)}å€‹æ¨æ–·ç‰©ä»¶ï¼ˆæª¢æ¸¬åˆ°{len(current_objects)}å€‹çœŸå¯¦ç‰©ä»¶ï¼‰")
            
            # åˆä½µå¯¦éš›æª¢æ¸¬å’Œæ¨æ–·ç‰©ä»¶
            all_objects = current_objects + virtual_objects
            
            # ğŸ¯ ç¬¬ä¸€éšæ®µï¼šç‚ºæ¯å€‹æª¢æ¸¬ç‰©ä»¶æ‰¾åˆ°æœ€ä½³åŒ¹é…
            object_track_matches = []  # [(object_index, track_id, distance, is_virtual), ...]
            
            for obj_idx, obj in enumerate(all_objects):
                x, y, w, h, centroid, area, radius = obj
                cx, cy = centroid
                is_virtual = obj_idx >= len(current_objects)  # åˆ¤æ–·æ˜¯å¦ç‚ºè™›æ“¬ç‰©ä»¶
                
                best_match_id = None
                best_match_distance = float('inf')
                
                # èˆ‡ç¾æœ‰è¿½è¹¤é€²è¡ŒåŒ¹é… (æ‰¾æœ€ä½³åŒ¹é…)
                for track_id, track in self.object_tracks.items():
                    if track_id in used_track_ids:  # è·³éå·²ç¶“è¢«åŒ¹é…çš„è¿½è¹¤
                        continue
                        
                    # è¨ˆç®—è·é›¢
                    distance = np.sqrt((cx - track['x'])**2 + (cy - track['y'])**2)
                    
                    # ğŸ§  å°è™›æ“¬ç‰©ä»¶ä½¿ç”¨æ›´å¯¬é¬†çš„å®¹å·®
                    tolerance_x = self.crossing_tolerance_x * (2 if is_virtual else 1)
                    tolerance_y = self.crossing_tolerance_y * (2 if is_virtual else 1)
                    
                    # æª¢æŸ¥æ˜¯å¦åœ¨å®¹å·®ç¯„åœå…§
                    if (abs(cx - track['x']) < tolerance_x and 
                        abs(cy - track['y']) < tolerance_y and
                        distance < best_match_distance):
                        
                        best_match_distance = distance
                        best_match_id = track_id
                
                # è¨˜éŒ„åŒ¹é…çµæœ
                if best_match_id is not None:
                    object_track_matches.append((obj_idx, best_match_id, best_match_distance, is_virtual))
            
            # ğŸ¯ ç¬¬äºŒéšæ®µï¼šæŒ‰è·é›¢æ’åºï¼Œç¢ºä¿æœ€ä½³åŒ¹é…å„ªå…ˆ
            object_track_matches.sort(key=lambda x: x[2])  # æŒ‰è·é›¢æ’åº
            
            # ğŸ¯ ç¬¬ä¸‰éšæ®µï¼šåŸ·è¡Œä¸€å°ä¸€åŒ¹é…ï¼ˆå«ç¶²æ ¼é©—è­‰ï¼‰
            # grid_conflicted_objects = set()  # ğŸ”§ è¨˜éŒ„å› ç¶²æ ¼è¡çªè¢«è·³éçš„ç‰©ä»¶
            
            for match_data in object_track_matches:
                if len(match_data) == 4:
                    obj_idx, track_id, distance, is_virtual = match_data
                else:
                    obj_idx, track_id, distance = match_data
                    is_virtual = False
                    
                if track_id not in used_track_ids:
                    # åŸ·è¡ŒåŒ¹é…
                    obj = all_objects[obj_idx]
                    x, y, w, h, centroid, area, radius = obj
                    cx, cy = centroid
                    
                    # ğŸ¯ ç¶²æ ¼é©—è­‰ï¼šæª¢æŸ¥ç©ºé–“è¡çª
                    grid_pos = self._get_grid_position(cx, cy)
                    grid_conflict = grid_pos in self.spatial_grid
                    
                    if not grid_conflict or not self.position_based_tracking:
                        # ç„¡ç¶²æ ¼è¡çªæˆ–æœªå•Ÿç”¨ä½ç½®è¿½è¹¤ï¼ŒåŸ·è¡ŒåŒ¹é…
                        old_track = self.object_tracks[track_id]
                        new_tracks[track_id] = {
                            'x': cx,
                            'y': cy,
                            'first_frame': old_track.get('first_frame', self.current_frame_count),
                            'last_frame': self.current_frame_count,
                            'positions': old_track.get('positions', []) + [(cx, cy)],
                            'counted': old_track.get('counted', False),
                            'in_roi_frames': old_track.get('in_roi_frames', 0) + 1,
                            'max_y': max(old_track.get('max_y', cy), cy),
                            'min_y': min(old_track.get('min_y', cy), cy),
                            'grid_position': grid_pos,  # è¨˜éŒ„ç¶²æ ¼ä½ç½®
                            # ğŸ§  ç‚ºæ¨æ–·å¼è¿½è¹¤æ·»åŠ å°ºå¯¸ä¿¡æ¯
                            'avg_w': int((old_track.get('avg_w', w) + w) / 2),
                            'avg_h': int((old_track.get('avg_h', h) + h) / 2),
                            'avg_area': (old_track.get('avg_area', area) + area) / 2
                        }
                        used_track_ids.add(track_id)
                        
                        # ä½”ç”¨ç¶²æ ¼
                        if self.position_based_tracking:
                            self.spatial_grid[grid_pos] = track_id
                            
                        logging.debug(f"ğŸ”— ç‰©ä»¶{obj_idx}åŒ¹é…åˆ°è¿½è¹¤{track_id}, è·é›¢={distance:.1f}px, ç¶²æ ¼={grid_pos}")
                    else:
                        # æœ‰ç¶²æ ¼è¡çªï¼Œè¨˜éŒ„ä¸¦è·³éï¼Œé˜²æ­¢é‡è¤‡å‰µå»º
                        conflicted_track = self.spatial_grid[grid_pos]
                        # grid_conflicted_objects.add(obj_idx)  # ğŸ”§ è¨˜éŒ„è¡çªç‰©ä»¶
                        logging.warning(f"âš ï¸ ç¶²æ ¼è¡çª: ç‰©ä»¶{obj_idx}èˆ‡è¿½è¹¤{conflicted_track}åœ¨ç¶²æ ¼{grid_pos}è¡çªï¼Œè·³éåŒ¹é…")
            
            # ğŸ¯ ç¬¬å››éšæ®µï¼šç‚ºæœªåŒ¹é…çš„ç‰©ä»¶ï¼ˆåŒ…æ‹¬è™›æ“¬ç‰©ä»¶ï¼‰å‰µå»ºæ–°è¿½è¹¤æˆ–å˜—è©¦æ¢å¾©
            matched_objects = {match[0] for match in object_track_matches if match[1] in used_track_ids}
            
            for obj_idx, obj in enumerate(all_objects):
                if obj_idx not in matched_objects:
                    x, y, w, h, centroid, area, radius = obj
                    cx, cy = centroid
                    is_virtual = obj_idx >= len(current_objects)  # åˆ¤æ–·æ˜¯å¦ç‚ºè™›æ“¬ç‰©ä»¶
                    
                    # ğŸ”„ è¿½è¹¤æ¢å¾©æ©Ÿåˆ¶ï¼šå˜—è©¦å¾lost_tracksä¸­æ¢å¾©åŒ¹é…çš„è¿½è¹¤
                    recovered_track_id = None
                    best_recovery_distance = float('inf')
                    best_recovery_track_id = None
                    
                    # éæ­·å¤±å»çš„è¿½è¹¤å°‹æ‰¾å¯èƒ½çš„æ¢å¾©åŒ¹é…
                    for lost_track_id, lost_track in self.lost_tracks.items():
                        # è¨ˆç®—ç©ºé–“è·é›¢
                        spatial_distance = np.sqrt((cx - lost_track['x'])**2 + (cy - lost_track['y'])**2)
                        # è¨ˆç®—æ™‚é–“é–“éš”
                        temporal_distance = self.current_frame_count - lost_track['last_frame']
                        
                        # æ¢å¾©æ¢ä»¶ï¼šç©ºé–“è·é›¢ç¨å¾®å¯¬é¬†ï¼Œæ™‚é–“é–“éš”åœ¨å®¹å¿ç¯„åœå…§
                        recovery_tolerance_x = self.crossing_tolerance_x * 1.5
                        recovery_tolerance_y = self.crossing_tolerance_y * 1.5
                        
                        if (abs(cx - lost_track['x']) < recovery_tolerance_x and 
                            abs(cy - lost_track['y']) < recovery_tolerance_y and
                            temporal_distance <= self.temporal_tolerance and
                            spatial_distance < best_recovery_distance):
                            
                            best_recovery_distance = spatial_distance
                            best_recovery_track_id = lost_track_id
                    
                    # å¦‚æœæ‰¾åˆ°åˆé©çš„æ¢å¾©åŒ¹é…
                    if best_recovery_track_id is not None:
                        recovered_track_id = best_recovery_track_id
                        recovered_track = self.lost_tracks[recovered_track_id]
                        
                        # ğŸ¯ æª¢æŸ¥æ¢å¾©ä½ç½®çš„ç¶²æ ¼è¡çª
                        recovery_grid_pos = self._get_grid_position(cx, cy)
                        if recovery_grid_pos not in self.spatial_grid or not self.position_based_tracking:
                            # æ¢å¾©è¿½è¹¤åˆ°new_tracks
                            new_tracks[recovered_track_id] = {
                                'x': cx,
                                'y': cy,
                                'first_frame': recovered_track.get('first_frame', self.current_frame_count),
                                'last_frame': self.current_frame_count,
                                'positions': recovered_track.get('positions', []) + [(cx, cy)],
                                'counted': recovered_track.get('counted', False),
                                'in_roi_frames': recovered_track.get('in_roi_frames', 0) + 1,
                                'max_y': max(recovered_track.get('max_y', cy), cy),
                                'min_y': min(recovered_track.get('min_y', cy), cy),
                                'grid_position': recovery_grid_pos,
                                # ğŸ§  ç‚ºæ¨æ–·å¼è¿½è¹¤æ·»åŠ å°ºå¯¸ä¿¡æ¯
                                'avg_w': int((recovered_track.get('avg_w', w) + w) / 2),
                                'avg_h': int((recovered_track.get('avg_h', h) + h) / 2),
                                'avg_area': (recovered_track.get('avg_area', area) + area) / 2
                            }
                            
                            # ä½”ç”¨ç¶²æ ¼
                            if self.position_based_tracking:
                                self.spatial_grid[recovery_grid_pos] = recovered_track_id
                        else:
                            # æ¢å¾©ä½ç½®æœ‰ç¶²æ ¼è¡çªï¼Œæ”¾æ£„æ¢å¾©
                            recovered_track_id = None
                            logging.warning(f"âš ï¸ è¿½è¹¤æ¢å¾©å¤±æ•—: ç¶²æ ¼{recovery_grid_pos}å·²è¢«ä½”ç”¨")
                        
                        # å¾lost_tracksä¸­ç§»é™¤å·²æ¢å¾©çš„è¿½è¹¤
                        del self.lost_tracks[recovered_track_id]
                        
                        logging.info(f"ğŸ”„ æˆåŠŸæ¢å¾©è¿½è¹¤{recovered_track_id}: è·é›¢={best_recovery_distance:.1f}px, æ™‚é–“é–“éš”={self.current_frame_count - recovered_track['last_frame']}å¹€")
                    
                    if not recovered_track_id:
                        # ğŸ§  å°æ–¼è™›æ“¬ç‰©ä»¶ï¼šå„ªå…ˆæ¢å¾©è€Œéå‰µå»ºæ–°è¿½è¹¤
                        if is_virtual:
                            logging.debug(f"ğŸ”® è™›æ“¬ç‰©ä»¶{obj_idx}æœªæ‰¾åˆ°æ¢å¾©ç›®æ¨™ï¼Œè·³éå‰µå»ºæ–°è¿½è¹¤")
                            continue
                        
                        # ğŸ¯ æª¢æŸ¥æ–°è¿½è¹¤ä½ç½®çš„ç¶²æ ¼è¡çªï¼ˆåƒ…å°çœŸå¯¦ç‰©ä»¶ï¼‰
                        new_grid_pos = self._get_grid_position(cx, cy)
                        if new_grid_pos not in self.spatial_grid or not self.position_based_tracking:
                            # å‰µå»ºæ–°çš„è¿½è¹¤
                            new_track_id = max(list(self.object_tracks.keys()) + list(new_tracks.keys()) + [0]) + 1
                            new_tracks[new_track_id] = {
                                'x': cx,
                                'y': cy,
                                'first_frame': self.current_frame_count,
                                'last_frame': self.current_frame_count,
                                'positions': [(cx, cy)],
                                'counted': False,
                                'in_roi_frames': 1,
                                'max_y': cy,
                                'min_y': cy,
                                'grid_position': new_grid_pos,
                                # ğŸ§  ç‚ºæ¨æ–·å¼è¿½è¹¤æ·»åŠ å°ºå¯¸ä¿¡æ¯
                                'avg_w': w,
                                'avg_h': h,
                                'avg_area': area
                            }
                            
                            # ä½”ç”¨ç¶²æ ¼
                            if self.position_based_tracking:
                                self.spatial_grid[new_grid_pos] = new_track_id
                                
                            logging.debug(f"ğŸ†• ç‰©ä»¶{obj_idx}å‰µå»ºæ–°è¿½è¹¤{new_track_id}, ç¶²æ ¼={new_grid_pos}")
                        else:
                            # æ–°ä½ç½®æœ‰ç¶²æ ¼è¡çªï¼Œè·³éå‰µå»º
                            conflicted_track = self.spatial_grid[new_grid_pos]
                            logging.warning(f"âš ï¸ æ–°è¿½è¹¤å‰µå»ºå¤±æ•—: ç‰©ä»¶{obj_idx}åœ¨ç¶²æ ¼{new_grid_pos}èˆ‡è¿½è¹¤{conflicted_track}è¡çª")
                    else:
                        logging.debug(f"ğŸ”„ ç‰©ä»¶{obj_idx}æ¢å¾©è¿½è¹¤{recovered_track_id}")
            
            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è»Œè·¡ç‹€æ…‹å’Œç¶²æ ¼è¡çªçµ±è¨ˆ (æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡)
            if self.current_frame_count % 20 == 0:
                logging.debug(f"ğŸ¯ è»Œè·¡ç‹€æ…‹: ç¸½è»Œè·¡æ•¸={len(new_tracks)}, ç•¶å‰ç©¿è¶Šè¨ˆæ•¸={self.crossing_counter}")
            
            # ğŸ¯ ç°¡åŒ–é«˜æ•ˆç©¿è¶Šè¨ˆæ•¸é‚è¼¯ - æå‡æª¢æ¸¬é€Ÿåº¦
            for track_id, track in new_tracks.items():
                if not track['counted'] and track['in_roi_frames'] >= self.min_track_frames:
                    # ç°¡åŒ–æª¢æŸ¥ï¼šåªè¦ç‰©ä»¶åœ¨ROIä¸­å‡ºç¾å°±è¨ˆæ•¸
                    y_travel = track['max_y'] - track['min_y']
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡è¨ˆæ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    is_duplicate = self._check_duplicate_detection_simple(track)
                    
                    # ğŸ¯ æå‡è¿½è¹¤ç©©å®šæ€§ï¼šé©åº¦æé«˜ç§»å‹•è¦æ±‚æ¸›å°‘èª¤æª¢
                    valid_crossing = (
                        y_travel >= 8 and           # ğŸ”§ æé«˜ç§»å‹•è¦æ±‚æ¸›å°‘èª¤æª¢ (3â†’8åƒç´ )
                        track['in_roi_frames'] >= self.min_track_frames and  # ç¢ºä¿å¤šå¹€ç©©å®šæª¢æ¸¬
                        not is_duplicate            # éé‡è¤‡æª¢æ¸¬
                    )
                    
                    # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è¨ˆæ•¸é‚è¼¯ (æ¯10å¹€è¨˜éŒ„ä¸€æ¬¡)
                    if self.current_frame_count % 10 == 0 and track_id in list(new_tracks.keys())[:2]:
                        logging.debug(f"ç‰©ä»¶{track_id}: Yç§»å‹•={y_travel}px, é‡è¤‡={is_duplicate}, åœ¨ROIå¹€æ•¸={track['in_roi_frames']}, æœ‰æ•ˆç©¿è¶Š={valid_crossing}")
                    
                    if valid_crossing:
                        # è¨˜éŒ„åˆ°æ­·å²ä¸­é˜²æ­¢é‡è¤‡
                        self._add_to_history(track)
                        
                        self.crossing_counter += 1
                        track['counted'] = True
                        
                        # ğŸ” é‡è¦ï¼šè¨˜éŒ„æ¯æ¬¡æˆåŠŸè¨ˆæ•¸ (æ€§èƒ½å½±éŸ¿å°ä½†å¾ˆé‡è¦)
                        logging.info(f"âœ… æˆåŠŸè¨ˆæ•¸ #{self.crossing_counter} - ç‰©ä»¶{track_id} (Yç§»å‹•: {y_travel}px)")
            
            # ğŸ”§ æ”¹é€²çš„è¿½è¹¤ç”Ÿå‘½é€±æœŸç®¡ç†ï¼šç§»å‹•å¤±å»çš„è¿½è¹¤åˆ°lost_tracks
            current_time = self.current_frame_count
            
            # å°‡ç•¶å‰æœªåŒ¹é…çš„è¿½è¹¤ç§»å‹•åˆ°lost_tracks
            for track_id, track in self.object_tracks.items():
                if track_id not in new_tracks:
                    # è¿½è¹¤å¤±å»åŒ¹é…ï¼Œç§»å‹•åˆ°lost_tracks
                    self.lost_tracks[track_id] = track
                    logging.debug(f"ğŸ”„ è¿½è¹¤{track_id}å¤±å»åŒ¹é…ï¼Œç§»å‹•åˆ°lost_tracks")
            
            # æ¸…ç†éæœŸçš„lost_tracks
            for track_id in list(self.lost_tracks.keys()):
                track = self.lost_tracks[track_id]
                if current_time - track['last_frame'] > self.temporal_tolerance:
                    del self.lost_tracks[track_id]
                    logging.debug(f"ğŸ—‘ï¸ æ¸…ç†éæœŸlost_track {track_id}")
            
            # æ›´æ–°è¿½è¹¤ç‹€æ…‹
            self.object_tracks = new_tracks
            
        except Exception as e:
            logging.error(f"ç‰©ä»¶è¿½è¹¤æ›´æ–°éŒ¯èª¤: {str(e)}")
    
    def _check_duplicate_detection_simple(self, track: Dict) -> bool:
        """ğŸ”§ å¢å¼·ç‰ˆé‡è¤‡æª¢æ¸¬ - åŠ å…¥æ™‚é–“èˆ‡ç©ºé–“é›™é‡è€ƒé‡"""
        try:
            current_pos = (track['x'], track['y'])
            current_frame = self.current_frame_count
            
            # ğŸ†• æª¢æŸ¥æ­·å²è¨˜éŒ„ä¸­çš„æ™‚ç©ºé‡è¤‡
            for hist_entry in self.counted_objects_history:
                if isinstance(hist_entry, tuple) and len(hist_entry) == 2:
                    # æ–°æ ¼å¼ï¼š(position, frame_number)
                    hist_pos, hist_frame = hist_entry
                    
                    # ğŸ¯ æ™‚ç©ºè·é›¢æª¢æ¸¬ï¼šåŒæ™‚è€ƒæ…®ç©ºé–“è·é›¢å’Œæ™‚é–“é–“éš”
                    spatial_distance = abs(current_pos[0] - hist_pos[0]) + abs(current_pos[1] - hist_pos[1])
                    temporal_distance = current_frame - hist_frame
                    
                    # ğŸ›¡ï¸ å¦‚æœç©ºé–“è·é›¢å°ä¸”æ™‚é–“é–“éš”åœ¨å®¹å¿ç¯„åœå…§ï¼Œè¦–ç‚ºé‡è¤‡
                    if (spatial_distance < self.duplicate_distance_threshold and 
                        temporal_distance <= self.temporal_tolerance):
                        logging.debug(f"ğŸš« æª¢æ¸¬åˆ°é‡è¤‡: ç©ºé–“è·é›¢={spatial_distance}, æ™‚é–“é–“éš”={temporal_distance}å¹€")
                        return True
                        
                elif isinstance(hist_entry, tuple) and len(hist_entry) == 2 and isinstance(hist_entry[0], (int, float)):
                    # èˆŠæ ¼å¼ï¼š(x, y) - å‘å¾Œç›¸å®¹
                    hist_pos = hist_entry
                    spatial_distance = abs(current_pos[0] - hist_pos[0]) + abs(current_pos[1] - hist_pos[1])
                    
                    if spatial_distance < self.duplicate_distance_threshold:
                        return True
            
            return False
            
        except Exception as e:
            logging.debug(f"é‡è¤‡æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return False
    
    def _add_to_history(self, track: Dict):
        """ğŸ”§ æ·»åŠ å·²è¨ˆæ•¸ç‰©ä»¶åˆ°æ­·å²è¨˜éŒ„ - åŒ…å«æ™‚é–“ä¿¡æ¯"""
        try:
            position = (track['x'], track['y'])
            frame_number = self.current_frame_count
            
            # ğŸ†• æ–°æ ¼å¼ï¼šåŒæ™‚è¨˜éŒ„ä½ç½®å’Œæ™‚é–“
            history_entry = (position, frame_number)
            self.counted_objects_history.append(history_entry)
            
            # ä¿æŒæ­·å²è¨˜éŒ„åœ¨é™åˆ¶ç¯„åœå…§
            if len(self.counted_objects_history) > self.history_length:
                self.counted_objects_history.pop(0)
                
            logging.debug(f"ğŸ“ æ·»åŠ åˆ°æ­·å²: ä½ç½®={position}, å¹€è™Ÿ={frame_number}")
                
        except Exception as e:
            logging.error(f"æ·»åŠ æ­·å²è¨˜éŒ„éŒ¯èª¤: {str(e)}")
    
    def get_crossing_count(self) -> int:
        """ç²å–ç©¿è¶Šè¨ˆæ•¸"""
        return self.crossing_counter
    
    def get_tracking_stats(self) -> Dict[str, Any]:
        """ç²å–è¿½è¹¤çµ±è¨ˆä¿¡æ¯ (ç”¨æ–¼èª¿è©¦)"""
        active_tracks = len(self.object_tracks)
        lost_tracks_count = len(self.lost_tracks)  # ğŸ”§ æ–°å¢å¤±å»è¿½è¹¤çµ±è¨ˆ
        counted_tracks = sum(1 for track in self.object_tracks.values() if track.get('counted', False))
        
        return {
            'crossing_count': self.crossing_counter,
            'active_tracks': active_tracks,
            'lost_tracks': lost_tracks_count,  # ğŸ”§ æ–°å¢lost_tracksçµ±è¨ˆ
            'counted_tracks': counted_tracks,
            'frame_count': self.current_frame_count,
            'roi_height': self.roi_height,
            'roi_position': self.roi_position_ratio,
            'history_length': len(self.counted_objects_history),
            'accuracy_features': {
                'min_track_frames': self.min_track_frames,
                'confidence_threshold': self.confidence_threshold,
                'duplicate_prevention': True,
                'track_recovery_enabled': True,  # ğŸ”§ æ–°å¢è¿½è¹¤æ¢å¾©åŠŸèƒ½æ¨™è¨˜
                'temporal_tolerance': self.temporal_tolerance
            }
        }
    
    def get_accuracy_metrics(self) -> Dict[str, Any]:
        """ç²å–æº–ç¢ºç‡ç›¸é—œæŒ‡æ¨™"""
        return {
            'total_crossings': self.crossing_counter,
            'confidence_threshold': self.confidence_threshold,
            'min_tracking_frames': self.min_track_frames,
            'duplicate_prevention_enabled': True,
            'history_buffer_size': len(self.counted_objects_history),
            'roi_optimization': {
                'height': self.roi_height,
                'position': self.roi_position_ratio,
                'coverage_threshold': self.crossing_threshold
            }
        }
    
    def reset_crossing_count(self):
        """é‡ç½®ç©¿è¶Šè¨ˆæ•¸"""
        self.crossing_counter = 0
        self.object_tracks = {}
        self.lost_tracks = {}  # ğŸ”§ é‡ç½®å¤±å»çš„è¿½è¹¤
        self.spatial_grid = {}  # ğŸ”§ é‡ç½®ç©ºé–“ç¶²æ ¼
        self.current_frame_count = 0
        self.total_processed_frames = 0  # ğŸ¯ é‡ç½®ç¸½å¹€æ•¸è¨ˆæ•¸å™¨
        self.debug_frame_counter = 0     # ğŸ¯ é‡ç½®èª¿è©¦åœ–ç‰‡è¨ˆæ•¸å™¨
        self.counted_objects_history = []  # æ¸…ç†æ­·å²è¨˜éŒ„
        # ğŸ§  ä¿ç•™å¤§å°çµ±è¨ˆæ¨¡å‹ï¼ˆä¸é‡ç½®ï¼Œç¹¼çºŒå­¸ç¿’ï¼‰
        logging.info("ğŸ”„ ç©¿è¶Šè¨ˆæ•¸ã€è¿½è¹¤ã€å¤±å»è¿½è¹¤ã€ç¶²æ ¼ã€æ­·å²è¨˜éŒ„å’Œèª¿è©¦è¨ˆæ•¸å™¨å·²é‡ç½®")
    
    def set_video_info(self, total_frames: int, fps: float = 206):
        """è¨­å®šå½±ç‰‡ä¿¡æ¯ï¼Œç”¨æ–¼å‹•æ…‹è¨ˆç®—ä¸­é–“æ®µ"""
        self.total_video_frames = total_frames
        
        # è¨ˆç®—ä¸­é–“æ®µçš„é–‹å§‹å’ŒçµæŸå¹€
        start_frame = int(total_frames * self.skip_start_ratio)
        end_frame = int(total_frames * (self.skip_start_ratio + self.save_middle_ratio))
        
        duration_sec = total_frames / fps
        start_time = start_frame / fps
        end_time = end_frame / fps
        
        # ğŸš€ğŸš€ 206fpsæ¨¡å¼ï¼šç°¡åŒ–å½±ç‰‡ä¿¡æ¯æ—¥èªŒ
        logging.info(f"ğŸ¬ å½±ç‰‡: {total_frames}å¹€, {fps:.1f}fps")
        
        # ğŸ¯ å¦‚æœè¨­å®šäº†è‡ªå®šç¾©èµ·å§‹å¹€ï¼Œè¨˜éŒ„ç›¸é—œä¿¡æ¯
        if self.custom_start_frame is not None:
            custom_time = self.custom_start_frame / fps
            logging.info(f"ğŸ“¸ è‡ªå®šç¾©èµ·å§‹ä¿å­˜å¹€: {self.custom_start_frame} (æ™‚é–“: {custom_time:.1f}ç§’)")
    
    def _is_in_save_window(self) -> bool:
        """æª¢æŸ¥ç•¶å‰æ˜¯å¦åœ¨ä¿å­˜çª—å£å…§ï¼ˆå½±ç‰‡ä¸­é–“æ®µæˆ–è‡ªå®šç¾©èµ·å§‹å¹€ï¼‰"""
        # ğŸ¯ å„ªå…ˆä½¿ç”¨è‡ªå®šç¾©èµ·å§‹å¹€
        if self.custom_start_frame is not None:
            return self.total_processed_frames >= self.custom_start_frame
        
        if self.total_video_frames is None:
            # å¦‚æœæ²’æœ‰è¨­å®šå½±ç‰‡ç¸½å¹€æ•¸ï¼Œä½¿ç”¨èˆŠé‚è¼¯
            return self.total_processed_frames > 100  # ç°¡å–®è·³éå‰100å¹€
        
        start_frame = int(self.total_video_frames * self.skip_start_ratio)
        end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
        
        return start_frame <= self.total_processed_frames <= end_frame
    
    def get_debug_status(self) -> Dict[str, Any]:
        """ç²å–èª¿è©¦ç‹€æ…‹ä¿¡æ¯"""
        if self.total_video_frames is not None:
            start_frame = int(self.total_video_frames * self.skip_start_ratio)
            end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
            
            return {
                'total_processed_frames': self.total_processed_frames,
                'total_video_frames': self.total_video_frames,
                'save_start_frame': start_frame,
                'save_end_frame': end_frame,
                'debug_frame_counter': self.debug_frame_counter,
                'max_debug_frames': self.max_debug_frames,
                'is_in_save_window': self._is_in_save_window(),
                'save_progress': f"{self.total_processed_frames - start_frame}/{end_frame - start_frame}" if self._is_in_save_window() else "æœªåœ¨ä¿å­˜çª—å£å…§"
            }
        else:
            return {
                'total_processed_frames': self.total_processed_frames,
                'total_video_frames': None,
                'debug_frame_counter': self.debug_frame_counter,
                'max_debug_frames': self.max_debug_frames,
                'is_in_save_window': self.total_processed_frames > 100,
                'note': 'æœªè¨­å®šå½±ç‰‡ç¸½å¹€æ•¸ï¼Œä½¿ç”¨ç°¡åŒ–é‚è¼¯'
            }
    
    def get_roi_info(self) -> Dict[str, Any]:
        """ç²å–ROIå€åŸŸä¿¡æ¯"""
        return {
            'enabled': self.roi_enabled,
            'y': getattr(self, 'current_roi_y', 0),
            'height': self.roi_height,
            'width': self.frame_width,
            'position_ratio': self.roi_position_ratio
        }
    
    def set_roi_position(self, position_ratio: float):
        """è¨­ç½®ROIä½ç½®æ¯”ä¾‹"""
        self.roi_position_ratio = max(0.0, min(1.0, position_ratio))
        logging.info(f"ğŸ¯ ROIä½ç½®å·²æ›´æ–°: {self.roi_position_ratio:.2f}")
    
    def reset_background_model(self):
        """é‡ç½®èƒŒæ™¯æ¨¡å‹ - ç”¨æ–¼åˆ‡æ›è¦–é »æˆ–é‡æ–°é–‹å§‹è¨ˆæ•¸"""
        self._reset_background_subtractor()
        self.reset_crossing_count()
        logging.info("ğŸ”„ èƒŒæ™¯æ¨¡å‹å’Œè¨ˆæ•¸å·²é‡ç½®")
    
    def set_parameters(self, params: Dict[str, Any]) -> bool:
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        try:
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
                    logging.debug(f"æ›´æ–°èƒŒæ™¯æ¸›é™¤æª¢æ¸¬åƒæ•¸ {key}: {value}")
            
            # å¦‚æœæ›´æ–°äº†èƒŒæ™¯æ¸›é™¤å™¨ç›¸é—œåƒæ•¸ï¼Œéœ€è¦é‡ç½®
            bg_params = ['bg_history', 'bg_var_threshold', 'detect_shadows']
            if any(param in params for param in bg_params):
                self._reset_background_subtractor()
                
            return True
        except Exception as e:
            logging.error(f"è¨­ç½®èƒŒæ™¯æ¸›é™¤æª¢æ¸¬åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False
    
    def _validate_object_size(self, area: int, min_area: int, max_area: int) -> bool:
        """ğŸ”§ ç‰©ä»¶å¤§å°é©—è­‰ - æ¸›å°‘å™ªé»èª¤æª¢åŒæ™‚ä¿ç•™çœŸå¯¦å°é›¶ä»¶"""
        try:
            # åŸºæœ¬é¢ç©æª¢æŸ¥
            if area < min_area:
                return False
                
            # å‹•æ…‹ä¸Šé™æª¢æŸ¥ï¼šå…è¨±åˆç†ç¯„åœå…§çš„å¤§ç‰©ä»¶
            # å°æ–¼å°é›¶ä»¶ç³»çµ±ï¼Œè¨­å®šè¼ƒç‚ºå¯¬é¬†ä½†æœ‰ç•Œçš„ä¸Šé™
            reasonable_max_area = max_area if max_area and max_area > 0 else 500
            
            # å¦‚æœç‰©ä»¶éå¤§ï¼Œå¯èƒ½æ˜¯ç²˜é€£æˆ–èƒŒæ™¯å™ªé»
            if area > reasonable_max_area:
                logging.debug(f"ğŸš« ç‰©ä»¶é¢ç©éå¤§: {area} > {reasonable_max_area}")
                return False
                
            # éå°ç‰©ä»¶å¯èƒ½æ˜¯å™ªé»
            if area < 10:  # æ¥µå°å™ªé»éæ¿¾
                logging.debug(f"ğŸš« ç‰©ä»¶é¢ç©éå°: {area} < 10")
                return False
                
            return True
            
        except Exception as e:
            logging.error(f"ç‰©ä»¶å¤§å°é©—è­‰éŒ¯èª¤: {str(e)}")
            return True  # ç™¼ç”ŸéŒ¯èª¤æ™‚é è¨­æ¥å—ï¼Œé¿å…ç³»çµ±ä¸­æ–·
    
    # ğŸ§¹ å·²ç§»é™¤ä¸éœ€è¦çš„çµ±è¨ˆå’Œè‡ªé©æ‡‰å‡½æ•¸ï¼Œå°ˆæ³¨æ–¼æ ¸å¿ƒæª¢æ¸¬
    
    def _save_composite_debug_image(self, original_frame, roi_region, fg_mask, combined_mask, final_processed, detected_objects):
        """ä¿å­˜åˆæˆèª¿è©¦åœ–ç‰‡ - å°‡æ‰€æœ‰åˆ†æéšæ®µåˆä½µç‚ºä¸€å¼µå¤§åœ–"""
        try:
            import os
            import time
            from datetime import datetime
            
            # åˆå§‹åŒ–æœƒè©±è³‡æ–™å¤¾ (åªåœ¨ç¬¬ä¸€æ¬¡æ™‚å‰µå»º)
            if self.current_session_dir is None:
                now = datetime.now()
                session_folder = now.strftime("%Y%m%d_%H%M%S")
                self.current_session_dir = os.path.join(self.debug_save_dir, f"composite_{session_folder}")
                
                # ç¢ºä¿ç›®éŒ„å­˜åœ¨
                os.makedirs(self.current_session_dir, exist_ok=True)
                
                # å‰µå»ºç•¶å‰æœƒè©±çš„è³‡è¨Šæª”æ¡ˆ
                info_file = os.path.join(self.current_session_dir, "session_info.txt")
                with open(info_file, 'w', encoding='utf-8') as f:
                    f.write(f"ğŸ¯ åˆæˆèª¿è©¦æœƒè©±é–‹å§‹æ™‚é–“: {now.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æª¢æ¸¬æ–¹æ³•: èƒŒæ™¯æ¸›é™¤æª¢æ¸¬ (åˆæˆåœ–ç‰‡æ¨¡å¼)\n")
                    f.write(f"ROIé«˜åº¦: {self.roi_height}px\n")
                    f.write(f"ROIä½ç½®æ¯”ä¾‹: {self.roi_position_ratio}\n")
                    f.write(f"æœ€å¤§èª¿è©¦å¹€æ•¸: {self.max_debug_frames}\n")
                    f.write(f"åœ–ç‰‡æ ¼å¼: 3x2åˆæˆå¸ƒå±€\n\n")
                
                logging.info(f"ğŸ–¼ï¸ é–‹å§‹æ–°çš„åˆæˆèª¿è©¦æœƒè©±: {self.current_session_dir}")
            
            timestamp = int(time.time() * 1000)
            frame_id = f"{self.debug_frame_counter:04d}_{timestamp}"
            
            # ğŸ¨ å‰µå»ºåˆæˆåœ–ç‰‡å¸ƒå±€ (3åˆ— x 2è¡Œ)
            # æº–å‚™å„å€‹åœ–ç‰‡çµ„ä»¶
            
            # 1. åŸå§‹åœ–ç‰‡ (å¸¶ROIæ¨™è¨˜)
            original_with_roi = original_frame.copy()
            roi_y = int(self.frame_height * self.roi_position_ratio)
            cv2.rectangle(original_with_roi, (0, roi_y), 
                         (self.frame_width, roi_y + self.roi_height), (0, 255, 0), 3)
            cv2.putText(original_with_roi, f"ROI ({self.roi_height}px)", 
                       (10, roi_y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # 2. ROIå€åŸŸ (å½©è‰²)
            roi_color = roi_region.copy()
            if len(roi_color.shape) == 2:
                roi_color = cv2.cvtColor(roi_color, cv2.COLOR_GRAY2BGR)
            
            # 3. å‰æ™¯é®ç½© (è½‰å½©è‰²ä»¥ä¾¿åˆæˆ)
            fg_mask_color = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)
            
            # 4. åˆä½µæª¢æ¸¬çµæœ (è½‰å½©è‰²)
            combined_color = cv2.cvtColor(combined_mask, cv2.COLOR_GRAY2BGR)
            
            # 5. æœ€çµ‚è™•ç†çµæœ (è½‰å½©è‰²)
            final_color = cv2.cvtColor(final_processed, cv2.COLOR_GRAY2BGR)
            
            # 6. æª¢æ¸¬çµæœåœ– (åœ¨ROIä¸Šç¹ªè£½æª¢æ¸¬æ¡†)
            detection_result = roi_color.copy()
            if detected_objects:
                for obj in detected_objects:
                    x, y, w, h, centroid, area, radius = obj
                    # è½‰æ›å›ROIåº§æ¨™
                    roi_y_offset = int(self.frame_height * self.roi_position_ratio)
                    local_y = y - roi_y_offset
                    local_centroid = (centroid[0], centroid[1] - roi_y_offset)
                    
                    if 0 <= local_y < self.roi_height and 0 <= local_centroid[1] < self.roi_height:
                        # ç¹ªè£½é‚Šç•Œæ¡†
                        cv2.rectangle(detection_result, (x, local_y), (x + w, local_y + h), (0, 255, 0), 2)
                        # ç¹ªè£½ä¸­å¿ƒé»
                        cv2.circle(detection_result, local_centroid, 4, (255, 0, 0), -1)
                        # æ¨™è¨»é¢ç©
                        cv2.putText(detection_result, f'{int(area)}', 
                                   (x, max(5, local_y - 8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            # ğŸ—ï¸ èª¿æ•´æ‰€æœ‰åœ–ç‰‡åˆ°çµ±ä¸€å°ºå¯¸
            target_height = 300  # çµ±ä¸€é«˜åº¦
            target_width = 400   # çµ±ä¸€å¯¬åº¦
            
            def resize_and_pad(img, target_h, target_w):
                """èª¿æ•´åœ–ç‰‡å°ºå¯¸åˆ°å›ºå®šå°ºå¯¸ä¸¦ä¿æŒæ¯”ä¾‹"""
                h, w = img.shape[:2]
                
                # ğŸ”§ ç¢ºä¿åœ–åƒæ˜¯ä¸‰é€šé“çš„
                if len(img.shape) == 2:  # å–®é€šé“åœ–åƒ
                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                elif len(img.shape) == 3 and img.shape[2] == 1:  # å–®é€šé“ä½†æœ‰ç¬¬ä¸‰ç¶­
                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                elif len(img.shape) == 3 and img.shape[2] == 4:  # RGBAåœ–åƒ
                    img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)
                
                # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œä¿æŒåœ–ç‰‡æ¯”ä¾‹
                scale_h = target_h / h
                scale_w = target_w / w
                scale = min(scale_h, scale_w)  # ä½¿ç”¨è¼ƒå°çš„ç¸®æ”¾æ¯”ä¾‹ä¿æŒæ¯”ä¾‹
                
                new_h = int(h * scale)
                new_w = int(w * scale)
                
                # ç¸®æ”¾åœ–ç‰‡
                resized = cv2.resize(img, (new_w, new_h))
                
                # ğŸ”§ å†æ¬¡ç¢ºä¿ç¸®æ”¾å¾Œçš„åœ–åƒæ˜¯ä¸‰é€šé“çš„
                if len(resized.shape) == 2:
                    resized = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                
                # å‰µå»ºå›ºå®šå°ºå¯¸çš„ç•«å¸ƒ
                canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
                
                # è¨ˆç®—å±…ä¸­ä½ç½®
                start_y = (target_h - new_h) // 2
                start_x = (target_w - new_w) // 2
                
                # å°‡ç¸®æ”¾å¾Œçš„åœ–ç‰‡æ”¾åˆ°ç•«å¸ƒä¸­å¤®
                canvas[start_y:start_y+new_h, start_x:start_x+new_w] = resized
                
                return canvas
            
            # èª¿æ•´æ‰€æœ‰åœ–ç‰‡å°ºå¯¸
            img1 = resize_and_pad(original_with_roi, target_height, target_width)
            img2 = resize_and_pad(roi_color, target_height, target_width)
            img3 = resize_and_pad(fg_mask_color, target_height, target_width)
            img4 = resize_and_pad(combined_color, target_height, target_width)
            img5 = resize_and_pad(final_color, target_height, target_width)
            img6 = resize_and_pad(detection_result, target_height, target_width)
            
            # æ·»åŠ æ¨™é¡Œæ–‡å­—
            def add_title(img, title, bg_color=(0, 0, 0)):
                """åœ¨åœ–ç‰‡é ‚éƒ¨æ·»åŠ æ¨™é¡Œ"""
                h, w = img.shape[:2]
                title_height = 40
                titled_img = np.full((h + title_height, w, 3), bg_color, dtype=np.uint8)
                titled_img[title_height:, :] = img
                
                # æ·»åŠ æ¨™é¡Œæ–‡å­—
                cv2.putText(titled_img, title, (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                return titled_img
            
            # ç‚ºæ¯å¼µåœ–ç‰‡æ·»åŠ æ¨™é¡Œ
            img1_titled = add_title(img1, "1. Original + ROI")
            img2_titled = add_title(img2, "2. ROI Region")  
            img3_titled = add_title(img3, "3. Foreground Mask")
            img4_titled = add_title(img4, "4. Combined Detection")
            img5_titled = add_title(img5, "5. Final Processed")
            img6_titled = add_title(img6, f"6. Objects ({len(detected_objects)})")
            
            # ğŸ–¼ï¸ åˆæˆæœ€çµ‚åœ–ç‰‡ (3x2å¸ƒå±€)
            # ç¬¬ä¸€è¡Œ
            row1 = np.hstack([img1_titled, img2_titled, img3_titled])
            # ç¬¬äºŒè¡Œ  
            row2 = np.hstack([img4_titled, img5_titled, img6_titled])
            
            # åˆä½µå…©è¡Œ
            composite_img = np.vstack([row1, row2])
            
            # ğŸ·ï¸ æ·»åŠ åº•éƒ¨åƒæ•¸ä¿¡æ¯ - è©³ç´°é…ç½®
            info_height = 160  # å¢åŠ é«˜åº¦ä»¥å®¹ç´æ›´å¤šåƒæ•¸ä¿¡æ¯
            info_panel = np.zeros((info_height, composite_img.shape[1], 3), dtype=np.uint8)
            
            # è©³ç´°åƒæ•¸æ–‡å­—ä¿¡æ¯
            params_text = [
                f"Frame: {self.debug_frame_counter:04d} | Count: {self.crossing_counter} | Objects: {len(detected_objects)} | Total Processed: {self.total_processed_frames}",
                f"ROI: {self.roi_height}px @ {self.roi_position_ratio:.2f} | MinArea: {self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area} | MaxArea: {self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area}",
                f"BG Threshold: {self.high_speed_bg_var_threshold if self.ultra_high_speed_mode else self.bg_var_threshold} | Binary: {self.high_speed_binary_threshold if self.ultra_high_speed_mode else self.binary_threshold} | Canny: {self.canny_low_threshold}-{self.canny_high_threshold}",
                f"Shape Filter - Aspect: >{getattr(self, 'min_aspect_ratio', 0.01):.2f} | Extent: >{getattr(self, 'min_extent', 0.02):.2f} | Solidity: >{getattr(self, 'min_solidity', 0.01):.2f}",
                f"Morph - Opening: {getattr(self, 'opening_kernel_size', (2, 2))} x{getattr(self, 'opening_iterations', 1)} | Closing: {getattr(self, 'closing_kernel_size', (3, 3))} x{getattr(self, 'closing_iterations', 1)}",
                f"Time: {datetime.fromtimestamp(timestamp/1000).strftime('%H:%M:%S.%f')[:-3]} | Gaussian Blur: {self.gaussian_blur_kernel}"
            ]
            
            # åœ¨ä¿¡æ¯é¢æ¿ä¸Šæ·»åŠ æ–‡å­—
            for i, text in enumerate(params_text):
                y_pos = 20 + i * 22  # èª¿æ•´è¡Œé–“è·ä»¥é©æ‡‰æ›´å¤šåƒæ•¸
                cv2.putText(info_panel, text, (10, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1)  # ç¨å°å­—é«”ä»¥å®¹ç´æ›´å¤šä¿¡æ¯
            
            # åˆä½µä¿¡æ¯é¢æ¿
            final_composite = np.vstack([composite_img, info_panel])
            
            # ğŸ’¾ ä¿å­˜åˆæˆåœ–ç‰‡ - å¼·åŒ–éŒ¯èª¤è™•ç†å’Œæ ¼å¼æª¢æŸ¥
            save_path = f"{self.current_session_dir}/composite_debug_{frame_id}.jpg"
            try:
                # æª¢æŸ¥åœ–ç‰‡æ•¸æ“šå®Œæ•´æ€§
                if final_composite is None or final_composite.size == 0:
                    logging.error(f"ğŸš« åˆæˆåœ–ç‰‡æ•¸æ“šç„¡æ•ˆ")
                    return
                
                # ç¢ºä¿ç›®éŒ„å­˜åœ¨
                import os
                os.makedirs(self.current_session_dir, exist_ok=True)
                
                # å˜—è©¦ä¿å­˜ç‚ºJPG
                success = cv2.imwrite(save_path, final_composite, [cv2.IMWRITE_JPEG_QUALITY, 95])
                if not success:
                    # å˜—è©¦ä¿å­˜ç‚ºPNG
                    png_path = save_path.replace('.jpg', '.png')
                    success = cv2.imwrite(png_path, final_composite)
                    if success:
                        logging.info(f"âœ… ä¿å­˜ç‚ºPNG: {png_path}")
                    else:
                        logging.error(f"ğŸš« JPGå’ŒPNGæ ¼å¼éƒ½ä¿å­˜å¤±æ•—: {save_path}")
                else:
                    logging.debug(f"âœ… JPGä¿å­˜æˆåŠŸ: {save_path}")
                    
            except Exception as e:
                logging.error(f"ğŸš« èª¿è©¦åœ–ç‰‡ä¿å­˜ç•°å¸¸: {save_path}, éŒ¯èª¤: {str(e)}")
                import traceback
                logging.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            
            # ğŸ“Š æ¯50å¹€è¨˜éŒ„ä¸€æ¬¡é€²åº¦
            if self.debug_frame_counter % 50 == 0:
                logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡å·²ä¿å­˜ {self.debug_frame_counter}/{self.max_debug_frames}")
            
        except Exception as e:
            logging.error(f"ä¿å­˜åˆæˆèª¿è©¦åœ–ç‰‡éŒ¯èª¤: {str(e)}")
    
    def _check_manual_trigger_file(self):
        """æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶"""
        try:
            from pathlib import Path
            trigger_file = Path("/tmp/basler_debug_trigger.txt")
            
            if trigger_file.exists():
                # è®€å–è§¸ç™¼ä¿¡è™Ÿ
                trigger_content = trigger_file.read_text().strip()
                if trigger_content.startswith("TRIGGER_"):
                    # å¼·åˆ¶å•Ÿç”¨èª¿è©¦ä¿å­˜
                    self.manual_trigger_active = True
                    logging.info(f"ğŸ“¸ æª¢æ¸¬åˆ°æ‰‹å‹•è§¸ç™¼ä¿¡è™Ÿ: {trigger_content}")
                    
                    # åˆªé™¤è§¸ç™¼æ–‡ä»¶
                    trigger_file.unlink()
                    
        except Exception as e:
            logging.debug(f"æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶éŒ¯èª¤: {str(e)}")
    
    def enable_debug_save(self, enabled: bool = True):
        """å•Ÿç”¨æˆ–ç¦ç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜"""
        self.debug_save_enabled = enabled
        if enabled:
            self.debug_frame_counter = 0  # é‡ç½®è¨ˆæ•¸å™¨
            logging.info("ğŸ“¸ èª¿è©¦åœ–ç‰‡ä¿å­˜å·²å•Ÿç”¨")
        else:
            logging.info("ğŸ“¸ èª¿è©¦åœ–ç‰‡ä¿å­˜å·²ç¦ç”¨")
    
    def get_debug_info(self) -> Dict[str, Any]:
        """ç²å–èª¿è©¦ä¿¡æ¯"""
        return {
            'debug_enabled': self.debug_save_enabled,
            'frames_saved': self.debug_frame_counter,
            'max_frames': self.max_debug_frames,
            'save_directory': self.debug_save_dir,
            'current_session': self.current_session_dir
        }
    
    def trigger_manual_save(self):
        """æ‰‹å‹•è§¸ç™¼ä¿å­˜ç•¶å‰å¹€ - ç”¨æ–¼æ•æ‰ç‰¹å®šç•«é¢"""
        self.manual_save_triggered = True
        logging.info("ğŸ”§ æ‰‹å‹•è§¸ç™¼èª¿è©¦åœ–ç‰‡ä¿å­˜")
    
    def get_ultra_high_speed_status(self) -> Dict[str, Any]:
        """ç²å–è¶…é«˜é€Ÿæ¨¡å¼ç‹€æ…‹"""
        return {
            'enabled': self.ultra_high_speed_mode,
            'target_fps': self.target_fps,
            'current_params': {
                'bg_history': self.high_speed_bg_history if self.ultra_high_speed_mode else self.bg_history,
                'bg_var_threshold': self.high_speed_bg_var_threshold if self.ultra_high_speed_mode else self.bg_var_threshold,
                'min_area': self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area,
                'max_area': self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area,
            },
            'optimizations': {
                'shape_filtering_disabled': self.ultra_high_speed_mode,
                'debug_disabled': self.ultra_high_speed_mode,
                'simplified_tracking': self.ultra_high_speed_mode,
                'reduced_logging': self.ultra_high_speed_mode
            }
        }

    def enable_composite_debug(self, enabled: bool = True, mode: str = "playback"):
        """å•Ÿç”¨æˆ–ç¦ç”¨åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜"""
        # ğŸ¯ åªåœ¨è¦–é »å›æ”¾æ¨¡å¼ä¸‹å…è¨±èª¿è©¦åœ–ç‰‡ä¿å­˜
        if mode in ["live", "recording"]:
            self.composite_debug_enabled = False
            self.debug_save_enabled = False
            logging.info(f"ğŸ–¼ï¸ {mode}æ¨¡å¼ä¸‹è‡ªå‹•ç¦ç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜ï¼ˆæ€§èƒ½å„ªåŒ–ï¼‰")
            return
            
        self.composite_debug_enabled = enabled
        self.debug_save_enabled = enabled
        
        if enabled:
            self.debug_frame_counter = 0  # é‡ç½®è¨ˆæ•¸å™¨
            self.current_session_dir = None  # é‡ç½®æœƒè©±ç›®éŒ„
            logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜å·²å•Ÿç”¨ (æ¨¡å¼: {mode})")
        else:
            logging.info("ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜å·²ç¦ç”¨")

    def get_composite_debug_info(self) -> Dict[str, Any]:
        """ç²å–åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜ä¿¡æ¯"""
        return {
            'enabled': self.composite_debug_enabled,
            'frames_saved': self.debug_frame_counter,
            'max_frames': self.max_debug_frames,
            'save_directory': self.debug_save_dir,
            'current_session': self.current_session_dir,
            'progress_percentage': self.debug_frame_counter,  # é¡¯ç¤ºå·²ä¿å­˜æ•¸é‡ï¼Œç„¡é™åˆ¶æ¨¡å¼
            'layout': '3x2 composite layout with annotations',
            'custom_start_frame': self.custom_start_frame
        }
    
    def set_custom_start_frame(self, start_frame: int):
        """è¨­å®šè‡ªå®šç¾©èµ·å§‹ä¿å­˜å¹€ï¼ˆä¾‹å¦‚2500ï¼‰"""
        self.custom_start_frame = start_frame
        logging.info(f"ğŸ¯ å·²è¨­å®šè‡ªå®šç¾©èµ·å§‹ä¿å­˜å¹€: {start_frame}")
    
    def clear_custom_start_frame(self):
        """æ¸…é™¤è‡ªå®šç¾©èµ·å§‹å¹€ï¼Œæ¢å¾©ä½¿ç”¨æ¯”ä¾‹è¨ˆç®—"""
        self.custom_start_frame = None
        logging.info("ğŸ”„ å·²æ¸…é™¤è‡ªå®šç¾©èµ·å§‹å¹€ï¼Œæ¢å¾©ä½¿ç”¨æ¯”ä¾‹è¨ˆç®—")
    
    def cleanup_early_debug_images(self, before_frame: int = None):
        """æ¸…ç†æŒ‡å®šå¹€æ•¸ä¹‹å‰çš„èª¿è©¦åœ–ç‰‡"""
        try:
            import os
            import glob
            from pathlib import Path
            
            if before_frame is None:
                before_frame = self.custom_start_frame or 2500
                
            if not os.path.exists(self.debug_save_dir):
                logging.info(f"ğŸ“ èª¿è©¦ç›®éŒ„ä¸å­˜åœ¨: {self.debug_save_dir}")
                return 0
            
            # æ‰¾åˆ°æ‰€æœ‰èª¿è©¦åœ–ç‰‡
            pattern = os.path.join(self.debug_save_dir, "**", "composite_debug_*.jpg")
            all_debug_files = glob.glob(pattern, recursive=True)
            
            deleted_count = 0
            for file_path in all_debug_files:
                try:
                    # å¾æ–‡ä»¶åæå–å¹€è™Ÿ (composite_debug_XXXX_timestamp.jpg)
                    filename = os.path.basename(file_path)
                    if filename.startswith("composite_debug_"):
                        # æå–å¹€è™Ÿ
                        frame_part = filename.split("_")[2]  # composite_debug_XXXX_timestamp.jpg
                        frame_number = int(frame_part)
                        
                        if frame_number < before_frame:
                            os.remove(file_path)
                            deleted_count += 1
                            
                except (ValueError, IndexError, OSError) as e:
                    logging.debug(f"è·³éæ–‡ä»¶ {file_path}: {str(e)}")
                    continue
            
            logging.info(f"ğŸ—‘ï¸ å·²æ¸…ç† {deleted_count} å€‹ç¬¬{before_frame}å¹€ä¹‹å‰çš„èª¿è©¦åœ–ç‰‡")
            return deleted_count
            
        except Exception as e:
            logging.error(f"æ¸…ç†æ—©æœŸèª¿è©¦åœ–ç‰‡éŒ¯èª¤: {str(e)}")
            return 0

    def _separate_clustered_components(self, frame, labels, component_id, x, y, w, h, area):
        """
        åˆ†æ°´å¶ºç®—æ³•åˆ†é›¢ç²˜é€£çš„å°é›¶ä»¶
        
        Args:
            frame: è™•ç†å¾Œçš„äºŒå€¼åœ–åƒ
            labels: é€£é€šçµ„ä»¶æ¨™ç±¤åœ–åƒ
            component_id: ç•¶å‰çµ„ä»¶ID
            x, y, w, h: çµ„ä»¶çš„é‚Šç•Œæ¡†
            area: çµ„ä»¶é¢ç©
            
        Returns:
            List of separated objects: [(x, y, w, h, area, radius), ...]
        """
        try:
            # æå–ç•¶å‰çµ„ä»¶çš„å€åŸŸ
            component_mask = (labels == component_id).astype(np.uint8) * 255
            
            # æå–çµ„ä»¶å€åŸŸ
            roi = component_mask[y:y+h, x:x+w]
            if roi.size == 0:
                return []
            
            # ğŸ”§ æ™ºèƒ½ä¼°ç®—é æœŸé›¶ä»¶æ•¸é‡
            if self.size_statistics['sample_count'] >= self.min_samples_for_stats:
                # ä½¿ç”¨çµ±è¨ˆæ¨¡å‹ä¼°ç®—
                expected_components = self._estimate_component_count(area)
            else:
                # çµ±è¨ˆä¸è¶³æ™‚çš„ä¿å®ˆä¼°ç®—
                expected_components = max(2, min(4, int(area / 200)))  # é™åˆ¶åœ¨2-4å€‹ä¹‹é–“
            
            # ğŸ”§ æ”¹é€²çš„è·é›¢è®Šæ›å’Œç¨®å­é»æª¢æ¸¬
            dist_transform = cv2.distanceTransform(roi, cv2.DIST_L2, 3)  # ä½¿ç”¨è¼ƒå°çš„mask
            
            # ğŸ”§ è‡ªé©æ‡‰å³°å€¼æª¢æ¸¬
            # å°æ–¼å°é›¶ä»¶ï¼Œä½¿ç”¨è¼ƒå°çš„å½¢æ…‹å­¸æ ¸å¿ƒ
            kernel_size = 2 if area < 400 else 3
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            local_maxima = cv2.morphologyEx(dist_transform, cv2.MORPH_OPEN, kernel)
            
            # ğŸ”§ è‡ªé©æ‡‰é–¾å€¼è¨­å®š
            # å°æ–¼å°é›¶ä»¶ä½¿ç”¨è¼ƒä½çš„é–¾å€¼
            threshold_ratio = 0.4 if area < 400 else 0.3
            sure_fg = np.uint8(local_maxima > threshold_ratio * dist_transform.max())
            
            # ğŸ”§ é€²ä¸€æ­¥éæ¿¾ï¼šç§»é™¤éå°çš„ç¨®å­é»
            if area < 400:
                # å°å°é›¶ä»¶ï¼Œç¢ºä¿ç¨®å­é»æœ‰æœ€å°å¤§å°
                seed_kernel = np.ones((2, 2), np.uint8)
                sure_fg = cv2.morphologyEx(sure_fg, cv2.MORPH_OPEN, seed_kernel)
            
            # æ¨™è¨˜ç¨®å­é»
            _, markers = cv2.connectedComponents(sure_fg)
            
            # ğŸ”§ æ”¹é€²çš„ç¨®å­é»é©—è­‰é‚è¼¯
            num_seeds = markers.max()
            seeds_reasonable = (num_seeds >= 2 and num_seeds <= expected_components + 1)
            
            logging.debug(f"ğŸ”§ åˆ†é›¢åˆ†æ: é¢ç©={area}, ç¨®å­é»={num_seeds}, æœŸæœ›çµ„ä»¶={expected_components}, åˆç†={seeds_reasonable}")
            
            if seeds_reasonable:
                # ç‚ºåˆ†æ°´å¶ºç®—æ³•æº–å‚™åœ–åƒ
                if len(roi.shape) == 2:
                    roi_3ch = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)
                else:
                    roi_3ch = roi
                
                # åŸ·è¡Œåˆ†æ°´å¶ºç®—æ³•
                markers = cv2.watershed(roi_3ch, markers)
                
                # æå–åˆ†é›¢å¾Œçš„çµ„ä»¶
                separated_objects = []
                for label_id in range(2, markers.max() + 1):  # è·³éèƒŒæ™¯(0)å’Œé‚Šç•Œ(-1,1)
                    mask = (markers == label_id).astype(np.uint8)
                    
                    # æ‰¾åˆ°è¼ªå»“
                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    if contours:
                        cnt = max(contours, key=cv2.contourArea)
                        sep_area = cv2.contourArea(cnt)
                        
                        # ğŸ”§ æ”¹é€²çš„åˆ†é›¢çµ„ä»¶é©—è­‰
                        # è¨­å®šåˆç†çš„æœ€å°é¢ç©ï¼ˆæ¯”æª¢æ¸¬æœ€å°é¢ç©ç¨å¤§ï¼‰
                        min_separated_area = max(self.min_area, 20)
                        if sep_area >= min_separated_area:
                            sep_x, sep_y, sep_w, sep_h = cv2.boundingRect(cnt)
                            # è½‰æ›å›åŸåœ–åæ¨™
                            sep_x += x
                            sep_y += y
                            sep_radius = np.sqrt(sep_area / np.pi)
                            
                            separated_objects.append((sep_x, sep_y, sep_w, sep_h, sep_area, sep_radius))
                
                # ğŸ”§ æ”¹é€²çš„åˆ†é›¢æˆåŠŸé©—è­‰
                total_separated_area = sum(obj[4] for obj in separated_objects)
                area_conservation = 0.7 <= (total_separated_area / area) <= 1.3  # å…è¨±30%çš„é¢ç©è®ŠåŒ–
                
                success_criteria = (
                    len(separated_objects) >= 2 and 
                    len(separated_objects) <= expected_components and
                    area_conservation
                )
                
                if success_criteria:
                    logging.info(f"âœ… æˆåŠŸåˆ†é›¢: åŸé¢ç©={area} -> {len(separated_objects)}å€‹çµ„ä»¶")
                    logging.debug(f"   åˆ†é›¢é¢ç©: {[f'{obj[4]:.0f}' for obj in separated_objects]}, ç¸½é¢ç©æ¯”ä¾‹={total_separated_area/area:.2f}")
                    return separated_objects
                else:
                    logging.debug(f"âŒ åˆ†é›¢é©—è­‰å¤±æ•—: çµ„ä»¶æ•¸={len(separated_objects)}, é¢ç©æ¯”ä¾‹={total_separated_area/area:.2f}")
            else:
                logging.debug(f"âŒ ç¨®å­é»ä¸åˆç†ï¼Œè·³éåˆ†é›¢")
            
            # åˆ†é›¢å¤±æ•—ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []
            
        except Exception as e:
            logging.debug(f"åˆ†é›¢ç®—æ³•éŒ¯èª¤: {str(e)}")
            return []

    def _get_grid_position(self, x: int, y: int) -> Tuple[int, int]:
        """å°‡åƒç´ åº§æ¨™è½‰æ›ç‚ºç¶²æ ¼åº§æ¨™"""
        grid_x = x // self.grid_cell_size
        grid_y = y // self.grid_cell_size
        return (grid_x, grid_y)
    
    def _update_size_statistics(self, area: float):
        """æ›´æ–°é›¶ä»¶å¤§å°çµ±è¨ˆæ¨¡å‹"""
        self.component_sizes.append(area)
        
        # ä¿æŒåˆç†çš„æ¨£æœ¬æ•¸é‡ï¼ˆæœ€å¤š1000å€‹æ¨£æœ¬ï¼‰
        if len(self.component_sizes) > 1000:
            self.component_sizes = self.component_sizes[-1000:]
        
        # å¦‚æœæœ‰è¶³å¤ çš„æ¨£æœ¬ï¼Œè¨ˆç®—çµ±è¨ˆæ•¸æ“š
        if len(self.component_sizes) >= self.min_samples_for_stats:
            import numpy as np
            sizes = np.array(self.component_sizes)
            
            self.size_statistics.update({
                'mean_size': float(np.mean(sizes)),
                'std_size': float(np.std(sizes)),
                'median_size': float(np.median(sizes)),
                'size_range': (float(np.min(sizes)), float(np.max(sizes))),
                'sample_count': len(sizes)
            })
            
            logging.debug(f"ğŸ“Š å¤§å°çµ±è¨ˆæ›´æ–°: å¹³å‡={self.size_statistics['mean_size']:.1f}, æ¨™æº–å·®={self.size_statistics['std_size']:.1f}")
    
    def _is_clustered_component(self, area: float) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºç²˜é€£çš„é›¶ä»¶ï¼ˆåŸºæ–¼å¤§å°çµ±è¨ˆï¼‰"""
        if self.size_statistics['sample_count'] < self.min_samples_for_stats:
            return False  # æ¨£æœ¬ä¸è¶³ï¼Œä¸é€²è¡Œåˆ¤æ–·
            
        mean_size = self.size_statistics['mean_size']
        threshold = mean_size * self.clustering_threshold_ratio
        
        is_clustered = area > threshold
        if is_clustered:
            logging.info(f"ğŸ”— æª¢æ¸¬åˆ°å¯èƒ½çš„ç²˜é€£é›¶ä»¶: é¢ç©={area:.0f} > é–¾å€¼={threshold:.0f} (å¹³å‡å¤§å°={mean_size:.0f})")
        
        return is_clustered
    
    def _estimate_component_count(self, area: float) -> int:
        """æ ¹æ“šé¢ç©ä¼°ç®—ç²˜é€£é›¶ä»¶çš„æ•¸é‡"""
        if self.size_statistics['sample_count'] < self.min_samples_for_stats:
            return 1
            
        mean_size = self.size_statistics['mean_size']
        estimated_count = max(1, round(area / mean_size))
        
        logging.debug(f"ğŸ“ é¢ç©={area:.0f}, å¹³å‡å¤§å°={mean_size:.0f}, ä¼°ç®—æ•¸é‡={estimated_count}")
        return estimated_count
    
    def get_size_statistics(self) -> Dict[str, Any]:
        """ç²å–å¤§å°çµ±è¨ˆä¿¡æ¯"""
        return {
            'statistics': self.size_statistics.copy(),
            'clustering_threshold_ratio': self.clustering_threshold_ratio,
            'grid_cell_size': self.grid_cell_size,
            'position_based_tracking': self.position_based_tracking
        }

    def _generate_predictive_objects(self) -> List[Tuple]:
        """ğŸ§  æ¨æ–·å¼è¿½è¹¤ï¼šæ ¹æ“šç¾æœ‰è¿½è¹¤è»Œè·¡é æ¸¬ç‰©ä»¶ä½ç½®"""
        virtual_objects = []
        
        try:
            current_frame = self.current_frame_count
            
            # åˆ†ææ´»èºè¿½è¹¤å’Œæœ€è¿‘å¤±å»çš„è¿½è¹¤
            all_tracks = {**self.object_tracks, **self.lost_tracks}
            
            for track_id, track in all_tracks.items():
                # æª¢æŸ¥è¿½è¹¤æ˜¯å¦éœ€è¦é æ¸¬
                frames_since_last = current_frame - track['last_frame']
                
                if (1 <= frames_since_last <= self.max_prediction_frames and 
                    len(track.get('positions', [])) >= 2):
                    
                    # ğŸ”® åŸºæ–¼æ­·å²ä½ç½®é æ¸¬ä¸‹ä¸€å€‹ä½ç½®
                    positions = track['positions'][-3:]  # ä½¿ç”¨æœ€è¿‘3å€‹ä½ç½®
                    
                    if len(positions) >= 2:
                        # ç°¡å–®ç·šæ€§é æ¸¬
                        last_pos = positions[-1]
                        prev_pos = positions[-2]
                        
                        # è¨ˆç®—ç§»å‹•å‘é‡
                        dx = last_pos[0] - prev_pos[0]
                        dy = last_pos[1] - prev_pos[1]
                        
                        # é æ¸¬æ–°ä½ç½®
                        predicted_x = int(last_pos[0] + dx * frames_since_last)
                        predicted_y = int(last_pos[1] + dy * frames_since_last)
                        
                        # æª¢æŸ¥é æ¸¬ä½ç½®æ˜¯å¦åœ¨åˆç†ç¯„åœå…§
                        if (0 <= predicted_x < self.frame_width and 
                            0 <= predicted_y < self.frame_height):
                            
                            # ä½¿ç”¨å¹³å‡å°ºå¯¸å‰µå»ºè™›æ“¬ç‰©ä»¶
                            avg_w = track.get('avg_w', 20)
                            avg_h = track.get('avg_h', 20) 
                            avg_area = track.get('avg_area', 300)
                            avg_radius = max(5, int(np.sqrt(avg_area / np.pi)))
                            
                            # å‰µå»ºè™›æ“¬ç‰©ä»¶ (æ ¼å¼èˆ‡çœŸå¯¦æª¢æ¸¬ä¸€è‡´)
                            virtual_obj = (
                                max(0, predicted_x - avg_w//2),  # x
                                max(0, predicted_y - avg_h//2),  # y  
                                avg_w,                           # w
                                avg_h,                           # h
                                (predicted_x, predicted_y),     # centroid
                                avg_area,                        # area
                                avg_radius                       # radius
                            )
                            
                            virtual_objects.append(virtual_obj)
                            
                            logging.debug(f"ğŸ”® ç”Ÿæˆè™›æ“¬ç‰©ä»¶ track_{track_id}: ä½ç½®({predicted_x},{predicted_y}), "
                                        f"ç§»å‹•å‘é‡({dx},{dy}), é æ¸¬å¹€æ•¸={frames_since_last}")
            
            if virtual_objects:
                logging.info(f"ğŸ§  æ¨æ–·å¼è¿½è¹¤: ç”Ÿæˆäº† {len(virtual_objects)} å€‹è™›æ“¬ç‰©ä»¶ç”¨æ–¼è¿½è¹¤é€£çºŒæ€§")
                
        except Exception as e:
            logging.error(f"ç”Ÿæˆé æ¸¬ç‰©ä»¶éŒ¯èª¤: {str(e)}")
        
        return virtual_objects

    @property
    def name(self) -> str:
        return "BackgroundSubtractionDetection"


