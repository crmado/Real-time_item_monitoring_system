#!/usr/bin/env python3
"""
èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³• - åŸºæ–¼å‰å¾Œæ™¯åˆ†æçš„ç‰©ä»¶æª¢æ¸¬å’Œè¨ˆæ•¸
åƒè€ƒ partsCounts_v1.py çš„å¯¦ç¾æ–¹å¼
"""

import cv2
import numpy as np
import logging
from typing import List, Tuple, Optional, Dict, Any
from .detection_base import DetectionMethod


class BackgroundSubtractionDetection(DetectionMethod):
    """
    èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³• - åŸºæ–¼å‰å¾Œæ™¯åˆ†æ
    åƒè€ƒ partsCounts_v1.py çš„é«˜æ•ˆå¯¦ç¾
    """
    
    def __init__(self):
        """åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤æª¢æ¸¬"""
        # ğŸ¯ å¹³è¡¡æª¢æ¸¬ - æ¸›å°‘èª¤åˆ¤ï¼Œä¿æŒæº–ç¢ºæ€§
        self.min_area = 25   # ğŸ”§ æé«˜æœ€å°é¢ç©ï¼Œéæ¿¾é›œè¨Š (8â†’25)  
        self.max_area = 3000 # ğŸ”§ é©ä¸­çš„ä¸Šé™ (4000â†’3000)
        
        # ç‰©ä»¶å½¢ç‹€éæ¿¾åƒæ•¸ - é©åº¦åš´æ ¼ï¼Œæ¸›å°‘é›œè¨Š
        self.min_aspect_ratio = 0.1  # æ›´åˆç†çš„é•·å¯¬æ¯” (0.003â†’0.1)
        self.max_aspect_ratio = 8.0  # é©åº¦é™åˆ¶æ¥µç«¯å½¢ç‹€ (20.0â†’8.0)
        self.min_extent = 0.2        # åˆç†çš„å¡«å……æ¯”ä¾‹è¦æ±‚ (0.0003â†’0.2)
        self.max_solidity = 1.0      # åš´æ ¼çš„çµå¯¦æ€§é™åˆ¶ (3.0â†’1.0)
        
        # ğŸ¯ é©åº¦æ•æ„ŸèƒŒæ™¯æ¸›é™¤ - å¹³è¡¡æª¢æ¸¬èˆ‡é›œè¨Š
        self.bg_history = 700    # å¢åŠ æ­·å²å¹€æ•¸ç©©å®šèƒŒæ™¯ (500â†’700)
        self.bg_var_threshold = 12  # ğŸ”§ æé«˜é–¾å€¼æ¸›å°‘é›œè¨Š (3â†’12)
        self.detect_shadows = False  # é—œé–‰é™°å½±æª¢æ¸¬
        
        # ğŸ¯ ä¿å®ˆé‚Šç·£æª¢æ¸¬ - æ¸›å°‘é›œè¨Šæª¢æ¸¬
        self.gaussian_blur_kernel = (5, 5)  # å¢åŠ æ¨¡ç³Šæ¸›å°‘é›œè¨Š (3â†’5)
        self.canny_low_threshold = 20        # ğŸ”§ æé«˜ä½é–¾å€¼ (8â†’20)
        self.canny_high_threshold = 60       # ğŸ”§ æé«˜é«˜é–¾å€¼ (35â†’60) 
        self.binary_threshold = 15           # ğŸ”§ æé«˜äºŒå€¼åŒ–é–¾å€¼ (5â†’15)
        
        # ğŸ” åŠ å¼·é›œè¨Šéæ¿¾ - ä½¿ç”¨æ›´å¤§çš„å½¢æ…‹å­¸æ ¸
        self.dilate_kernel_size = (3, 3)    # ğŸ”§ é©åº¦çš„æ ¸å¤§å° (2â†’3)
        self.dilate_iterations = 1           # ğŸ”§ ä¿æŒé©åº¦è†¨è„¹
        self.close_kernel_size = (5, 5)     # ğŸ”§ æ›´å¤§çš„æ ¸ï¼Œæ›´å¥½çš„å¡«è£œ (3â†’5)
        
        # ğŸ¯ é¡å¤–çš„é›œè¨Šéæ¿¾
        self.opening_kernel_size = (4, 4)   # ğŸ†• é–‹é‹ç®—æ ¸ï¼Œå»é™¤å°é›œè¨Š
        self.opening_iterations = 2          # ğŸ†• å¤šæ¬¡é–‹é‹ç®—å»å™ª
        
        # é€£é€šçµ„ä»¶åƒæ•¸
        self.connectivity = 4  # 4-é€£é€šæˆ–8-é€£é€š
        
        # ğŸ¯ ROI æª¢æ¸¬å€åŸŸåƒæ•¸ (æ ¹æ“šå½±åƒåˆ†æçµæœå„ªåŒ–)
        self.roi_enabled = True
        self.roi_height = 80  # ROI å€åŸŸé«˜åº¦ (ä¿æŒ80ä»¥æ•ç²å®Œæ•´é›¶ä»¶)
        self.roi_position_ratio = 0.15  # ROI ä½ç½®æ¯”ä¾‹ (èª¿æ•´åˆ°0.15ï¼Œæ›´é è¿‘é ‚éƒ¨)
        self.current_roi_y = 0  # ç•¶å‰ROIçš„Yåº§æ¨™
        
        # ğŸ¯ ç‰©ä»¶è¿½è¹¤å’Œè¨ˆæ•¸åƒæ•¸
        self.enable_crossing_count = True
        self.crossing_tolerance_x = 30  # xæ–¹å‘è¿½è¹¤å®¹å·® (æ¸›å°ä»¥æé«˜ç²¾ç¢ºåº¦)
        self.crossing_tolerance_y = 60  # yæ–¹å‘è¿½è¹¤å®¹å·® (å¢å¤§ä»¥é©æ‡‰ROIé«˜åº¦)
        
        # ğŸ¯ æé«˜è¿½è¹¤ç©©å®šæ€§ - æ¸›å°‘èª¤åˆ¤
        self.track_lifetime = 10  # å¢åŠ è¿½è¹¤é€±æœŸï¼Œæé«˜ç©©å®šæ€§ (5â†’10)
        self.min_track_frames = 3  # éœ€è¦å¤šå¹€ç¢ºèªï¼Œæ¸›å°‘èª¤åˆ¤ (1â†’3)
        self.crossing_threshold = 0.1   # æé«˜ç©¿è¶Šé–¾å€¼ï¼Œæ›´ä¿å®ˆ (0.03â†’0.1)
        self.confidence_threshold = 0.1  # æé«˜ç½®ä¿¡åº¦è¦æ±‚ (0.03â†’0.1)
        
        # ğŸ›¡ï¸ ç°¡åŒ–é˜²é‡è¤‡æ©Ÿåˆ¶ - æå‡æ€§èƒ½
        self.counted_objects_history = []  # å·²è¨ˆæ•¸ç‰©ä»¶çš„æ­·å²è¨˜éŒ„
        self.history_length = 10  # æ¸›å°‘æ­·å²é•·åº¦ï¼Œæé«˜æ•ˆç‡
        self.duplicate_distance_threshold = 25  # ç°¡åŒ–é‡è¤‡æª¢æ¸¬è·é›¢
        
        # è¿½è¹¤ç‹€æ…‹
        self.object_tracks = {}
        self.crossing_counter = 0
        self.frame_width = 640  # é è¨­å¯¬åº¦ï¼Œæœƒåœ¨ç¬¬ä¸€å¹€æ™‚æ›´æ–°
        self.frame_height = 480  # é è¨­é«˜åº¦ï¼Œæœƒåœ¨ç¬¬ä¸€å¹€æ™‚æ›´æ–°
        self.current_frame_count = 0  # ç•¶å‰å¹€è¨ˆæ•¸
        
        # åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤å™¨
        self.bg_subtractor = None
        self._reset_background_subtractor()
        
        # ğŸ¯ å°ˆæ³¨æ–¼æ ¸å¿ƒæª¢æ¸¬åŠŸèƒ½ï¼Œç§»é™¤å¤šé¤˜çµ±è¨ˆ
        
        # ğŸ“¸ åˆæˆèª¿è©¦åœ–ç‰‡åŠŸèƒ½ - æ•´åˆæ‰€æœ‰åˆ†æéšæ®µæ–¼ä¸€å¼µåœ–ç‰‡
        self.debug_save_enabled = True   # ğŸ¯ å•Ÿç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜
        self.debug_save_dir = "/Users/crmado/github/Real-time_item_monitoring_system/basler_mvc/recordings/composite_debug"
        self.debug_frame_counter = 0
        self.max_debug_frames = 200     # ğŸ¯ é™åˆ¶èª¿è©¦åœ–ç‰‡æ•¸é‡é¿å…å ç”¨éå¤šç©ºé–“
        
        # ğŸ†• åˆæˆèª¿è©¦åœ–ç‰‡æ¨¡å¼ - é è¨­å•Ÿç”¨ 
        self.composite_debug_enabled = True  # åˆæˆèª¿è©¦åœ–ç‰‡é–‹é—œï¼ˆé è¨­å•Ÿç”¨ï¼‰
        
        # ğŸ¯ å‹•æ…‹ä¸­é–“æ®µè¨ˆç®—åƒæ•¸
        self.total_video_frames = None   # å½±ç‰‡ç¸½å¹€æ•¸ï¼ˆç”±è¦–é »æ’­æ”¾å™¨æä¾›ï¼‰
        self.skip_start_ratio = 0.3      # è·³éå‰30%
        self.save_middle_ratio = 0.4     # ä¿å­˜ä¸­é–“40%ï¼ˆ30%-70%å€é–“ï¼‰
        self.total_processed_frames = 0  # ç¸½è™•ç†å¹€æ•¸è¨ˆæ•¸å™¨
        self.current_session_dir = None  # ç•¶å‰æœƒè©±ç›®éŒ„
        self.manual_save_triggered = False  # æ‰‹å‹•è§¸ç™¼ä¿å­˜
        self.manual_trigger_active = False  # æ‰‹å‹•è§¸ç™¼ç‹€æ…‹
        self._temp_debug_data = None  # è‡¨æ™‚èª¿è©¦æ•¸æ“š
        
        logging.info("ğŸ” èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•åˆå§‹åŒ–å®Œæˆ (ğŸ¯ æ¥µåº¦é«˜éˆæ•åº¦ - å°ˆé–€å„ªåŒ–å°é›¶ä»¶æª¢æ¸¬)")
    
    def _reset_background_subtractor(self):
        """é‡ç½®èƒŒæ™¯æ¸›é™¤å™¨"""
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=self.bg_history,
            varThreshold=self.bg_var_threshold,
            detectShadows=self.detect_shadows
        )
        logging.debug("èƒŒæ™¯æ¸›é™¤å™¨å·²é‡ç½®")
    
    def process_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """åŸºæ–¼èƒŒæ™¯æ¸›é™¤çš„å½±åƒé è™•ç† - æ”¯æ´ROIå€åŸŸæª¢æ¸¬"""
        if frame is None:
            return None
        
        try:
            # ğŸš€ğŸš€ 206fpsæ¨¡å¼ï¼šç°¡åŒ–å¹€è¨ˆæ•¸
            self.total_processed_frames += 1
            
            # æ›´æ–°å¹€å°ºå¯¸
            self.frame_height, self.frame_width = frame.shape[:2]
            
            # ğŸ¯ ROI å€åŸŸæå– (åƒè€ƒ partsCounts_v1.py)
            if self.roi_enabled:
                roi_y = int(self.frame_height * self.roi_position_ratio)
                roi = frame[roi_y:roi_y + self.roi_height, :]
                
                # å­˜å„²ROIä½ç½®ä¿¡æ¯ä¾›å¾ŒçºŒä½¿ç”¨
                self.current_roi_y = roi_y
                self.current_roi_height = self.roi_height
                
                # å°ROIå€åŸŸé€²è¡Œè™•ç†
                process_region = roi
            else:
                # å…¨åœ–æª¢æ¸¬
                process_region = frame
                self.current_roi_y = 0
                self.current_roi_height = self.frame_height
            
            # 1. èƒŒæ™¯æ¸›é™¤ç²å¾—å‰æ™¯é®ç½©
            fg_mask = self.bg_subtractor.apply(process_region)
            
            # 2. é«˜æ–¯æ¨¡ç³Šæ¸›å°‘å™ªè²
            blurred = cv2.GaussianBlur(process_region, self.gaussian_blur_kernel, 0)
            
            # 3. Cannyé‚Šç·£æª¢æ¸¬
            edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
            
            # 4. ğŸš€ å¤šè§’åº¦æª¢æ¸¬ç­–ç•¥ - çµåˆå¤šç¨®æ–¹æ³•æé«˜æª¢æ¸¬ç‡
            
            # ğŸ”§ æ–¹æ³•1: è¶…æ¥µå°åŒ–å½¢æ…‹å­¸è™•ç† - æœ€å¤§åŒ–ä¿ç•™å°é›¶ä»¶
            # ä½¿ç”¨å¤šå±¤æ¬¡å¾®å‹é–‹é‹ç®—ï¼Œæ¼¸é€²å¼å»å™ªï¼Œä¿ç•™æ¥µå°é›¶ä»¶
            micro_kernel = np.ones((1, 1), np.uint8)  # å¾®å‹æ ¸ä¿ç•™æœ€å°ç‰¹å¾µ
            fg_step1 = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, micro_kernel, iterations=1)
            
            # ç¬¬äºŒå±¤ï¼šç¨å¤§ä¸€é»çš„æ ¸ï¼Œä½†è¿­ä»£æ¬¡æ•¸æ¸›å°‘
            nano_kernel = np.ones((2, 2), np.uint8)  
            fg_cleaned = cv2.morphologyEx(fg_step1, cv2.MORPH_OPEN, nano_kernel, iterations=1)
            
            # ğŸ”§ æ–¹æ³•2: å¤šæ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
            # ä½¿ç”¨å…©ç¨®ä¸åŒæ•æ„Ÿåº¦çš„é‚Šç·£æª¢æ¸¬
            strong_edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
            sensitive_edges = cv2.Canny(blurred, self.canny_low_threshold//2, self.canny_high_threshold//2)
            
            # ğŸ”§ æ–¹æ³•3: è‡ªé©æ‡‰é–¾å€¼æª¢æ¸¬ - è£œå¼·å°é›¶ä»¶æª¢æ¸¬
            gray_roi = cv2.cvtColor(process_region, cv2.COLOR_BGR2GRAY) if len(process_region.shape) == 3 else process_region
            adaptive_thresh = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            
            # çµåˆå‰æ™¯é®ç½©å’Œé‚Šç·£æª¢æ¸¬
            filtered_strong = cv2.bitwise_and(strong_edges, strong_edges, mask=fg_cleaned)
            filtered_sensitive = cv2.bitwise_and(sensitive_edges, sensitive_edges, mask=fg_cleaned)
            filtered_adaptive = cv2.bitwise_and(adaptive_thresh, adaptive_thresh, mask=fg_cleaned)
            
            # 5. äºŒå€¼åŒ–å’Œåˆä½µ
            _, thresh_strong = cv2.threshold(filtered_strong, self.binary_threshold, 255, cv2.THRESH_BINARY)
            _, thresh_sensitive = cv2.threshold(filtered_sensitive, self.binary_threshold//2, 255, cv2.THRESH_BINARY)
            
            # 6. ğŸš€ å¤šæ–¹æ³•è¯åˆæª¢æ¸¬ - æé«˜å¬å›ç‡
            # è¯åˆå¤šç¨®æª¢æ¸¬æ–¹æ³•çš„çµæœ
            combined = cv2.bitwise_or(fg_cleaned, thresh_strong)
            combined = cv2.bitwise_or(combined, thresh_sensitive)
            combined = cv2.bitwise_or(combined, filtered_adaptive)
            
            # 7. ğŸ”§ åŠ å¼·é›œè¨Šéæ¿¾çš„å½¢æ…‹å­¸è™•ç†
            # å¤šéšæ®µå»å™ªï¼Œå¼·åŒ–é›œè¨Šéæ¿¾èƒ½åŠ›
            
            # ç¬¬ä¸€éšæ®µï¼šå¼·åŒ–é–‹é‹ç®—å»é™¤å°é›œè¨Š
            opening_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.opening_kernel_size)
            opened_stage1 = cv2.morphologyEx(combined, cv2.MORPH_OPEN, opening_kernel, iterations=self.opening_iterations)
            
            # ç¬¬äºŒéšæ®µï¼šä¸­ç­‰æ ¸å¿ƒé–‹é‹ç®—ï¼Œé€²ä¸€æ­¥æ¸…ç†
            medium_open_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            opened_stage2 = cv2.morphologyEx(opened_stage1, cv2.MORPH_OPEN, medium_open_kernel, iterations=1)
            
            # é©åº¦è†¨è„¹é€£æ¥ç›¸è¿‘çš„é›¶ä»¶å€åŸŸ
            dilate_kernel = np.ones(self.dilate_kernel_size, np.uint8)
            dilated = cv2.dilate(opened_stage2, dilate_kernel, iterations=self.dilate_iterations)
            
            # é–‰åˆé‹ç®—å¡«è£œé›¶ä»¶å…§éƒ¨çš„å°æ´
            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.close_kernel_size)
            processed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, close_kernel, iterations=1)
            
            # ğŸ“¸ èª¿è©¦åœ–ç‰‡ä¿å­˜ (å¦‚æœå•Ÿç”¨) - å®Œæ•´åºåˆ—ä¿å­˜
            should_create_debug_data = (
                self.debug_save_enabled and 
                self.debug_frame_counter < self.max_debug_frames
            )
            
            self._temp_debug_data = {
                'frame': frame.copy(),
                'process_region': process_region.copy(),
                'fg_mask': fg_mask.copy(),
                'fg_cleaned': fg_cleaned.copy(),
                'processed': processed.copy()
            } if should_create_debug_data else None
            
            # ğŸ”§ æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶
            self._check_manual_trigger_file()
            
            return processed
            
        except Exception as e:
            logging.error(f"èƒŒæ™¯æ¸›é™¤é è™•ç†éŒ¯èª¤: {str(e)}")
            return None
    
    def detect_objects(self, processed_frame: np.ndarray, min_area: int = None, max_area: int = None) -> List[Tuple]:
        """åŸºæ–¼é€£é€šçµ„ä»¶çš„ç‰©ä»¶æª¢æ¸¬ - æ”¯æ´ç©¿è¶Šè¨ˆæ•¸"""
        if processed_frame is None:
            return []
        
        try:
            # ğŸ¯ å¼·åˆ¶ä½¿ç”¨æ¥µå°é›¶ä»¶æª¢æ¸¬åƒæ•¸ï¼Œé¿å…è¢«å¤–éƒ¨è¦†è“‹
            # åªæœ‰ç•¶å¤–éƒ¨åƒæ•¸æ›´å°æ™‚æ‰æ¡ç”¨ï¼Œç¢ºä¿æ•ç²æ¥µå°é›¶ä»¶
            min_a = min(min_area if min_area is not None else float('inf'), self.min_area)
            max_a = max(max_area if max_area is not None else 0, self.max_area)
            
            # é€£é€šçµ„ä»¶æ¨™è¨˜ (Connected Component Labeling)
            # åƒè€ƒ partsCounts_v1.py çš„å¯¦ç¾
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                processed_frame, connectivity=self.connectivity
            )
            
            current_objects = []
            
            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„ç¸½çµ„ä»¶æ•¸
            if self.current_frame_count % 20 == 0:  # æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡
                logging.debug(f"ç¸½é€£é€šçµ„ä»¶æ•¸: {num_labels-1}, é¢ç©ç¯„åœ: {min_a}-{max_a}")
            
            # éæ­·æ‰€æœ‰é€£é€šçµ„ä»¶ (è·³éèƒŒæ™¯ï¼Œå¾1é–‹å§‹)
            for i in range(1, num_labels):
                area = stats[i, cv2.CC_STAT_AREA]
                
                # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„é¢ç©éæ¿¾
                if self.current_frame_count % 20 == 0 and i <= 3:  # æ¯20å¹€è¨˜éŒ„å‰3å€‹çµ„ä»¶
                    logging.debug(f"çµ„ä»¶{i}: é¢ç©={area}, æ˜¯å¦é€šéé¢ç©éæ¿¾={min_a < area < max_a}")
                
                # é¢ç©ç¯©é¸
                if min_a < area < max_a:
                    # æå–é‚Šç•Œæ¡†ä¿¡æ¯ (ROIåº§æ¨™)
                    x = stats[i, cv2.CC_STAT_LEFT]
                    y = stats[i, cv2.CC_STAT_TOP]
                    w = stats[i, cv2.CC_STAT_WIDTH]
                    h = stats[i, cv2.CC_STAT_HEIGHT]
                    
                    # ğŸ”§ å½¢ç‹€éæ¿¾ - æ¸›å°‘é›œè¨Šèª¤åˆ¤
                    # è¨ˆç®—é•·å¯¬æ¯”
                    aspect_ratio = w / h if h > 0 else 0
                    
                    # è¨ˆç®—å¡«å……æ¯”ä¾‹ (ç‰©ä»¶é¢ç© / é‚Šç•Œæ¡†é¢ç©)
                    bbox_area = w * h
                    extent = area / bbox_area if bbox_area > 0 else 0
                    
                    # è¨ˆç®—å‡¸åŒ…çµå¯¦æ€§ (éœ€è¦æå–è¼ªå»“)
                    try:
                        # æå–ç•¶å‰çµ„ä»¶çš„é®ç½©
                        component_mask = (labels == i).astype(np.uint8) * 255
                        contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        if contours:
                            contour = contours[0]  # å–æœ€å¤§è¼ªå»“
                            hull = cv2.convexHull(contour)
                            hull_area = cv2.contourArea(hull)
                            solidity = area / hull_area if hull_area > 0 else 0
                        else:
                            solidity = 1.0  # å¦‚æœç„¡æ³•è¨ˆç®—ï¼Œçµ¦äºˆé è¨­å€¼
                    except:
                        solidity = 1.0  # éŒ¯èª¤æ™‚çµ¦äºˆé è¨­å€¼
                    
                    # ğŸ” è¶…æ¥µåº¦æ”¾å¯¬å½¢ç‹€éæ¿¾ - å°ˆé–€ç‚ºå°é›¶ä»¶æª¢æ¸¬å„ªåŒ–
                    shape_valid = (
                        aspect_ratio > self.min_aspect_ratio and  # è¶…å¯¬é¬†å€¼ 0.005
                        extent > self.min_extent and              # è¶…å¯¬é¬†å€¼ 0.0005  
                        solidity <= self.max_solidity             # è¶…æ”¾å¯¬å€¼ 2.0
                    )
                    
                    # ğŸ” è©³ç´°èª¿è©¦ä¿¡æ¯ï¼šè¨˜éŒ„æ‰€æœ‰éæ¿¾æƒ…æ³ 
                    if not shape_valid and self.current_frame_count % 5 == 0:  # æ›´é »ç¹çš„èª¿è©¦è¨˜éŒ„
                        reasons = []
                        if aspect_ratio <= self.min_aspect_ratio:
                            reasons.append(f"é•·å¯¬æ¯”å¤ªå°({aspect_ratio:.4f} <= {self.min_aspect_ratio})")
                        if extent <= self.min_extent:
                            reasons.append(f"å¡«å……æ¯”ä¾‹å¤ªå°({extent:.4f} <= {self.min_extent})")
                        if solidity > self.max_solidity:
                            reasons.append(f"çµå¯¦æ€§å¤ªå¤§({solidity:.3f} > {self.max_solidity})")
                        
                        logging.debug(f"ğŸš« å°é›¶ä»¶è¢«éæ¿¾: é¢ç©={area}, åŸå› ={'; '.join(reasons)}")
                    
                    # ğŸ” è¨˜éŒ„é€šéæª¢æ¸¬çš„å°é›¶ä»¶
                    if shape_valid and area < 50 and self.current_frame_count % 5 == 0:
                        logging.debug(f"âœ… æª¢æ¸¬åˆ°å°é›¶ä»¶: é¢ç©={area}, é•·å¯¬æ¯”={aspect_ratio:.3f}, ä½ç½®=({x},{y})")
                    
                    if shape_valid:
                        # ç²å–è³ªå¿ƒ (ROIåº§æ¨™)
                        roi_centroid = tuple(map(int, centroids[i]))
                        
                        # è½‰æ›ç‚ºå…¨åœ–åº§æ¨™
                        global_centroid = (roi_centroid[0], roi_centroid[1] + self.current_roi_y)
                        global_y = y + self.current_roi_y
                        
                        # è¨ˆç®—ç­‰æ•ˆåœ“åŠå¾‘
                        radius = np.sqrt(area / np.pi)
                        
                        # æ·»åŠ åˆ°ç•¶å‰ç‰©ä»¶åˆ—è¡¨ (ä½¿ç”¨å…¨åœ–åº§æ¨™)
                        # æ ¼å¼: (x, global_y, w, h, global_centroid, area, radius)
                        current_objects.append((x, global_y, w, h, global_centroid, area, radius))
            
            # ğŸ¯ åŸ·è¡Œç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸ (åƒè€ƒ partsCounts_v1.py)
            if self.enable_crossing_count:
                # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è¿½è¹¤ç‹€æ…‹ (æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡)
                if self.current_frame_count % 20 == 0:
                    logging.debug(f"ğŸ” é–‹å§‹è¿½è¹¤: æª¢æ¸¬ç‰©ä»¶æ•¸={len(current_objects)}, å•Ÿç”¨è¨ˆæ•¸={self.enable_crossing_count}")
                self._update_object_tracking(current_objects)
            
            # ğŸ’¾ ä¿å­˜æª¢æ¸¬çµæœä¾›èª¿è©¦ä½¿ç”¨
            self.last_detected_objects = current_objects.copy()
            
            # ğŸ“¸ ä¿å­˜èª¿è©¦åœ–ç‰‡çš„æ¢ä»¶ - åªåœ¨è¦–é »å›æ”¾æ¨¡å¼ä¸‹å•Ÿç”¨
            should_save = (
                self._temp_debug_data is not None and 
                self.debug_frame_counter < self.max_debug_frames and
                self.debug_save_enabled and
                self.composite_debug_enabled
            )
            
            # ğŸ¯ åœ¨å‰›é€²å…¥ä¸­é–“æ®µä¿å­˜çª—å£æ™‚è¨˜éŒ„æ—¥èªŒ
            if self.total_video_frames is not None:
                start_frame = int(self.total_video_frames * self.skip_start_ratio)
                if (self.total_processed_frames == start_frame + 1 and self.debug_save_enabled):
                    end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
                    logging.info(f"ğŸ“¸ é–‹å§‹ä¿å­˜å½±ç‰‡ä¸­é–“æ®µèª¿è©¦åœ–ç‰‡")
                    logging.info(f"   ä¿å­˜ç¯„åœ: ç¬¬{start_frame}å¹€ - ç¬¬{end_frame}å¹€")
                    logging.info(f"   é è¨ˆä¿å­˜ç´„ {end_frame - start_frame} å¹€çš„æ•¸æ“š")
            
            if should_save:
                save_reason = f"ç¬¬{self.debug_frame_counter+1}å¹€ (æª¢æ¸¬åˆ° {len(current_objects)} å€‹ç‰©ä»¶)"
                
                # ğŸ–¼ï¸ ä½¿ç”¨æ–°çš„åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜æ–¹æ³•
                self._save_composite_debug_image(
                    self._temp_debug_data['frame'],           # åŸå§‹å¹€
                    self._temp_debug_data['process_region'],  # ROIå€åŸŸ
                    self._temp_debug_data['fg_mask'],         # å‰æ™¯é®ç½©
                    self._temp_debug_data['fg_cleaned'],      # åˆä½µæª¢æ¸¬çµæœ
                    self._temp_debug_data['processed'],       # æœ€çµ‚è™•ç†çµæœ
                    current_objects                           # æª¢æ¸¬åˆ°çš„ç‰©ä»¶
                )
                self.debug_frame_counter += 1
                
                # æ¯50å¹€è¨˜éŒ„ä¸€æ¬¡é€²åº¦
                if self.debug_frame_counter % 50 == 0:
                    logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ {save_reason}ï¼Œå·²ä¿å­˜ {self.debug_frame_counter}/{self.max_debug_frames}")
                
                # é‡ç½®æ‰‹å‹•è§¸ç™¼æ¨™è¨˜
                self.manual_save_triggered = False
            
            # æ¸…ç†è‡¨æ™‚æ•¸æ“šï¼Œå¼·åˆ¶é‡‹æ”¾è¨˜æ†¶é«”
            if self._temp_debug_data is not None:
                del self._temp_debug_data
            self._temp_debug_data = None
            
            # ğŸš€ğŸš€ 206fpsæ¨¡å¼ï¼šç§»é™¤å¼·åˆ¶åƒåœ¾å›æ”¶ä»¥æå‡æ€§èƒ½
            # import gc  # å·²ç¦ç”¨
            # if self.debug_frame_counter % 10 == 0:  # å·²ç¦ç”¨
            #     gc.collect()  # å·²ç¦ç”¨
            
            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„æª¢æ¸¬çµæœ
            if self.current_frame_count % 20 == 0:  # æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡
                logging.debug(f"æœ€çµ‚æª¢æ¸¬åˆ°ç‰©ä»¶æ•¸: {len(current_objects)}")
            
            return current_objects
            
        except Exception as e:
            logging.error(f"èƒŒæ™¯æ¸›é™¤æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return []
    
    def _update_object_tracking(self, current_objects: List[Tuple]):
        """æ”¹é€²çš„ç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸é‚è¼¯"""
        try:
            self.current_frame_count += 1
            
            # ROIå€åŸŸé‚Šç•Œ
            roi_top = self.current_roi_y
            roi_bottom = self.current_roi_y + self.roi_height
            roi_center = self.current_roi_y + self.roi_height // 2
            
            # æ–°çš„è¿½è¹¤å­—å…¸
            new_tracks = {}
            
            # ç‚ºæ¯å€‹æª¢æ¸¬åˆ°çš„ç‰©ä»¶å°‹æ‰¾åŒ¹é…çš„è¿½è¹¤
            for obj in current_objects:
                x, y, w, h, centroid, area, radius = obj
                cx, cy = centroid
                
                matched = False
                best_match_id = None
                best_match_distance = float('inf')
                
                # èˆ‡ç¾æœ‰è¿½è¹¤é€²è¡ŒåŒ¹é… (æ‰¾æœ€ä½³åŒ¹é…)
                for track_id, track in self.object_tracks.items():
                    # è¨ˆç®—è·é›¢
                    distance = np.sqrt((cx - track['x'])**2 + (cy - track['y'])**2)
                    
                    # æª¢æŸ¥æ˜¯å¦åœ¨å®¹å·®ç¯„åœå…§
                    if (abs(cx - track['x']) < self.crossing_tolerance_x and 
                        abs(cy - track['y']) < self.crossing_tolerance_y and
                        distance < best_match_distance):
                        
                        best_match_distance = distance
                        best_match_id = track_id
                        matched = True
                
                if matched and best_match_id is not None:
                    # æ›´æ–°ç¾æœ‰è¿½è¹¤
                    old_track = self.object_tracks[best_match_id]
                    new_tracks[best_match_id] = {
                        'x': cx,
                        'y': cy,
                        'first_frame': old_track.get('first_frame', self.current_frame_count),
                        'last_frame': self.current_frame_count,
                        'positions': old_track.get('positions', []) + [(cx, cy)],
                        'counted': old_track.get('counted', False),
                        'in_roi_frames': old_track.get('in_roi_frames', 0) + 1,
                        'max_y': max(old_track.get('max_y', cy), cy),
                        'min_y': min(old_track.get('min_y', cy), cy)
                    }
                else:
                    # å‰µå»ºæ–°çš„è¿½è¹¤
                    new_track_id = max(self.object_tracks.keys()) + 1 if self.object_tracks else 0
                    new_tracks[new_track_id] = {
                        'x': cx,
                        'y': cy,
                        'first_frame': self.current_frame_count,
                        'last_frame': self.current_frame_count,
                        'positions': [(cx, cy)],
                        'counted': False,
                        'in_roi_frames': 1,
                        'max_y': cy,
                        'min_y': cy
                    }
            
            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è»Œè·¡ç‹€æ…‹ (æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡)
            if self.current_frame_count % 20 == 0:
                logging.debug(f"ğŸ¯ è»Œè·¡ç‹€æ…‹: ç¸½è»Œè·¡æ•¸={len(new_tracks)}, ç•¶å‰ç©¿è¶Šè¨ˆæ•¸={self.crossing_counter}")
            
            # ğŸ¯ ç°¡åŒ–é«˜æ•ˆç©¿è¶Šè¨ˆæ•¸é‚è¼¯ - æå‡æª¢æ¸¬é€Ÿåº¦
            for track_id, track in new_tracks.items():
                if not track['counted'] and track['in_roi_frames'] >= self.min_track_frames:
                    # ç°¡åŒ–æª¢æŸ¥ï¼šåªè¦ç‰©ä»¶åœ¨ROIä¸­å‡ºç¾å°±è¨ˆæ•¸
                    y_travel = track['max_y'] - track['min_y']
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡è¨ˆæ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    is_duplicate = self._check_duplicate_detection_simple(track)
                    
                    # ğŸ¯ æé«˜è¨ˆæ•¸è¦æ±‚ï¼šç¢ºä¿ç©©å®šæª¢æ¸¬ï¼Œæ¸›å°‘èª¤åˆ¤
                    valid_crossing = (
                        y_travel >= 10 and          # ğŸ”§ æé«˜ç§»å‹•è¦æ±‚ï¼Œç¢ºä¿çœŸå¯¦ç§»å‹• (1â†’10åƒç´ )
                        track['in_roi_frames'] >= self.min_track_frames and  # ç¢ºä¿å¤šå¹€ç©©å®šæª¢æ¸¬
                        not is_duplicate            # éé‡è¤‡æª¢æ¸¬
                    )
                    
                    # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è¨ˆæ•¸é‚è¼¯ (æ¯10å¹€è¨˜éŒ„ä¸€æ¬¡)
                    if self.current_frame_count % 10 == 0 and track_id in list(new_tracks.keys())[:2]:
                        logging.debug(f"ç‰©ä»¶{track_id}: Yç§»å‹•={y_travel}px, é‡è¤‡={is_duplicate}, åœ¨ROIå¹€æ•¸={track['in_roi_frames']}, æœ‰æ•ˆç©¿è¶Š={valid_crossing}")
                    
                    if valid_crossing:
                        # è¨˜éŒ„åˆ°æ­·å²ä¸­é˜²æ­¢é‡è¤‡
                        self._add_to_history(track)
                        
                        self.crossing_counter += 1
                        track['counted'] = True
                        
                        # ğŸ” é‡è¦ï¼šè¨˜éŒ„æ¯æ¬¡æˆåŠŸè¨ˆæ•¸ (æ€§èƒ½å½±éŸ¿å°ä½†å¾ˆé‡è¦)
                        logging.info(f"âœ… æˆåŠŸè¨ˆæ•¸ #{self.crossing_counter} - ç‰©ä»¶{track_id} (Yç§»å‹•: {y_travel}px)")
            
            # æ¸…ç†éæœŸçš„è¿½è¹¤ (ç”Ÿå‘½é€±æœŸç®¡ç†)
            current_time = self.current_frame_count
            for track_id in list(new_tracks.keys()):
                track = new_tracks[track_id]
                if current_time - track['last_frame'] > self.track_lifetime:
                    del new_tracks[track_id]
            
            # æ›´æ–°è¿½è¹¤ç‹€æ…‹
            self.object_tracks = new_tracks
            
        except Exception as e:
            logging.error(f"ç‰©ä»¶è¿½è¹¤æ›´æ–°éŒ¯èª¤: {str(e)}")
    
    def _check_duplicate_detection_simple(self, track: Dict) -> bool:
        """ç°¡åŒ–ç‰ˆé‡è¤‡æª¢æ¸¬ - æå‡æ€§èƒ½"""
        try:
            current_pos = (track['x'], track['y'])
            
            # åªæª¢æŸ¥æœ€è¿‘çš„å¹¾å€‹æ­·å²è¨˜éŒ„
            recent_history = self.counted_objects_history[-5:] if len(self.counted_objects_history) > 5 else self.counted_objects_history
            
            for hist_pos in recent_history:
                distance = abs(current_pos[0] - hist_pos[0]) + abs(current_pos[1] - hist_pos[1])  # ä½¿ç”¨æ›¼å“ˆé “è·é›¢ï¼Œæ›´å¿«
                
                if distance < self.duplicate_distance_threshold:
                    return True  # ç™¼ç¾é‡è¤‡
            
            return False
            
        except Exception:
            return False
    
    def _add_to_history(self, track: Dict):
        """æ·»åŠ å·²è¨ˆæ•¸ç‰©ä»¶åˆ°æ­·å²è¨˜éŒ„"""
        try:
            position = (track['x'], track['y'])
            self.counted_objects_history.append(position)
            
            # ä¿æŒæ­·å²è¨˜éŒ„åœ¨é™åˆ¶ç¯„åœå…§
            if len(self.counted_objects_history) > self.history_length:
                self.counted_objects_history.pop(0)
                
        except Exception as e:
            logging.error(f"æ·»åŠ æ­·å²è¨˜éŒ„éŒ¯èª¤: {str(e)}")
    
    def get_crossing_count(self) -> int:
        """ç²å–ç©¿è¶Šè¨ˆæ•¸"""
        return self.crossing_counter
    
    def get_tracking_stats(self) -> Dict[str, Any]:
        """ç²å–è¿½è¹¤çµ±è¨ˆä¿¡æ¯ (ç”¨æ–¼èª¿è©¦)"""
        active_tracks = len(self.object_tracks)
        counted_tracks = sum(1 for track in self.object_tracks.values() if track.get('counted', False))
        
        return {
            'crossing_count': self.crossing_counter,
            'active_tracks': active_tracks,
            'counted_tracks': counted_tracks,
            'frame_count': self.current_frame_count,
            'roi_height': self.roi_height,
            'roi_position': self.roi_position_ratio,
            'history_length': len(self.counted_objects_history),
            'accuracy_features': {
                'min_track_frames': self.min_track_frames,
                'confidence_threshold': self.confidence_threshold,
                'duplicate_prevention': True
            }
        }
    
    def get_accuracy_metrics(self) -> Dict[str, Any]:
        """ç²å–æº–ç¢ºç‡ç›¸é—œæŒ‡æ¨™"""
        return {
            'total_crossings': self.crossing_counter,
            'confidence_threshold': self.confidence_threshold,
            'min_tracking_frames': self.min_track_frames,
            'duplicate_prevention_enabled': True,
            'history_buffer_size': len(self.counted_objects_history),
            'roi_optimization': {
                'height': self.roi_height,
                'position': self.roi_position_ratio,
                'coverage_threshold': self.crossing_threshold
            }
        }
    
    def reset_crossing_count(self):
        """é‡ç½®ç©¿è¶Šè¨ˆæ•¸"""
        self.crossing_counter = 0
        self.object_tracks = {}
        self.current_frame_count = 0
        self.total_processed_frames = 0  # ğŸ¯ é‡ç½®ç¸½å¹€æ•¸è¨ˆæ•¸å™¨
        self.debug_frame_counter = 0     # ğŸ¯ é‡ç½®èª¿è©¦åœ–ç‰‡è¨ˆæ•¸å™¨
        self.counted_objects_history = []  # æ¸…ç†æ­·å²è¨˜éŒ„
        logging.info("ğŸ”„ ç©¿è¶Šè¨ˆæ•¸ã€è¿½è¹¤ã€æ­·å²è¨˜éŒ„å’Œèª¿è©¦è¨ˆæ•¸å™¨å·²é‡ç½®")
    
    def set_video_info(self, total_frames: int, fps: float = 206):
        """è¨­å®šå½±ç‰‡ä¿¡æ¯ï¼Œç”¨æ–¼å‹•æ…‹è¨ˆç®—ä¸­é–“æ®µ"""
        self.total_video_frames = total_frames
        
        # è¨ˆç®—ä¸­é–“æ®µçš„é–‹å§‹å’ŒçµæŸå¹€
        start_frame = int(total_frames * self.skip_start_ratio)
        end_frame = int(total_frames * (self.skip_start_ratio + self.save_middle_ratio))
        
        duration_sec = total_frames / fps
        start_time = start_frame / fps
        end_time = end_frame / fps
        
        # ğŸš€ğŸš€ 206fpsæ¨¡å¼ï¼šç°¡åŒ–å½±ç‰‡ä¿¡æ¯æ—¥èªŒ
        logging.info(f"ğŸ¬ å½±ç‰‡: {total_frames}å¹€, {fps:.1f}fps")
    
    def _is_in_save_window(self) -> bool:
        """æª¢æŸ¥ç•¶å‰æ˜¯å¦åœ¨ä¿å­˜çª—å£å…§ï¼ˆå½±ç‰‡ä¸­é–“æ®µï¼‰"""
        if self.total_video_frames is None:
            # å¦‚æœæ²’æœ‰è¨­å®šå½±ç‰‡ç¸½å¹€æ•¸ï¼Œä½¿ç”¨èˆŠé‚è¼¯
            return self.total_processed_frames > 100  # ç°¡å–®è·³éå‰100å¹€
        
        start_frame = int(self.total_video_frames * self.skip_start_ratio)
        end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
        
        return start_frame <= self.total_processed_frames <= end_frame
    
    def get_debug_status(self) -> Dict[str, Any]:
        """ç²å–èª¿è©¦ç‹€æ…‹ä¿¡æ¯"""
        if self.total_video_frames is not None:
            start_frame = int(self.total_video_frames * self.skip_start_ratio)
            end_frame = int(self.total_video_frames * (self.skip_start_ratio + self.save_middle_ratio))
            
            return {
                'total_processed_frames': self.total_processed_frames,
                'total_video_frames': self.total_video_frames,
                'save_start_frame': start_frame,
                'save_end_frame': end_frame,
                'debug_frame_counter': self.debug_frame_counter,
                'max_debug_frames': self.max_debug_frames,
                'is_in_save_window': self._is_in_save_window(),
                'save_progress': f"{self.total_processed_frames - start_frame}/{end_frame - start_frame}" if self._is_in_save_window() else "æœªåœ¨ä¿å­˜çª—å£å…§"
            }
        else:
            return {
                'total_processed_frames': self.total_processed_frames,
                'total_video_frames': None,
                'debug_frame_counter': self.debug_frame_counter,
                'max_debug_frames': self.max_debug_frames,
                'is_in_save_window': self.total_processed_frames > 100,
                'note': 'æœªè¨­å®šå½±ç‰‡ç¸½å¹€æ•¸ï¼Œä½¿ç”¨ç°¡åŒ–é‚è¼¯'
            }
    
    def get_roi_info(self) -> Dict[str, Any]:
        """ç²å–ROIå€åŸŸä¿¡æ¯"""
        return {
            'enabled': self.roi_enabled,
            'y': getattr(self, 'current_roi_y', 0),
            'height': self.roi_height,
            'width': self.frame_width,
            'position_ratio': self.roi_position_ratio
        }
    
    def set_roi_position(self, position_ratio: float):
        """è¨­ç½®ROIä½ç½®æ¯”ä¾‹"""
        self.roi_position_ratio = max(0.0, min(1.0, position_ratio))
        logging.info(f"ğŸ¯ ROIä½ç½®å·²æ›´æ–°: {self.roi_position_ratio:.2f}")
    
    def reset_background_model(self):
        """é‡ç½®èƒŒæ™¯æ¨¡å‹ - ç”¨æ–¼åˆ‡æ›è¦–é »æˆ–é‡æ–°é–‹å§‹è¨ˆæ•¸"""
        self._reset_background_subtractor()
        self.reset_crossing_count()
        logging.info("ğŸ”„ èƒŒæ™¯æ¨¡å‹å’Œè¨ˆæ•¸å·²é‡ç½®")
    
    def set_parameters(self, params: Dict[str, Any]) -> bool:
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        try:
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
                    logging.debug(f"æ›´æ–°èƒŒæ™¯æ¸›é™¤æª¢æ¸¬åƒæ•¸ {key}: {value}")
            
            # å¦‚æœæ›´æ–°äº†èƒŒæ™¯æ¸›é™¤å™¨ç›¸é—œåƒæ•¸ï¼Œéœ€è¦é‡ç½®
            bg_params = ['bg_history', 'bg_var_threshold', 'detect_shadows']
            if any(param in params for param in bg_params):
                self._reset_background_subtractor()
                
            return True
        except Exception as e:
            logging.error(f"è¨­ç½®èƒŒæ™¯æ¸›é™¤æª¢æ¸¬åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False
    
    # ğŸ§¹ å·²ç§»é™¤ä¸éœ€è¦çš„çµ±è¨ˆå’Œè‡ªé©æ‡‰å‡½æ•¸ï¼Œå°ˆæ³¨æ–¼æ ¸å¿ƒæª¢æ¸¬
    
    def _save_composite_debug_image(self, original_frame, roi_region, fg_mask, combined_mask, final_processed, detected_objects):
        """ä¿å­˜åˆæˆèª¿è©¦åœ–ç‰‡ - å°‡æ‰€æœ‰åˆ†æéšæ®µåˆä½µç‚ºä¸€å¼µå¤§åœ–"""
        try:
            import os
            import time
            from datetime import datetime
            
            # åˆå§‹åŒ–æœƒè©±è³‡æ–™å¤¾ (åªåœ¨ç¬¬ä¸€æ¬¡æ™‚å‰µå»º)
            if self.current_session_dir is None:
                now = datetime.now()
                session_folder = now.strftime("%Y%m%d_%H%M%S")
                self.current_session_dir = os.path.join(self.debug_save_dir, f"composite_{session_folder}")
                
                # ç¢ºä¿ç›®éŒ„å­˜åœ¨
                os.makedirs(self.current_session_dir, exist_ok=True)
                
                # å‰µå»ºç•¶å‰æœƒè©±çš„è³‡è¨Šæª”æ¡ˆ
                info_file = os.path.join(self.current_session_dir, "session_info.txt")
                with open(info_file, 'w', encoding='utf-8') as f:
                    f.write(f"ğŸ¯ åˆæˆèª¿è©¦æœƒè©±é–‹å§‹æ™‚é–“: {now.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æª¢æ¸¬æ–¹æ³•: èƒŒæ™¯æ¸›é™¤æª¢æ¸¬ (åˆæˆåœ–ç‰‡æ¨¡å¼)\n")
                    f.write(f"ROIé«˜åº¦: {self.roi_height}px\n")
                    f.write(f"ROIä½ç½®æ¯”ä¾‹: {self.roi_position_ratio}\n")
                    f.write(f"æœ€å¤§èª¿è©¦å¹€æ•¸: {self.max_debug_frames}\n")
                    f.write(f"åœ–ç‰‡æ ¼å¼: 3x2åˆæˆå¸ƒå±€\n\n")
                
                logging.info(f"ğŸ–¼ï¸ é–‹å§‹æ–°çš„åˆæˆèª¿è©¦æœƒè©±: {self.current_session_dir}")
            
            timestamp = int(time.time() * 1000)
            frame_id = f"{self.debug_frame_counter:04d}_{timestamp}"
            
            # ğŸ¨ å‰µå»ºåˆæˆåœ–ç‰‡å¸ƒå±€ (3åˆ— x 2è¡Œ)
            # æº–å‚™å„å€‹åœ–ç‰‡çµ„ä»¶
            
            # 1. åŸå§‹åœ–ç‰‡ (å¸¶ROIæ¨™è¨˜)
            original_with_roi = original_frame.copy()
            roi_y = int(self.frame_height * self.roi_position_ratio)
            cv2.rectangle(original_with_roi, (0, roi_y), 
                         (self.frame_width, roi_y + self.roi_height), (0, 255, 0), 3)
            cv2.putText(original_with_roi, f"ROI ({self.roi_height}px)", 
                       (10, roi_y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # 2. ROIå€åŸŸ (å½©è‰²)
            roi_color = roi_region.copy()
            if len(roi_color.shape) == 2:
                roi_color = cv2.cvtColor(roi_color, cv2.COLOR_GRAY2BGR)
            
            # 3. å‰æ™¯é®ç½© (è½‰å½©è‰²ä»¥ä¾¿åˆæˆ)
            fg_mask_color = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)
            
            # 4. åˆä½µæª¢æ¸¬çµæœ (è½‰å½©è‰²)
            combined_color = cv2.cvtColor(combined_mask, cv2.COLOR_GRAY2BGR)
            
            # 5. æœ€çµ‚è™•ç†çµæœ (è½‰å½©è‰²)
            final_color = cv2.cvtColor(final_processed, cv2.COLOR_GRAY2BGR)
            
            # 6. æª¢æ¸¬çµæœåœ– (åœ¨ROIä¸Šç¹ªè£½æª¢æ¸¬æ¡†)
            detection_result = roi_color.copy()
            if detected_objects:
                for obj in detected_objects:
                    x, y, w, h, centroid, area, radius = obj
                    # è½‰æ›å›ROIåº§æ¨™
                    roi_y_offset = int(self.frame_height * self.roi_position_ratio)
                    local_y = y - roi_y_offset
                    local_centroid = (centroid[0], centroid[1] - roi_y_offset)
                    
                    if 0 <= local_y < self.roi_height and 0 <= local_centroid[1] < self.roi_height:
                        # ç¹ªè£½é‚Šç•Œæ¡†
                        cv2.rectangle(detection_result, (x, local_y), (x + w, local_y + h), (0, 255, 0), 2)
                        # ç¹ªè£½ä¸­å¿ƒé»
                        cv2.circle(detection_result, local_centroid, 4, (255, 0, 0), -1)
                        # æ¨™è¨»é¢ç©
                        cv2.putText(detection_result, f'{int(area)}', 
                                   (x, max(5, local_y - 8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            # ğŸ—ï¸ èª¿æ•´æ‰€æœ‰åœ–ç‰‡åˆ°çµ±ä¸€å°ºå¯¸
            target_height = 300  # çµ±ä¸€é«˜åº¦
            target_width = 400   # çµ±ä¸€å¯¬åº¦
            
            def resize_and_pad(img, target_h, target_w):
                """èª¿æ•´åœ–ç‰‡å°ºå¯¸åˆ°å›ºå®šå°ºå¯¸ä¸¦ä¿æŒæ¯”ä¾‹"""
                h, w = img.shape[:2]
                
                # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œä¿æŒåœ–ç‰‡æ¯”ä¾‹
                scale_h = target_h / h
                scale_w = target_w / w
                scale = min(scale_h, scale_w)  # ä½¿ç”¨è¼ƒå°çš„ç¸®æ”¾æ¯”ä¾‹ä¿æŒæ¯”ä¾‹
                
                new_h = int(h * scale)
                new_w = int(w * scale)
                
                # ç¸®æ”¾åœ–ç‰‡
                resized = cv2.resize(img, (new_w, new_h))
                
                # å‰µå»ºå›ºå®šå°ºå¯¸çš„ç•«å¸ƒ
                canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
                
                # è¨ˆç®—å±…ä¸­ä½ç½®
                start_y = (target_h - new_h) // 2
                start_x = (target_w - new_w) // 2
                
                # å°‡ç¸®æ”¾å¾Œçš„åœ–ç‰‡æ”¾åˆ°ç•«å¸ƒä¸­å¤®
                canvas[start_y:start_y+new_h, start_x:start_x+new_w] = resized
                
                return canvas
            
            # èª¿æ•´æ‰€æœ‰åœ–ç‰‡å°ºå¯¸
            img1 = resize_and_pad(original_with_roi, target_height, target_width)
            img2 = resize_and_pad(roi_color, target_height, target_width)
            img3 = resize_and_pad(fg_mask_color, target_height, target_width)
            img4 = resize_and_pad(combined_color, target_height, target_width)
            img5 = resize_and_pad(final_color, target_height, target_width)
            img6 = resize_and_pad(detection_result, target_height, target_width)
            
            # æ·»åŠ æ¨™é¡Œæ–‡å­—
            def add_title(img, title, bg_color=(0, 0, 0)):
                """åœ¨åœ–ç‰‡é ‚éƒ¨æ·»åŠ æ¨™é¡Œ"""
                h, w = img.shape[:2]
                title_height = 40
                titled_img = np.full((h + title_height, w, 3), bg_color, dtype=np.uint8)
                titled_img[title_height:, :] = img
                
                # æ·»åŠ æ¨™é¡Œæ–‡å­—
                cv2.putText(titled_img, title, (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                return titled_img
            
            # ç‚ºæ¯å¼µåœ–ç‰‡æ·»åŠ æ¨™é¡Œ
            img1_titled = add_title(img1, "1. Original + ROI")
            img2_titled = add_title(img2, "2. ROI Region")  
            img3_titled = add_title(img3, "3. Foreground Mask")
            img4_titled = add_title(img4, "4. Combined Detection")
            img5_titled = add_title(img5, "5. Final Processed")
            img6_titled = add_title(img6, f"6. Objects ({len(detected_objects)})")
            
            # ğŸ–¼ï¸ åˆæˆæœ€çµ‚åœ–ç‰‡ (3x2å¸ƒå±€)
            # ç¬¬ä¸€è¡Œ
            row1 = np.hstack([img1_titled, img2_titled, img3_titled])
            # ç¬¬äºŒè¡Œ  
            row2 = np.hstack([img4_titled, img5_titled, img6_titled])
            
            # åˆä½µå…©è¡Œ
            composite_img = np.vstack([row1, row2])
            
            # ğŸ·ï¸ æ·»åŠ åº•éƒ¨åƒæ•¸ä¿¡æ¯
            info_height = 120
            info_panel = np.zeros((info_height, composite_img.shape[1], 3), dtype=np.uint8)
            
            # åƒæ•¸æ–‡å­—ä¿¡æ¯
            params_text = [
                f"Frame: {self.debug_frame_counter:04d} | Count: {self.crossing_counter} | Objects: {len(detected_objects)}",
                f"ROI: {self.roi_height}px @ {self.roi_position_ratio:.2f} | MinArea: {self.min_area} | MaxArea: {self.max_area}",
                f"BG Threshold: {self.bg_var_threshold} | Binary: {self.binary_threshold} | Canny: {self.canny_low_threshold}-{self.canny_high_threshold}",
                f"Time: {datetime.fromtimestamp(timestamp/1000).strftime('%H:%M:%S.%f')[:-3]}"
            ]
            
            # åœ¨ä¿¡æ¯é¢æ¿ä¸Šæ·»åŠ æ–‡å­—
            for i, text in enumerate(params_text):
                y_pos = 25 + i * 25
                cv2.putText(info_panel, text, (10, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            # åˆä½µä¿¡æ¯é¢æ¿
            final_composite = np.vstack([composite_img, info_panel])
            
            # ğŸ’¾ ä¿å­˜åˆæˆåœ–ç‰‡
            save_path = f"{self.current_session_dir}/composite_debug_{frame_id}.jpg"
            cv2.imwrite(save_path, final_composite)
            
            # ğŸ“Š æ¯50å¹€è¨˜éŒ„ä¸€æ¬¡é€²åº¦
            if self.debug_frame_counter % 50 == 0:
                logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡å·²ä¿å­˜ {self.debug_frame_counter}/{self.max_debug_frames}")
            
        except Exception as e:
            logging.error(f"ä¿å­˜åˆæˆèª¿è©¦åœ–ç‰‡éŒ¯èª¤: {str(e)}")
    
    def _check_manual_trigger_file(self):
        """æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶"""
        try:
            from pathlib import Path
            trigger_file = Path("/tmp/basler_debug_trigger.txt")
            
            if trigger_file.exists():
                # è®€å–è§¸ç™¼ä¿¡è™Ÿ
                trigger_content = trigger_file.read_text().strip()
                if trigger_content.startswith("TRIGGER_"):
                    # å¼·åˆ¶å•Ÿç”¨èª¿è©¦ä¿å­˜
                    self.manual_trigger_active = True
                    logging.info(f"ğŸ“¸ æª¢æ¸¬åˆ°æ‰‹å‹•è§¸ç™¼ä¿¡è™Ÿ: {trigger_content}")
                    
                    # åˆªé™¤è§¸ç™¼æ–‡ä»¶
                    trigger_file.unlink()
                    
        except Exception as e:
            logging.debug(f"æª¢æŸ¥æ‰‹å‹•è§¸ç™¼æ–‡ä»¶éŒ¯èª¤: {str(e)}")
    
    def enable_debug_save(self, enabled: bool = True):
        """å•Ÿç”¨æˆ–ç¦ç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜"""
        self.debug_save_enabled = enabled
        if enabled:
            self.debug_frame_counter = 0  # é‡ç½®è¨ˆæ•¸å™¨
            logging.info("ğŸ“¸ èª¿è©¦åœ–ç‰‡ä¿å­˜å·²å•Ÿç”¨")
        else:
            logging.info("ğŸ“¸ èª¿è©¦åœ–ç‰‡ä¿å­˜å·²ç¦ç”¨")
    
    def get_debug_info(self) -> Dict[str, Any]:
        """ç²å–èª¿è©¦ä¿¡æ¯"""
        return {
            'debug_enabled': self.debug_save_enabled,
            'frames_saved': self.debug_frame_counter,
            'max_frames': self.max_debug_frames,
            'save_directory': self.debug_save_dir,
            'current_session': self.current_session_dir
        }
    
    def trigger_manual_save(self):
        """æ‰‹å‹•è§¸ç™¼ä¿å­˜ç•¶å‰å¹€ - ç”¨æ–¼æ•æ‰ç‰¹å®šç•«é¢"""
        self.manual_save_triggered = True
        logging.info("ğŸ”§ æ‰‹å‹•è§¸ç™¼èª¿è©¦åœ–ç‰‡ä¿å­˜")

    def enable_composite_debug(self, enabled: bool = True, mode: str = "playback"):
        """å•Ÿç”¨æˆ–ç¦ç”¨åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜"""
        # ğŸ¯ åªåœ¨è¦–é »å›æ”¾æ¨¡å¼ä¸‹å…è¨±èª¿è©¦åœ–ç‰‡ä¿å­˜
        if mode in ["live", "recording"]:
            self.composite_debug_enabled = False
            self.debug_save_enabled = False
            logging.info(f"ğŸ–¼ï¸ {mode}æ¨¡å¼ä¸‹è‡ªå‹•ç¦ç”¨èª¿è©¦åœ–ç‰‡ä¿å­˜ï¼ˆæ€§èƒ½å„ªåŒ–ï¼‰")
            return
            
        self.composite_debug_enabled = enabled
        self.debug_save_enabled = enabled
        
        if enabled:
            self.debug_frame_counter = 0  # é‡ç½®è¨ˆæ•¸å™¨
            self.current_session_dir = None  # é‡ç½®æœƒè©±ç›®éŒ„
            logging.info(f"ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜å·²å•Ÿç”¨ (æ¨¡å¼: {mode})")
        else:
            logging.info("ğŸ–¼ï¸ åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜å·²ç¦ç”¨")

    def get_composite_debug_info(self) -> Dict[str, Any]:
        """ç²å–åˆæˆèª¿è©¦åœ–ç‰‡ä¿å­˜ä¿¡æ¯"""
        return {
            'enabled': self.composite_debug_enabled,
            'frames_saved': self.debug_frame_counter,
            'max_frames': self.max_debug_frames,
            'save_directory': self.debug_save_dir,
            'current_session': self.current_session_dir,
            'progress_percentage': (self.debug_frame_counter / self.max_debug_frames) * 100 if self.max_debug_frames > 0 else 0,
            'layout': '3x2 composite layout with annotations'
        }

    @property
    def name(self) -> str:
        return "BackgroundSubtractionDetection"


