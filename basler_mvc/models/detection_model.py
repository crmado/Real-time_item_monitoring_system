"""
å½±åƒæª¢æ¸¬ Model - MVC æ¶æ§‹æ ¸å¿ƒ
å°ˆæ³¨æ–¼æ ¸å¿ƒå½±åƒè­˜åˆ¥ç®—æ³•çš„æ•¸æ“šç®¡ç†
"""

import cv2
import numpy as np
import logging
import threading
import time
from typing import Optional, List, Dict, Any, Tuple, Callable
from collections import deque
from .detection_base import DetectionMethod

# æ¨™è¨˜å¢å¼·æª¢æ¸¬æ˜¯å¦å¯ç”¨ï¼ˆç¨å¾Œå‹•æ…‹åŠ è¼‰ï¼‰
ENHANCED_DETECTION_AVAILABLE = False


class CircleDetection(DetectionMethod):
    """éœå¤«åœ“æª¢æ¸¬æ–¹æ³• - é«˜æ€§èƒ½å„ªåŒ–ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–åœ“å½¢æª¢æ¸¬"""
        # ğŸš€ æ¥µé€Ÿå„ªåŒ–åƒæ•¸ï¼ˆé‡å°å¯¦æ™‚è™•ç†ï¼‰
        self.resize_factor = 0.3      # åœ–åƒç¸®å°70%å¤§å¹…æå‡æ€§èƒ½
        self.dp = 3.0                 # é€²ä¸€æ­¥å¢å¤§dpæ¸›å°‘è¨ˆç®—é‡
        self.min_dist = 30            # é©åº¦èª¿æ•´æœ€å°è·é›¢
        self.param1 = 120             # æé«˜é–¾å€¼æ¸›å°‘è¨ˆç®—
        self.param2 = 70              # æé«˜é–¾å€¼
        self.min_radius = 8           # èª¿æ•´æœ€å°åŠå¾‘
        self.max_radius = 50          # é™åˆ¶æœ€å¤§åŠå¾‘
        self.min_area = 100           # èª¿æ•´é¢ç©ç¯„åœ
        self.max_area = 5000
        self.blur_kernel = 3          # ä½¿ç”¨æ›´å°çš„æ¨¡ç³Šæ ¸
        
        logging.info("âœ… é«˜æ€§èƒ½åœ“å½¢æª¢æ¸¬åˆå§‹åŒ–å®Œæˆ")
    
    def process_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """é«˜é€Ÿå¹€è™•ç† - è¼•é‡åŒ–å„ªåŒ–"""
        if frame is None:
            return None
            
        try:
            # ğŸš€ é—œéµå„ªåŒ–ï¼šç¸®å°åœ–åƒè™•ç†
            height, width = frame.shape[:2]
            new_height = int(height * self.resize_factor)
            new_width = int(width * self.resize_factor)
            
            # å¿«é€Ÿç¸®æ”¾ï¼ˆä½¿ç”¨æœ€å¿«çš„æ’å€¼æ–¹æ³•ï¼‰
            small_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_NEAREST)
            
            # è½‰ç°åº¦
            if len(small_frame.shape) == 3:
                gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)
            else:
                gray = small_frame
                
            # ğŸš€ å„ªåŒ–ï¼šä½¿ç”¨æ›´å¿«çš„ä¸­å€¼æ¿¾æ³¢
            blurred = cv2.medianBlur(gray, self.blur_kernel)
            return blurred
            
        except Exception as e:
            logging.error(f"è™•ç†å¹€éŒ¯èª¤: {str(e)}")
            return None
    
    def detect_objects(self, processed_frame: np.ndarray, min_area: int = None, max_area: int = None) -> List[Tuple]:
        """é«˜æ€§èƒ½éœå¤«åœ“æª¢æ¸¬"""
        if processed_frame is None:
            return []
            
        try:
            # ğŸš€ å„ªåŒ–çš„åœ“æª¢æ¸¬ï¼ˆåœ¨ç¸®å°çš„åœ–åƒä¸Šï¼‰
            circles = cv2.HoughCircles(
                processed_frame,
                cv2.HOUGH_GRADIENT,
                dp=self.dp,
                minDist=int(self.min_dist * self.resize_factor),
                param1=self.param1,
                param2=self.param2,
                minRadius=int(self.min_radius * self.resize_factor),
                maxRadius=int(self.max_radius * self.resize_factor)
            )
            
            objects = []
            if circles is not None:
                circles = np.round(circles[0, :]).astype("int")
                scale_factor = 1.0 / self.resize_factor
                
                min_a = min_area if min_area is not None else self.min_area
                max_a = max_area if max_area is not None else self.max_area
                
                for (x, y, r) in circles:
                    # ğŸš€ é—œéµï¼šç¸®æ”¾å›åŸå§‹å°ºå¯¸
                    orig_x = int(x * scale_factor)
                    orig_y = int(y * scale_factor)
                    orig_r = int(r * scale_factor)
                    area = np.pi * orig_r * orig_r
                    
                    if min_a <= area <= max_a:
                        # è¿”å› (x, y, w, h, centroid, area, radius)
                        bbox_x = int(orig_x - orig_r)
                        bbox_y = int(orig_y - orig_r)
                        bbox_w = int(orig_r * 2)
                        bbox_h = int(orig_r * 2)
                        objects.append((bbox_x, bbox_y, bbox_w, bbox_h, (orig_x, orig_y), area, orig_r))
            
            return objects
            
        except Exception as e:
            logging.error(f"åœ“æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return []
    
    def set_parameters(self, params: Dict[str, Any]) -> bool:
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        try:
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
                    logging.info(f"æ›´æ–°åƒæ•¸ {key}: {value}")
            return True
        except Exception as e:
            logging.error(f"è¨­ç½®åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False


class ContourDetection(DetectionMethod):
    """è¼ªå»“æª¢æ¸¬æ–¹æ³• - å¢å¼·ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¼ªå»“æª¢æ¸¬"""
        self.threshold_value = 127
        self.min_area = 100
        self.max_area = 10000
        self.morphology_kernel_size = 3
        
        # ğŸ¯ æ–°å¢è‡ªé©æ‡‰åƒæ•¸
        self.adaptive_threshold = True
        self.noise_reduction = True
        self.edge_enhancement = True
        
        logging.info("å¢å¼·è¼ªå»“æª¢æ¸¬åˆå§‹åŒ–å®Œæˆ")
    
    def process_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """å¢å¼·å¹€è™•ç† - è‡ªé©æ‡‰ç®—æ³•"""
        if frame is None:
            return None
            
        try:
            # è½‰ç°åº¦
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            else:
                gray = frame
                
            # ğŸ¯ å™ªè²æ¸›å°‘
            if self.noise_reduction:
                gray = cv2.medianBlur(gray, 5)
                
            # ğŸ¯ é‚Šç·£å¢å¼·
            if self.edge_enhancement:
                gray = cv2.addWeighted(gray, 1.5, cv2.GaussianBlur(gray, (0, 0), 2), -0.5, 0)
                
            # ğŸ¯ è‡ªé©æ‡‰äºŒå€¼åŒ–æˆ–å›ºå®šé–¾å€¼
            if self.adaptive_threshold:
                binary = cv2.adaptiveThreshold(
                    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                    cv2.THRESH_BINARY, 11, 2
                )
            else:
                _, binary = cv2.threshold(gray, self.threshold_value, 255, cv2.THRESH_BINARY)
            
            # å½¢æ…‹å­¸è™•ç†
            kernel = np.ones((self.morphology_kernel_size, self.morphology_kernel_size), np.uint8)
            processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            processed = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel)  # é¡å¤–çš„é–‹é‹ç®—å»é™¤å™ªé»
            
            return processed
            
        except Exception as e:
            logging.error(f"è™•ç†å¹€éŒ¯èª¤: {str(e)}")
            return None
    
    def detect_objects(self, processed_frame: np.ndarray, min_area: int = None, max_area: int = None) -> List[Tuple]:
        """è¼ªå»“æª¢æ¸¬"""
        if processed_frame is None:
            return []
            
        try:
            contours, _ = cv2.findContours(processed_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            objects = []
            min_a = min_area if min_area is not None else self.min_area
            max_a = max_area if max_area is not None else self.max_area
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                if min_a <= area <= max_a:
                    x, y, w, h = cv2.boundingRect(contour)
                    centroid_x = x + w // 2
                    centroid_y = y + h // 2
                    objects.append((x, y, w, h, (centroid_x, centroid_y), area, 0))
            
            return objects
            
        except Exception as e:
            logging.error(f"è¼ªå»“æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return []
    
    def set_parameters(self, params: Dict[str, Any]) -> bool:
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        try:
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            return True
        except Exception as e:
            logging.error(f"è¨­ç½®åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False


class HybridDetection(DetectionMethod):
    """æ··åˆæª¢æ¸¬æ–¹æ³• - çµåˆåœ“å½¢å’Œè¼ªå»“æª¢æ¸¬çš„å„ªé»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ··åˆæª¢æ¸¬"""
        self.circle_detector = CircleDetection()
        self.contour_detector = ContourDetection()
        
        # æ··åˆç­–ç•¥åƒæ•¸
        self.use_circle_primary = True  # å„ªå…ˆä½¿ç”¨åœ“å½¢æª¢æ¸¬
        self.confidence_threshold = 0.7  # ç½®ä¿¡åº¦é–¾å€¼
        self.merge_nearby_detections = True  # åˆä½µé„°è¿‘æª¢æ¸¬
        self.merge_distance_threshold = 50  # åˆä½µè·é›¢é–¾å€¼
        
        # è‡ªé©æ‡‰åƒæ•¸
        self.auto_switch_method = True  # æ ¹æ“šæª¢æ¸¬æ•ˆæœè‡ªå‹•åˆ‡æ›æ–¹æ³•
        self.circle_success_rate = 1.0  # åœ“å½¢æª¢æ¸¬æˆåŠŸç‡
        self.contour_success_rate = 1.0  # è¼ªå»“æª¢æ¸¬æˆåŠŸç‡
        
        logging.info("ğŸ”„ æ··åˆæª¢æ¸¬åˆå§‹åŒ–å®Œæˆ")
    
    def process_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """æ··åˆé è™•ç† - åŒæ™‚ç‚ºå…©ç¨®æª¢æ¸¬æ–¹æ³•æº–å‚™"""
        if frame is None:
            return None
        
        # è¿”å›åŸå§‹å¹€ï¼Œè®“å„å€‹æª¢æ¸¬æ–¹æ³•è‡ªå·±è™•ç†
        return frame
    
    def detect_objects(self, frame: np.ndarray, min_area: int = None, max_area: int = None) -> List[Tuple]:
        """æ··åˆæª¢æ¸¬ - æ™ºèƒ½çµåˆå¤šç¨®æ–¹æ³•"""
        if frame is None:
            return []
        
        try:
            circle_objects = []
            contour_objects = []
            
            # ğŸ¯ ä¸¦è¡Œæª¢æ¸¬ï¼ˆå¦‚æœæ€§èƒ½å…è¨±ï¼‰
            if self.use_circle_primary:
                # å…ˆå˜—è©¦åœ“å½¢æª¢æ¸¬
                processed_circle = self.circle_detector.process_frame(frame)
                if processed_circle is not None:
                    circle_objects = self.circle_detector.detect_objects(
                        processed_circle, min_area, max_area
                    )
                
                # å¦‚æœåœ“å½¢æª¢æ¸¬çµæœä¸ç†æƒ³ï¼Œè£œå……è¼ªå»“æª¢æ¸¬
                if len(circle_objects) == 0 or self.auto_switch_method:
                    processed_contour = self.contour_detector.process_frame(frame)
                    if processed_contour is not None:
                        contour_objects = self.contour_detector.detect_objects(
                            processed_contour, min_area, max_area
                        )
            else:
                # å„ªå…ˆè¼ªå»“æª¢æ¸¬
                processed_contour = self.contour_detector.process_frame(frame)
                if processed_contour is not None:
                    contour_objects = self.contour_detector.detect_objects(
                        processed_contour, min_area, max_area
                    )
                
                # è£œå……åœ“å½¢æª¢æ¸¬
                if len(contour_objects) == 0 or self.auto_switch_method:
                    processed_circle = self.circle_detector.process_frame(frame)
                    if processed_circle is not None:
                        circle_objects = self.circle_detector.detect_objects(
                            processed_circle, min_area, max_area
                        )
            
            # ğŸ¯ æ™ºèƒ½èåˆçµæœ
            final_objects = self._merge_detections(circle_objects, contour_objects)
            
            # ğŸ¯ æ›´æ–°æˆåŠŸç‡çµ±è¨ˆï¼ˆç”¨æ–¼è‡ªå‹•åˆ‡æ›æ–¹æ³•ï¼‰
            if self.auto_switch_method:
                self._update_success_rates(len(circle_objects), len(contour_objects))
            
            return final_objects
            
        except Exception as e:
            logging.error(f"æ··åˆæª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return []
    
    def _merge_detections(self, circle_objects: List[Tuple], contour_objects: List[Tuple]) -> List[Tuple]:
        """æ™ºèƒ½èåˆæª¢æ¸¬çµæœ"""
        if not self.merge_nearby_detections:
            # ç°¡å–®ç­–ç•¥ï¼šé¸æ“‡è¼ƒå¥½çš„çµæœ
            if len(circle_objects) >= len(contour_objects):
                return circle_objects
            else:
                return contour_objects
        
        # é«˜ç´šç­–ç•¥ï¼šåˆä½µé„°è¿‘æª¢æ¸¬ï¼Œå»é™¤é‡è¤‡
        all_objects = []
        all_objects.extend([(obj, 'circle') for obj in circle_objects])
        all_objects.extend([(obj, 'contour') for obj in contour_objects])
        
        if not all_objects:
            return []
        
        merged_objects = []
        used_indices = set()
        
        for i, (obj1, type1) in enumerate(all_objects):
            if i in used_indices:
                continue
                
            x1, y1, w1, h1, centroid1, area1, radius1 = obj1
            group = [obj1]
            used_indices.add(i)
            
            # å°‹æ‰¾é„°è¿‘çš„æª¢æ¸¬çµæœ
            for j, (obj2, type2) in enumerate(all_objects[i+1:], i+1):
                if j in used_indices:
                    continue
                    
                x2, y2, w2, h2, centroid2, area2, radius2 = obj2
                distance = np.sqrt((centroid1[0] - centroid2[0])**2 + (centroid1[1] - centroid2[1])**2)
                
                if distance < self.merge_distance_threshold:
                    group.append(obj2)
                    used_indices.add(j)
            
            # å¾ç¾¤çµ„ä¸­é¸æ“‡æœ€ä½³æª¢æ¸¬çµæœ
            if len(group) == 1:
                merged_objects.append(group[0])
            else:
                best_obj = self._select_best_detection(group)
                merged_objects.append(best_obj)
        
        return merged_objects
    
    def _select_best_detection(self, group: List[Tuple]) -> Tuple:
        """å¾ç¾¤çµ„ä¸­é¸æ“‡æœ€ä½³æª¢æ¸¬çµæœ"""
        # ç°¡å–®ç­–ç•¥ï¼šé¸æ“‡é¢ç©æœ€æ¥è¿‘ä¸­ä½æ•¸çš„æª¢æ¸¬çµæœ
        areas = [obj[5] for obj in group]  # area is at index 5
        median_area = np.median(areas)
        
        best_obj = group[0]
        min_diff = abs(best_obj[5] - median_area)
        
        for obj in group[1:]:
            diff = abs(obj[5] - median_area)
            if diff < min_diff:
                min_diff = diff
                best_obj = obj
        
        return best_obj
    
    def _update_success_rates(self, circle_count: int, contour_count: int):
        """æ›´æ–°æª¢æ¸¬æ–¹æ³•æˆåŠŸç‡çµ±è¨ˆ"""
        # ç°¡åŒ–çš„æˆåŠŸç‡è©•ä¼°
        decay_factor = 0.95  # è¡°æ¸›å› å­
        
        self.circle_success_rate = (self.circle_success_rate * decay_factor + 
                                  (1.0 if circle_count > 0 else 0.0) * (1 - decay_factor))
        self.contour_success_rate = (self.contour_success_rate * decay_factor + 
                                   (1.0 if contour_count > 0 else 0.0) * (1 - decay_factor))
        
        # è‡ªå‹•èª¿æ•´å„ªå…ˆæª¢æ¸¬æ–¹æ³•
        if self.circle_success_rate > self.contour_success_rate + 0.1:
            self.use_circle_primary = True
        elif self.contour_success_rate > self.circle_success_rate + 0.1:
            self.use_circle_primary = False
    
    def set_parameters(self, params: Dict[str, Any]) -> bool:
        """è¨­ç½®æ··åˆæª¢æ¸¬åƒæ•¸"""
        try:
            # æ›´æ–°è‡ªèº«åƒæ•¸
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            
            # å°‡ç›¸é—œåƒæ•¸å‚³éçµ¦å­æª¢æ¸¬å™¨
            self.circle_detector.set_parameters(params)
            self.contour_detector.set_parameters(params)
            
            return True
        except Exception as e:
            logging.error(f"è¨­ç½®æ··åˆæª¢æ¸¬åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False
    
    @property
    def name(self) -> str:
        return "HybridDetection"


class DetectionModel:
    """å½±åƒæª¢æ¸¬æ•¸æ“šæ¨¡å‹ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–æª¢æ¸¬æ¨¡å‹"""
        # å¯ç”¨æª¢æ¸¬æ–¹æ³•
        self.available_methods = {
            'circle': CircleDetection(),
            'contour': ContourDetection(),
            'hybrid': HybridDetection()  # ğŸ¯ æ–°å¢æ··åˆæª¢æ¸¬æ–¹æ³•
        }
        
        # ğŸš€ å˜—è©¦åŠ è¼‰èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•
        try:
            from .enhanced_detection_method import BackgroundSubtractionDetection
            self.available_methods['background'] = BackgroundSubtractionDetection()
            logging.info("âœ… èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•å·²è¼‰å…¥")
            background_available = True
        except Exception as e:
            logging.warning(f"âš ï¸ èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•ä¸å¯ç”¨: {str(e)}")
            background_available = False
        
        # ç•¶å‰æª¢æ¸¬æ–¹æ³• - å„ªå…ˆä½¿ç”¨èƒŒæ™¯æ¸›é™¤æª¢æ¸¬
        if background_available:
            self.current_method = self.available_methods['background']
            self.method_name = 'background'
            logging.info("ğŸ¯ é è¨­ä½¿ç”¨èƒŒæ™¯æ¸›é™¤æª¢æ¸¬æ–¹æ³•")
        else:
            self.current_method = self.available_methods['hybrid']
            self.method_name = 'hybrid'
            logging.info("ğŸ¯ é è¨­ä½¿ç”¨æ··åˆæª¢æ¸¬æ–¹æ³•")
        
        # æ•¸æ“šæºé¡å‹å’Œå°æ‡‰åƒæ•¸
        self.current_source_type = 'camera'  # camera, video
        self.source_params = {
            'camera': {
                'min_area': 100,
                'max_area': 5000,
                'resize_factor': 0.5,  # å·¥æ¥­ç›¸æ©Ÿé«˜ç²¾åº¦æ¨¡å¼
                'high_performance_mode': True
            },
            'video': {
                'min_area': 100,
                'max_area': 5000,
                'resize_factor': 0.5,  # ğŸ¯ è¦–é »å›æ”¾ä¹Ÿä½¿ç”¨é«˜ç²¾åº¦ï¼ˆGPUåŠ é€Ÿè£œå„Ÿï¼‰
                'high_performance_mode': True,  # ğŸš€ å•Ÿç”¨é«˜æ€§èƒ½æ¨¡å¼
                'gpu_optimized': True  # ğŸ¯ è¦–é »æ¨¡å¼å„ªå…ˆä½¿ç”¨GPU
            }
        }
        
        # æª¢æ¸¬åƒæ•¸ - æ ¹æ“šç•¶å‰æ•¸æ“šæºå‹•æ…‹è¨­å®š
        self.detection_params = {
            'enable_detection': True,
            **self.source_params['camera']  # é è¨­ä½¿ç”¨ç›¸æ©Ÿåƒæ•¸
        }
        
        # æª¢æ¸¬çµæœ
        self.latest_objects = []
        self.object_count = 0
        self.detection_lock = threading.Lock()
        
        # æ€§èƒ½çµ±è¨ˆ
        self.detection_times = deque(maxlen=100)
        self.detection_fps = 0.0
        
        # è§€å¯Ÿè€…æ¨¡å¼
        self.observers = []
        
        logging.info("æª¢æ¸¬æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def add_observer(self, observer: Callable):
        """æ·»åŠ è§€å¯Ÿè€…"""
        self.observers.append(observer)
    
    def notify_observers(self, event_type: str, data: Any = None):
        """é€šçŸ¥è§€å¯Ÿè€…"""
        for observer in self.observers:
            try:
                observer(event_type, data)
            except Exception as e:
                logging.error(f"é€šçŸ¥è§€å¯Ÿè€…éŒ¯èª¤: {str(e)}")
    
    def set_detection_method(self, method_name: str) -> bool:
        """è¨­ç½®æª¢æ¸¬æ–¹æ³•"""
        if method_name in self.available_methods:
            self.current_method = self.available_methods[method_name]
            self.method_name = method_name
            logging.info(f"åˆ‡æ›æª¢æ¸¬æ–¹æ³•: {method_name}")
            self.notify_observers('method_changed', method_name)
            return True
        return False
    
    def set_source_type(self, source_type: str, video_info: Dict[str, Any] = None) -> bool:
        """è¨­ç½®æ•¸æ“šæºé¡å‹ï¼šcamera æˆ– videoï¼Œæ”¯æŒå‹•æ…‹åƒæ•¸èª¿æ•´"""
        if source_type not in ['camera', 'video']:
            logging.error(f"ä¸æ”¯æŒçš„æ•¸æ“šæºé¡å‹: {source_type}")
            return False
            
        self.current_source_type = source_type
        
        if source_type == 'video' and video_info:
            # ğŸ¯ æ–°åŠŸèƒ½ï¼šæ ¹æ“šå¯¦éš›è¦–é »æ•¸æ“šå‹•æ…‹èª¿æ•´åƒæ•¸
            optimized_params = self._analyze_video_and_optimize_params(video_info)
            source_params = optimized_params
            
            logging.info(f"ğŸ¬ æ ¹æ“šè¦–é »è¦æ ¼å‹•æ…‹å„ªåŒ–åƒæ•¸:")
            logging.info(f"è§£æåº¦: {video_info.get('width', 'N/A')}x{video_info.get('height', 'N/A')}")
            logging.info(f"FPS: {video_info.get('fps', 'N/A'):.2f}")
            logging.info(f"å„ªåŒ–å¾Œåƒæ•¸: {optimized_params}")
        else:
            # ä½¿ç”¨é è¨­åƒæ•¸
            source_params = self.source_params[source_type]
            logging.info(f"ä½¿ç”¨é è¨­åƒæ•¸: {source_params}")
        
        # æ›´æ–°æª¢æ¸¬åƒæ•¸
        self.detection_params.update(source_params)
        
        # åŒæ™‚æ›´æ–°ç•¶å‰æª¢æ¸¬æ–¹æ³•çš„åƒæ•¸
        self.current_method.set_parameters(source_params)
        
        logging.info(f"æ•¸æ“šæºå·²åˆ‡æ›ç‚º: {source_type}")
        
        self.notify_observers('source_type_changed', {
            'source_type': source_type,
            'params': source_params,
            'video_info': video_info
        })
        
        return True
    
    def _analyze_video_and_optimize_params(self, video_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ“šè¦–é »å¯¦éš›æ•¸æ“šåˆ†æä¸¦å„ªåŒ–æª¢æ¸¬åƒæ•¸"""
        try:
            # ç²å–è¦–é »å¯¦éš›è¦æ ¼
            width = video_info.get('width', 640)
            height = video_info.get('height', 480)
            fps = video_info.get('fps', 30.0)
            codec = video_info.get('codec', 'unknown')
            total_frames = video_info.get('total_frames', 0)
            
            # è¨ˆç®—è§£æåº¦ç­‰ç´š
            resolution_pixels = width * height
            
            # ğŸ¯ æ ¹æ“šè§£æåº¦å‹•æ…‹èª¿æ•´åƒæ•¸
            if resolution_pixels >= 1920 * 1080:  # 1080pä»¥ä¸Š
                resize_factor = 0.3  # é«˜è§£æåº¦ï¼Œå¤§å¹…ç¸®å°
                min_radius = 15
                max_radius = 80
                min_area = 200
                max_area = 8000
                logging.info("ğŸ“º é«˜è§£æåº¦è¦–é »ï¼Œä½¿ç”¨å„ªåŒ–åƒæ•¸")
            elif resolution_pixels >= 1280 * 720:  # 720p
                resize_factor = 0.4
                min_radius = 10
                max_radius = 60
                min_area = 150
                max_area = 6000
                logging.info("ğŸ“º ä¸­è§£æåº¦è¦–é »ï¼Œä½¿ç”¨æ¨™æº–åƒæ•¸")
            else:  # 480påŠä»¥ä¸‹
                resize_factor = 0.6
                min_radius = 5
                max_radius = 40
                min_area = 80
                max_area = 4000
                logging.info("ğŸ“º ä½è§£æåº¦è¦–é »ï¼Œä½¿ç”¨ç²¾ç´°åƒæ•¸")
            
            # ğŸ¯ æ ¹æ“š FPS èª¿æ•´æ€§èƒ½åƒæ•¸ - æ›´ç´°ç·»çš„åˆ†ç´š
            if fps >= 120:
                # è¶…é«˜å¹€ç‡ï¼Œæ¥µå„ªå…ˆæ€§èƒ½
                dp = 4.0
                param1 = 150
                param2 = 100
                logging.info(f"âš¡ è¶…é«˜å¹€ç‡è¦–é » ({fps:.1f} fps)ï¼Œæ¥µå„ªå…ˆæ€§èƒ½")
            elif fps >= 60:
                # é«˜å¹€ç‡ï¼Œå„ªå…ˆæ€§èƒ½
                dp = 3.0
                param1 = 120
                param2 = 80
                logging.info(f"ğŸš€ é«˜å¹€ç‡è¦–é » ({fps:.1f} fps)ï¼Œå„ªå…ˆæ€§èƒ½")
            elif fps >= 30:
                # æ¨™æº–å¹€ç‡ï¼Œå¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
                dp = 2.5
                param1 = 100
                param2 = 65
                logging.info(f"ğŸ“º æ¨™æº–å¹€ç‡è¦–é » ({fps:.1f} fps)ï¼Œå¹³è¡¡æ¨¡å¼")
            elif fps >= 15:
                # ä½å¹€ç‡ï¼Œå„ªå…ˆç²¾åº¦
                dp = 2.0
                param1 = 80
                param2 = 50
                logging.info(f"ğŸ” ä½å¹€ç‡è¦–é » ({fps:.1f} fps)ï¼Œå„ªå…ˆç²¾åº¦")
            else:
                # æ¥µä½å¹€ç‡ï¼Œæœ€é«˜ç²¾åº¦
                dp = 1.5
                param1 = 60
                param2 = 40
                logging.info(f"ğŸ”¬ æ¥µä½å¹€ç‡è¦–é » ({fps:.1f} fps)ï¼Œæœ€é«˜ç²¾åº¦")
            
            # ğŸ¯ æ ¹æ“šç·¨ç¢¼æ ¼å¼èª¿æ•´
            blur_kernel = 3  # é è¨­
            if codec.lower() in ['h264', 'h265', 'hevc']:
                blur_kernel = 5  # å£“ç¸®ç·¨ç¢¼ï¼Œå¢åŠ æ¨¡ç³Šä»¥æ¸›å°‘å™ªé»
                logging.info(f"ğŸ¥ å£“ç¸®ç·¨ç¢¼ ({codec})ï¼Œèª¿æ•´æ¨¡ç³Šåƒæ•¸")
            
            # ğŸ¯ çµ„åˆå„ªåŒ–åƒæ•¸
            optimized_params = {
                'min_area': min_area,
                'max_area': max_area,
                'resize_factor': resize_factor,
                'high_performance_mode': True,
                'gpu_optimized': True,
                # CircleDetection åƒæ•¸
                'dp': dp,
                'min_dist': int(30 * resize_factor),  # æŒ‰ç¸®æ”¾æ¯”ä¾‹èª¿æ•´
                'param1': param1,
                'param2': param2,
                'min_radius': min_radius,
                'max_radius': max_radius,
                'blur_kernel': blur_kernel,
                # è¦–é »è¦æ ¼ä¿¡æ¯ç”¨æ–¼è¨˜éŒ„
                'source_resolution': f"{width}x{height}",
                'source_fps': fps,
                'source_codec': codec
            }
            
            return optimized_params
            
        except Exception as e:
            logging.error(f"åˆ†æè¦–é »åƒæ•¸å¤±æ•—: {e}")
            # è¿”å›å®‰å…¨çš„é è¨­åƒæ•¸
            return self.source_params['video'].copy()
    
    def update_parameters(self, params: Dict[str, Any]) -> bool:
        """æ›´æ–°æª¢æ¸¬åƒæ•¸"""
        try:
            self.detection_params.update(params)
            
            # æ›´æ–°ç•¶å‰æª¢æ¸¬æ–¹æ³•çš„åƒæ•¸
            method_params = {k: v for k, v in params.items() 
                           if k not in ['min_area', 'max_area', 'enable_detection']}
            
            if method_params:
                self.current_method.set_parameters(method_params)
            
            self.notify_observers('parameters_updated', self.detection_params)
            return True
        except Exception as e:
            logging.error(f"æ›´æ–°åƒæ•¸éŒ¯èª¤: {str(e)}")
            return False
    
    def detect_frame(self, frame: np.ndarray) -> Tuple[List[Tuple], np.ndarray]:
        """æª¢æ¸¬å–®å¹€ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
        if frame is None or not self.detection_params.get('enable_detection', True):
            return [], frame
        
        start_time = time.time()
        
        try:
            # é è™•ç†
            processed_frame = self.current_method.process_frame(frame)
            if processed_frame is None:
                return [], frame
            
            # æª¢æ¸¬ç‰©ä»¶
            objects = self.current_method.detect_objects(
                processed_frame,
                self.detection_params.get('min_area'),
                self.detection_params.get('max_area')
            )
            
            # æ›´æ–°çµæœ
            with self.detection_lock:
                self.latest_objects = objects
                self.object_count = len(objects)
            
            # æ›´æ–°æ€§èƒ½çµ±è¨ˆ - é˜²æ­¢è¨˜æ†¶é«”æ´©æ¼
            detection_time = time.time() - start_time
            self.detection_times.append(detection_time)
            
            # é™åˆ¶åˆ—è¡¨å¤§å°ï¼Œé˜²æ­¢è¨˜æ†¶é«”ç„¡é™å¢é•·
            if len(self.detection_times) > 100:  # ä¿æŒæœ€æ–°100æ¬¡æª¢æ¸¬æ™‚é–“
                self.detection_times.pop(0)
            
            if len(self.detection_times) >= 10:
                avg_time = sum(self.detection_times) / len(self.detection_times)
                self.detection_fps = 1.0 / avg_time if avg_time > 0 else 0
            
            # ğŸš€ æ€§èƒ½å„ªåŒ–ï¼šåªåœ¨éœ€è¦æ™‚è¤‡è£½å¹€
            if len(objects) > 0:
                # æœ‰æª¢æ¸¬çµæœæ™‚æ‰è¤‡è£½å’Œç¹ªè£½
                result_frame = self._draw_detections(frame.copy(), objects)
            else:
                # ç„¡æª¢æ¸¬çµæœæ™‚ç›´æ¥åœ¨åŸåœ–ä¸Šç¹ªè£½è¨ˆæ•¸
                result_frame = frame
                cv2.putText(result_frame, f'Count: 0', 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            
            # é€šçŸ¥è§€å¯Ÿè€…
            self.notify_observers('detection_completed', {
                'object_count': len(objects),
                'detection_fps': self.detection_fps,
                'objects': objects
            })
            
            return objects, result_frame
            
        except Exception as e:
            logging.error(f"æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return [], frame
    
    def _draw_detections(self, frame: np.ndarray, objects: List[Tuple]) -> np.ndarray:
        """ç¹ªè£½æª¢æ¸¬çµæœ"""
        try:
            for obj in objects:
                x, y, w, h, centroid, area, radius = obj
                
                # ç¹ªè£½é‚Šç•Œæ¡†
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # ç¹ªè£½ä¸­å¿ƒé»
                cv2.circle(frame, centroid, 3, (255, 0, 0), -1)
                
                # å¦‚æœæ˜¯åœ“æª¢æ¸¬ï¼Œç¹ªè£½åœ“
                if self.method_name == 'circle' and radius > 0:
                    cv2.circle(frame, centroid, int(radius), (0, 0, 255), 2)
                
                # æ¨™è¨»é¢ç©
                cv2.putText(frame, f'{int(area)}', 
                           (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # é¡¯ç¤ºç¸½æ•¸
            cv2.putText(frame, f'Count: {len(objects)}', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            
            return frame
            
        except Exception as e:
            logging.error(f"ç¹ªè£½æª¢æ¸¬çµæœéŒ¯èª¤: {str(e)}")
            return frame
    
    def get_latest_results(self) -> Dict[str, Any]:
        """ç²å–æœ€æ–°æª¢æ¸¬çµæœ"""
        with self.detection_lock:
            return {
                'objects': self.latest_objects.copy(),
                'count': self.object_count,
                'method': self.method_name,
                'detection_fps': self.detection_fps,
                'parameters': self.detection_params.copy()
            }
    
    def get_available_methods(self) -> List[str]:
        """ç²å–å¯ç”¨æª¢æ¸¬æ–¹æ³•"""
        return list(self.available_methods.keys())
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–æª¢æ¸¬çµ±è¨ˆ"""
        return {
            'current_method': self.method_name,
            'object_count': self.object_count,
            'detection_fps': self.detection_fps,
            'available_methods': self.get_available_methods(),
            'parameters': self.detection_params.copy()
        }