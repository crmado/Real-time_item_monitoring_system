"""
å°é›¶ä»¶æª¢æ¸¬æ§åˆ¶å™¨ - åŸºæ–¼ basler_mvc çš„èƒŒæ™¯æ¸›é™¤ç®—æ³•
æ•´åˆ SORT è¿½è¹¤ç®—æ³•ï¼ˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨ + åŒˆç‰™åˆ©ç®—æ³•ï¼‰
"""

import cv2
import numpy as np
import logging
import os
from typing import List, Dict, Any, Tuple, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

# å˜—è©¦å°å…¥ SORT è¿½è¹¤å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    from .kalman_tracker import (
        KalmanBoxTracker,
        associate_detections_to_trackers
    )
    SORT_AVAILABLE = True
    logger.info("âœ… SORT è¿½è¹¤ç®—æ³•å·²å•Ÿç”¨ï¼ˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨ + åŒˆç‰™åˆ©ç®—æ³•ï¼‰")
except ImportError as e:
    SORT_AVAILABLE = False
    logger.warning(f"âš ï¸ SORT è¿½è¹¤ç®—æ³•ä¸å¯ç”¨ï¼ˆç¼ºå°‘ä¾è³´ï¼‰: {e}")
    logger.warning("   è«‹å®‰è£: pip install filterpy scipy")


class DetectionController:
    """å°é›¶ä»¶æª¢æ¸¬æ§åˆ¶å™¨ - èƒŒæ™¯æ¸›é™¤ + ç‰©ä»¶è¿½è¹¤"""

    def __init__(self, use_sort=False):  # ç¦ç”¨ SORTï¼Œä½¿ç”¨å‚³çµ±è¿½è¹¤
        self.enabled = False
        self.detected_objects: List[Dict] = []

        # ğŸš€ é«˜é€Ÿæª¢æ¸¬æ¨¡å¼æ§åˆ¶
        self.ultra_high_speed_mode = False
        self.target_fps = 280

        # ğŸ¯ SORT è¿½è¹¤ç®—æ³•æ§åˆ¶
        self.use_sort = use_sort and SORT_AVAILABLE
        self.kalman_trackers: List[KalmanBoxTracker] = [] if self.use_sort else None
        self.max_age = 3  # è¿½è¹¤å™¨æœ€å¤§æœªåŒ¹é…å¹€æ•¸
        self.min_hits = 3  # é–‹å§‹è¨ˆæ•¸å‰çš„æœ€å°å‘½ä¸­æ¬¡æ•¸
        self.iou_threshold = 0.3  # IOU åŒ¹é…é–¾å€¼

        # ğŸ¯ æ¥µå°é›¶ä»¶æª¢æ¸¬åƒæ•¸ - åŸºæ–¼ basler_mvc
        self.min_area = 1           # ğŸ”§ é™ä½æœ€å°é¢ç©æ•æ‰æ›´å°é›¶ä»¶ (2â†’1)
        self.max_area = 5000        # ğŸ”§ æé«˜æœ€å¤§é¢ç©é¿å…éæ¿¾ (3000â†’5000)

        # ç‰©ä»¶å½¢ç‹€éæ¿¾åƒæ•¸ - ç‚ºå°é›¶ä»¶æ”¾å¯¬æ¢ä»¶
        self.min_aspect_ratio = 0.001  # æ¥µåº¦å¯¬é¬†çš„é•·å¯¬æ¯”
        self.max_aspect_ratio = 100.0
        self.min_extent = 0.001        # æ¥µåº¦é™ä½å¡«å……æ¯”ä¾‹è¦æ±‚
        self.max_solidity = 5.0        # æ¥µåº¦æ”¾å¯¬çµå¯¦æ€§é™åˆ¶

        # ğŸ¯ è¶…ç©©å®šèƒŒæ™¯æ¸›é™¤ - å°ˆç‚ºå°é›¶ä»¶é•·æœŸæª¢æ¸¬å„ªåŒ–
        self.bg_history = 500           # ğŸ”§ é™ä½æ­·å²å¹€æ•¸åŠ å¿«èƒŒæ™¯å»ºç«‹ (1000â†’500)
        self.bg_var_threshold = 2       # ğŸ”§ é€²ä¸€æ­¥é™ä½é–¾å€¼æé«˜æ•æ„Ÿåº¦ (3â†’2)
        self.detect_shadows = False
        self.bg_learning_rate = 0.0005  # ğŸ”§ é™ä½å­¸ç¿’ç‡é¿å…å°é›¶ä»¶è¢«ç´å…¥èƒŒæ™¯ (0.001â†’0.0005)

        # ğŸš€ é«˜é€Ÿæ¨¡å¼åƒæ•¸
        self.high_speed_bg_history = 100
        self.high_speed_bg_var_threshold = 8
        self.high_speed_min_area = 1
        self.high_speed_max_area = 2000
        self.high_speed_binary_threshold = 3

        # ğŸ¯ æ¥µé«˜æ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
        self.gaussian_blur_kernel = (1, 1)  # æœ€å°æ¨¡ç³Šä¿ç•™æœ€å¤šç´°ç¯€
        self.canny_low_threshold = 2        # ğŸ”§ é€²ä¸€æ­¥é™ä½é–¾å€¼ (3â†’2)
        self.canny_high_threshold = 8       # ğŸ”§ é€²ä¸€æ­¥é™ä½é–¾å€¼ (10â†’8)
        self.binary_threshold = 1           # æ¥µä½é–¾å€¼æé«˜æ•æ„Ÿåº¦

        # ğŸ” åˆ†é›¢å„ªåŒ–çš„å½¢æ…‹å­¸è™•ç†
        self.dilate_kernel_size = (1, 1)    # æœ€å°æ ¸é¿å…éåº¦è†¨è„¹
        self.dilate_iterations = 0           # ç¦ç”¨è†¨è„¹ä»¥ä¿ç•™å°é›¶ä»¶
        self.close_kernel_size = (1, 1)     # ç¦ç”¨é–‰åˆé¿å…é›¶ä»¶ç²˜é€£
        self.enable_watershed_separation = True  # å•Ÿç”¨åˆ†æ°´å¶ºåˆ†é›¢ç®—æ³•

        # ğŸ¯ æœ€å°åŒ–é›œè¨Šéæ¿¾
        self.opening_kernel_size = (1, 1)   # æœ€å°é–‹é‹ç®—æ ¸
        self.opening_iterations = 0          # ç¦ç”¨é–‹é‹ç®—ä»¥ä¿ç•™å°é›¶ä»¶

        # é€£é€šçµ„ä»¶åƒæ•¸
        self.connectivity = 4  # 4-é€£é€šæˆ–8-é€£é€š

        # ğŸ¯ ROI æª¢æ¸¬å€åŸŸåƒæ•¸
        self.roi_enabled = True
        self.roi_height = 150  # ğŸ”§ æ“´å¤§ ROI å€åŸŸé«˜åº¦ (120â†’150)
        self.roi_position_ratio = 0.10  # ğŸ”§ ç¨å¾®ä¸Šç§» ROI ä½ç½® (0.12â†’0.10)
        self.current_roi_y = 0
        self.current_roi_height = 150

        # ğŸ¯ ç‰©ä»¶è¿½è¹¤å’Œè¨ˆæ•¸åƒæ•¸
        self.enable_crossing_count = True
        self.crossing_tolerance_x = 35
        self.crossing_tolerance_y = 50

        # è¿½è¹¤ç©©å®šæ€§åƒæ•¸
        self.track_lifetime = 20
        self.min_track_frames = 3  # ğŸ¯ èˆ‡ MVC ä¸€è‡´ï¼šç¢ºä¿ç©©å®šè¿½è¹¤
        self.crossing_threshold = 0.12
        self.confidence_threshold = 0.10

        # é˜²é‡è¤‡æ©Ÿåˆ¶
        self.counted_objects_history = []
        self.history_length = 25
        self.duplicate_distance_threshold = 30  # ğŸ”§ èˆ‡ MVC ä¸€è‡´
        self.temporal_tolerance = 12  # ğŸ”§ èˆ‡ MVC ä¸€è‡´

        # ç©ºé–“ç¶²æ ¼è¿½è¹¤
        self.position_based_tracking = True  # ğŸ¯ èˆ‡ MVC ä¸€è‡´ï¼šå•Ÿç”¨ä½ç½®è¿½è¹¤
        self.spatial_grid = {}
        self.grid_cell_size = 30  # ğŸ¯ èˆ‡ MVC ä¸€è‡´

        # è¿½è¹¤ç‹€æ…‹
        self.object_tracks = {}
        self.lost_tracks = {}
        self.crossing_counter = 0
        self.frame_width = 640
        self.frame_height = 480
        self.current_frame_count = 0
        self.total_processed_frames = 0

        # èƒŒæ™¯æ¸›é™¤å™¨
        self.bg_subtractor = None
        self._reset_background_subtractor()

        # ğŸ“¸ èª¿è©¦åœ–ç‰‡åŠŸèƒ½
        self.debug_save_enabled = False
        self.debug_save_dir = "basler_pyqt6/recordings/debug"
        self.debug_frame_counter = 0
        self.max_debug_frames = 100

        # è¼¸å‡ºè¿½è¹¤ç®—æ³•ç‹€æ…‹
        logger.info("âœ… æª¢æ¸¬æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ (åŸºæ–¼ basler_mvc ç®—æ³•)")
        logger.info(f"â„¹ï¸ ä½¿ç”¨{'SORT' if self.use_sort else 'å‚³çµ±'}è¿½è¹¤ç®—æ³•")

    def _reset_background_subtractor(self):
        """é‡ç½®èƒŒæ™¯æ¸›é™¤å™¨"""
        if self.ultra_high_speed_mode:
            history = self.high_speed_bg_history
            var_threshold = self.high_speed_bg_var_threshold
        else:
            history = self.bg_history
            var_threshold = self.bg_var_threshold

        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=history,
            varThreshold=var_threshold,
            detectShadows=self.detect_shadows
        )
        self.current_learning_rate = self.bg_learning_rate
        logger.debug(f"èƒŒæ™¯æ¸›é™¤å™¨å·²é‡ç½®: history={history}, var_threshold={var_threshold}")

    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        è™•ç†å¹€ä¸¦åŸ·è¡Œå°é›¶ä»¶æª¢æ¸¬

        Returns:
            (è™•ç†å¾Œçš„åœ–åƒ, æª¢æ¸¬çµæœåˆ—è¡¨)
        """
        if frame is None or not self.enabled:
            return frame, []

        try:
            self.total_processed_frames += 1
            self.frame_height, self.frame_width = frame.shape[:2]

            # ğŸ¯ ROI å€åŸŸæå–
            if self.roi_enabled:
                roi_y = int(self.frame_height * self.roi_position_ratio)
                process_region = frame[roi_y:roi_y + self.roi_height, :]
                self.current_roi_y = roi_y
                self.current_roi_height = self.roi_height
            else:
                process_region = frame
                self.current_roi_y = 0
                self.current_roi_height = self.frame_height

            # åŸ·è¡Œæª¢æ¸¬è™•ç†
            if self.ultra_high_speed_mode:
                processed = self._ultra_high_speed_processing(process_region)
            else:
                processed = self._standard_processing(process_region)

            # æª¢æ¸¬ç‰©ä»¶
            detected_objects = self._detect_objects(processed)

            # ğŸ› èª¿è©¦ï¼šæ¯ 500 å¹€è¼¸å‡ºå®Œæ•´è¨ºæ–·å ±å‘Š
            if self.total_processed_frames % 500 == 0:
                logger.info(f"{'='*60}")
                logger.info(f"ğŸ” è¨ºæ–·å ±å‘Š - ç¬¬ {self.total_processed_frames} å¹€")
                logger.info(f"{'='*60}")
                logger.info(f"ğŸ“Š [æœ€çµ‚çµæœ] å¹€{self.total_processed_frames}: "
                          f"æª¢æ¸¬åˆ° {len(detected_objects)} å€‹ç‰©ä»¶, "
                          f"è¿½è¹¤ç®—æ³•: {'SORT' if self.use_sort else 'å‚³çµ±'}, "
                          f"ç•¶å‰è¨ˆæ•¸: {self.crossing_counter}")
                logger.info(f"{'='*60}")

            # åŸ·è¡Œç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸
            if self.enable_crossing_count and len(detected_objects) > 0:
                if self.use_sort:
                    # ä½¿ç”¨ SORT ç®—æ³•ï¼ˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨ + åŒˆç‰™åˆ©ç®—æ³•ï¼‰
                    self._update_object_tracking_sort(detected_objects)
                else:
                    # ä½¿ç”¨å‚³çµ±è¿½è¹¤ç®—æ³•
                    tracking_objects = []
                    for obj in detected_objects:
                        x, y, w, h = obj['x'], obj['y'], obj['w'], obj['h']
                        cx, cy = obj['cx'], obj['cy']
                        area = obj['area']
                        radius = max(w, h) // 2
                        tracking_objects.append((x, y, w, h, (cx, cy), area, radius))
                    self._update_object_tracking(tracking_objects)

            # ç¹ªè£½çµæœ
            result_frame = self._draw_detection_results(frame.copy(), detected_objects)

            self.detected_objects = detected_objects
            return result_frame, detected_objects

        except Exception as e:
            logger.error(f"âŒ æª¢æ¸¬å¤±æ•—: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return frame, []

    def _standard_processing(self, process_region: np.ndarray) -> np.ndarray:
        """æ¨™æº–æ¨¡å¼è™•ç†æµç¨‹ - å®Œæ•´çš„å¤šé‡æª¢æ¸¬ç­–ç•¥ (åŸºæ–¼ basler_mvc)"""
        # 1. èƒŒæ™¯æ¸›é™¤ç²å¾—å‰æ™¯é®ç½©
        fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)

        # ğŸ› èª¿è©¦ï¼šæª¢æŸ¥å‰æ™¯é®ç½©
        if self.total_processed_frames % 500 == 0:
            fg_pixels = cv2.countNonZero(fg_mask)
            roi_total = process_region.shape[0] * process_region.shape[1]
            fg_ratio = (fg_pixels / roi_total * 100) if roi_total > 0 else 0
            logger.info(f"  âŠ [èƒŒæ™¯æ¸›é™¤] å‰æ™¯åƒç´ ={fg_pixels} ({fg_ratio:.2f}%), å­¸ç¿’ç‡={self.current_learning_rate}")

        # 2. é«˜æ–¯æ¨¡ç³Šæ¸›å°‘å™ªè²
        blurred = cv2.GaussianBlur(process_region, self.gaussian_blur_kernel, 0)

        # 3. Cannyé‚Šç·£æª¢æ¸¬
        edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)

        # 4. å¤šè§’åº¦æª¢æ¸¬ç­–ç•¥
        # æ–¹æ³•1: æ¥µåº¦æº«å’Œçš„å‰æ™¯é®ç½©è™•ç† - é‡å°å°é›¶ä»¶å„ªåŒ–
        # ğŸ”§ é—œéµä¿®æ­£ï¼šä½¿ç”¨æœ€å°æ ¸å¿ƒé¿å…æ¶ˆé™¤å°é›¶ä»¶
        tiny_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))  # 5â†’2: æ¥µå°æ ¸å¿ƒ
        fg_cleaned = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, tiny_kernel, iterations=1)  # åªåšä¸€æ¬¡é–‰åˆå¡«å……å°å­”
        # âŒ ç§»é™¤æ‰€æœ‰é–‹é‹ç®—å’Œä¸­å€¼æ¿¾æ³¢ - å®ƒå€‘æœƒæ¶ˆé™¤å°é›¶ä»¶

        # æ–¹æ³•2: å¤šæ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
        strong_edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
        sensitive_edges = cv2.Canny(blurred, self.canny_low_threshold//2, self.canny_high_threshold//2)

        # æ–¹æ³•3: è‡ªé©æ‡‰é–¾å€¼æª¢æ¸¬
        gray_roi = cv2.cvtColor(process_region, cv2.COLOR_BGR2GRAY) if len(process_region.shape) == 3 else process_region
        adaptive_thresh = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                                cv2.THRESH_BINARY, 11, 2)

        # 5. é‚Šç·£å¢å¼·
        edge_enhanced = cv2.bitwise_and(sensitive_edges, sensitive_edges, mask=fg_cleaned)
        _, edge_thresh = cv2.threshold(edge_enhanced, 1, 255, cv2.THRESH_BINARY)

        adaptive_enhanced = cv2.bitwise_and(adaptive_thresh, adaptive_thresh, mask=fg_cleaned)
        _, adaptive_thresh_clean = cv2.threshold(adaptive_enhanced, 127, 255, cv2.THRESH_BINARY)

        # 6. ä¸‰é‡è¯åˆæª¢æ¸¬
        temp_combined = cv2.bitwise_or(fg_cleaned, edge_thresh)
        combined = cv2.bitwise_or(temp_combined, adaptive_thresh_clean)

        # 7. æ¥µåº¦ç°¡åŒ–å½¢æ…‹å­¸è™•ç† - æœ€å¤§åŒ–ä¿ç•™å°é›¶ä»¶
        if self.opening_kernel_size != (1, 1):
            opening_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.opening_kernel_size)
            opened_stage1 = cv2.morphologyEx(combined, cv2.MORPH_OPEN, opening_kernel, iterations=self.opening_iterations)
        else:
            opened_stage1 = combined.copy()

        # æœ€å°åŒ–è†¨è„¹
        if self.dilate_kernel_size != (1, 1) and self.dilate_iterations > 0:
            dilate_kernel = np.ones(self.dilate_kernel_size, np.uint8)
            dilated = cv2.dilate(opened_stage1, dilate_kernel, iterations=self.dilate_iterations)
        else:
            dilated = opened_stage1.copy()

        # é—œéµï¼šæœ€å°åŒ–é–‰åˆé‹ç®—
        if self.close_kernel_size != (1, 1):
            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.close_kernel_size)
            processed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, close_kernel, iterations=1)
        else:
            processed = dilated.copy()

        # ğŸ› èª¿è©¦ï¼šæª¢æŸ¥æœ€çµ‚è™•ç†çµæœ
        if self.total_processed_frames % 500 == 0:
            # æª¢æŸ¥å„éšæ®µåƒç´ æ•¸
            fg_cleaned_pixels = cv2.countNonZero(fg_cleaned)
            combined_pixels = cv2.countNonZero(combined)
            processed_pixels = cv2.countNonZero(processed)

            logger.info(f"  â‹ [å½¢æ…‹è™•ç†] æ¸…ç†å¾Œ={fg_cleaned_pixels}px, è¯åˆæª¢æ¸¬={combined_pixels}px, æœ€çµ‚={processed_pixels}px")

        return processed

    def _ultra_high_speed_processing(self, process_region: np.ndarray) -> np.ndarray:
        """è¶…é«˜é€Ÿè™•ç†æ¨¡å¼ - ç°¡åŒ–æµç¨‹"""
        fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)
        kernel = np.ones((3, 3), np.uint8)
        processed = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        processed = cv2.dilate(processed, kernel, iterations=1)
        return processed

    def _detect_objects(self, processed: np.ndarray) -> List[Dict]:
        """æª¢æ¸¬ç‰©ä»¶ - ä½¿ç”¨é€£é€šçµ„ä»¶åˆ†æ"""
        if processed is None:
            return []

        try:
            # ä½¿ç”¨é€£é€šçµ„ä»¶åˆ†æ
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                processed, connectivity=self.connectivity
            )

            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„é€£é€šçµ„ä»¶ä¿¡æ¯
            if self.total_processed_frames % 500 == 0:
                min_area = self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area
                max_area = self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area

                # çµ±è¨ˆçµ„ä»¶é¢ç©åˆ†ä½ˆ
                if num_labels > 1:
                    all_areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]
                    areas_in_range = [a for a in all_areas if min_area <= a <= max_area]

                    logger.info(f"ğŸ“Š [é€£é€šçµ„ä»¶] å¹€{self.total_processed_frames}: "
                              f"ç¸½çµ„ä»¶={num_labels-1}, "
                              f"é¢ç©ç¯„åœå…§={len(areas_in_range)}, "
                              f"ç¯„åœ=[{min_area}, {max_area}]")

                    if all_areas:
                        area_stats = {
                            'æœ€å°': min(all_areas),
                            'æœ€å¤§': max(all_areas),
                            'å¹³å‡': int(sum(all_areas) / len(all_areas))
                        }
                        logger.info(f"   é¢ç©çµ±è¨ˆ: {area_stats}")
                        # é¡¯ç¤ºå‰10å€‹çµ„ä»¶çš„é¢ç©
                        sample_areas = sorted(all_areas)[:10]
                        logger.info(f"   å‰10å€‹çµ„ä»¶é¢ç©: {sample_areas}")
                else:
                    logger.warning(f"âš ï¸ [é€£é€šçµ„ä»¶] å¹€{self.total_processed_frames}: æ²’æœ‰æª¢æ¸¬åˆ°ä»»ä½•çµ„ä»¶ï¼")

            detected_objects = []
            min_area = self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area
            max_area = self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area

            # ğŸ” çµ±è¨ˆéæ¿¾ä¿¡æ¯
            filter_stats = {
                'total': num_labels - 1,
                'area_filtered': 0,
                'shape_filtered': 0,
                'passed': 0
            }

            for i in range(1, num_labels):  # è·³éèƒŒæ™¯ (label 0)
                area = stats[i, cv2.CC_STAT_AREA]

                # é¢ç©éæ¿¾
                if area < min_area or area > max_area:
                    filter_stats['area_filtered'] += 1
                    continue

                x = stats[i, cv2.CC_STAT_LEFT]
                y = stats[i, cv2.CC_STAT_TOP] + self.current_roi_y  # åŠ ä¸Š ROI åç§»
                w = stats[i, cv2.CC_STAT_WIDTH]
                h = stats[i, cv2.CC_STAT_HEIGHT]

                cx = int(centroids[i][0])
                cy = int(centroids[i][1]) + self.current_roi_y  # åŠ ä¸Š ROI åç§»

                # å½¢ç‹€é©—è­‰
                if not self._validate_shape(w, h, area):
                    filter_stats['shape_filtered'] += 1
                    continue

                filter_stats['passed'] += 1
                detected_objects.append({
                    'x': x,
                    'y': y,
                    'w': w,
                    'h': h,
                    'cx': cx,
                    'cy': cy,
                    'area': area
                })

            # ğŸ” è¼¸å‡ºéæ¿¾çµ±è¨ˆ
            if self.total_processed_frames % 500 == 0:
                logger.info(f"ğŸ“Š [ç‰©ä»¶éæ¿¾] å¹€{self.total_processed_frames}: "
                          f"ç¸½çµ„ä»¶={filter_stats['total']}, "
                          f"é¢ç©éæ¿¾={filter_stats['area_filtered']}, "
                          f"å½¢ç‹€éæ¿¾={filter_stats['shape_filtered']}, "
                          f"âœ…é€šé={filter_stats['passed']}")

            return detected_objects

        except Exception as e:
            logger.error(f"æª¢æ¸¬ç‰©ä»¶éŒ¯èª¤: {str(e)}")
            return []

    def _validate_shape(self, width: int, height: int, area: float) -> bool:
        """é©—è­‰å½¢ç‹€åƒæ•¸"""
        if width <= 0 or height <= 0:
            return False

        # é•·å¯¬æ¯”
        aspect_ratio = width / height if height > width else height / width
        if aspect_ratio < self.min_aspect_ratio or aspect_ratio > self.max_aspect_ratio:
            return False

        # å¡«å……åº¦
        extent = area / (width * height)
        if extent < self.min_extent:
            return False

        return True

    def _draw_detection_results(self, frame: np.ndarray, objects: List[Dict]) -> np.ndarray:
        """ç¹ªè£½æª¢æ¸¬çµæœ"""
        try:
            # ç¹ªè£½ ROI å€åŸŸ
            if self.roi_enabled:
                cv2.rectangle(frame,
                            (0, self.current_roi_y),
                            (self.frame_width, self.current_roi_y + self.current_roi_height),
                            (255, 255, 0), 2)

            # ç¹ªè£½æª¢æ¸¬åˆ°çš„ç‰©ä»¶
            for obj in objects:
                x, y, w, h = obj['x'], obj['y'], obj['w'], obj['h']
                cx, cy = obj['cx'], obj['cy']
                area = obj['area']

                # ç¹ªè£½é‚Šç•Œæ¡†
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

                # ç¹ªè£½ä¸­å¿ƒé»
                cv2.circle(frame, (cx, cy), 3, (255, 0, 0), -1)

                # æ¨™è¨»é¢ç©
                cv2.putText(frame, f'{int(area)}',
                          (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
            info_text = f'Objects: {len(objects)} | Counted: {self.crossing_counter}'
            cv2.putText(frame, info_text,
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

            return frame

        except Exception as e:
            logger.error(f"ç¹ªè£½æª¢æ¸¬çµæœéŒ¯èª¤: {str(e)}")
            return frame

    def enable(self):
        """å•Ÿç”¨æª¢æ¸¬"""
        self.enabled = True
        self._reset_background_subtractor()
        logger.info("æª¢æ¸¬å·²å•Ÿç”¨")

    def disable(self):
        """ç¦ç”¨æª¢æ¸¬"""
        self.enabled = False
        logger.info("æª¢æ¸¬å·²ç¦ç”¨")

    def reset(self):
        """é‡ç½®æª¢æ¸¬ç‹€æ…‹"""
        self.crossing_counter = 0
        self.object_tracks.clear()
        self.lost_tracks.clear()
        self.counted_objects_history.clear()
        self.spatial_grid.clear()
        self.current_frame_count = 0
        self.total_processed_frames = 0
        self._reset_background_subtractor()
        logger.info("æª¢æ¸¬ç‹€æ…‹å·²é‡ç½®")

    def get_count(self) -> int:
        """ç²å–è¨ˆæ•¸"""
        return self.crossing_counter

    def set_parameters(self, **kwargs):
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
                logger.info(f"åƒæ•¸æ›´æ–°: {key} = {value}")

        # å¦‚æœæ›´æ–°äº†èƒŒæ™¯åƒæ•¸ï¼Œé‡ç½®èƒŒæ™¯æ¸›é™¤å™¨
        bg_params = ['bg_history', 'bg_var_threshold', 'detect_shadows', 'bg_learning_rate']
        if any(key in kwargs for key in bg_params):
            self._reset_background_subtractor()

    def set_roi_enabled(self, enabled: bool):
        """è¨­ç½® ROI å•Ÿç”¨ç‹€æ…‹"""
        self.roi_enabled = enabled
        logger.info(f"ROI æª¢æ¸¬: {'å•Ÿç”¨' if enabled else 'ç¦ç”¨'}")

    def set_ultra_high_speed_mode(self, enabled: bool, target_fps: int = 280):
        """è¨­ç½®è¶…é«˜é€Ÿæ¨¡å¼"""
        self.ultra_high_speed_mode = enabled
        self.target_fps = target_fps
        self._reset_background_subtractor()
        logger.info(f"è¶…é«˜é€Ÿæ¨¡å¼: {'å•Ÿç”¨' if enabled else 'ç¦ç”¨'} (ç›®æ¨™ {target_fps} fps)")

    def _update_object_tracking(self, current_objects: List[Tuple]):
        """æ”¹é€²çš„ç‰©ä»¶è¿½è¹¤å’Œç©¿è¶Šè¨ˆæ•¸é‚è¼¯"""
        try:
            self.current_frame_count += 1

            # ROIå€åŸŸé‚Šç•Œ
            roi_top = self.current_roi_y
            roi_bottom = self.current_roi_y + self.roi_height
            roi_center = self.current_roi_y + self.roi_height // 2

            # ğŸ”§ æ”¹é€²çš„è¿½è¹¤åŒ¹é…é‚è¼¯ï¼šå¯¦ç¾ä¸€å°ä¸€åŒ¹é…ï¼Œé¿å…å¤šç‰©ä»¶æ²–çª
            new_tracks = {}
            used_track_ids = set()  # è¨˜éŒ„å·²ç¶“åŒ¹é…çš„è¿½è¹¤ID

            # ğŸ¯ æ¸…ç†ç©ºé–“ç¶²æ ¼ä¸¦é‡å»º (æ¯å¹€é‡æ–°è¨ˆç®—ç¶²æ ¼ä½”ç”¨)
            self.spatial_grid.clear()

            # ğŸš« ç§»é™¤è™›æ“¬ç‰©ä»¶ç”Ÿæˆé‚è¼¯ - åªä½¿ç”¨çœŸå¯¦æª¢æ¸¬ç‰©ä»¶
            all_objects = current_objects

            # ğŸ¯ ç¬¬ä¸€éšæ®µï¼šç‚ºæ¯å€‹æª¢æ¸¬ç‰©ä»¶æ‰¾åˆ°æœ€ä½³åŒ¹é…
            object_track_matches = []  # [(object_index, track_id, distance, is_virtual), ...]

            for obj_idx, obj in enumerate(all_objects):
                x, y, w, h, centroid, area, radius = obj
                cx, cy = centroid

                best_match_id = None
                best_match_distance = float('inf')

                # èˆ‡ç¾æœ‰è¿½è¹¤é€²è¡ŒåŒ¹é… (æ‰¾æœ€ä½³åŒ¹é…)
                for track_id, track in self.object_tracks.items():
                    if track_id in used_track_ids:  # è·³éå·²ç¶“è¢«åŒ¹é…çš„è¿½è¹¤
                        continue

                    # è¨ˆç®—è·é›¢
                    distance = np.sqrt((cx - track['x'])**2 + (cy - track['y'])**2)

                    # ğŸ”§ ç²¾å¯†å¾®èª¿: å¢å¼·åŒ¹é…ç©©å®šæ€§ï¼Œä½¿ç”¨æ›´å¯¬é¬†çš„å®¹å·®
                    tolerance_x = self.crossing_tolerance_x
                    tolerance_y = self.crossing_tolerance_y

                    # ğŸ¯ åŠ å…¥è·é›¢ç©©å®šæ€§åŠ æ¬Š: è¿‘è·é›¢åŒ¹é…å„ªå…ˆæ¬Šæ›´é«˜
                    distance_weight = 1.0 + (distance / 100.0)  # è·é›¢è¶Šè¿‘å„ªå…ˆæ¬Šè¶Šé«˜

                    # æª¢æŸ¥æ˜¯å¦åœ¨å®¹å·®ç¯„åœå…§
                    if (abs(cx - track['x']) < tolerance_x and
                        abs(cy - track['y']) < tolerance_y and
                        distance / distance_weight < best_match_distance):

                        best_match_distance = distance / distance_weight  # ä½¿ç”¨åŠ æ¬Šå¾Œçš„è·é›¢
                        best_match_id = track_id

                # è¨˜éŒ„åŒ¹é…çµæœ
                if best_match_id is not None:
                    object_track_matches.append((obj_idx, best_match_id, best_match_distance))

            # ğŸ¯ ç¬¬äºŒéšæ®µï¼šæŒ‰è·é›¢æ’åºï¼Œç¢ºä¿æœ€ä½³åŒ¹é…å„ªå…ˆ
            object_track_matches.sort(key=lambda x: x[2])  # æŒ‰è·é›¢æ’åº

            # ğŸ¯ ç¬¬ä¸‰éšæ®µï¼šåŸ·è¡Œä¸€å°ä¸€åŒ¹é…ï¼ˆå«ç¶²æ ¼é©—è­‰ï¼‰
            # grid_conflicted_objects = set()  # ğŸ”§ è¨˜éŒ„å› ç¶²æ ¼è¡çªè¢«è·³éçš„ç‰©ä»¶

            for match_data in object_track_matches:
                obj_idx, track_id, distance = match_data

                if track_id not in used_track_ids:
                    # åŸ·è¡ŒåŒ¹é…
                    obj = all_objects[obj_idx]
                    x, y, w, h, centroid, area, radius = obj
                    cx, cy = centroid

                    # ğŸ¯ ç¶²æ ¼é©—è­‰ï¼šæª¢æŸ¥ç©ºé–“è¡çª
                    grid_pos = self._get_grid_position(cx, cy)
                    grid_conflict = grid_pos in self.spatial_grid

                    if not grid_conflict or not self.position_based_tracking:
                        # ç„¡ç¶²æ ¼è¡çªæˆ–æœªå•Ÿç”¨ä½ç½®è¿½è¹¤ï¼ŒåŸ·è¡ŒåŒ¹é…
                        old_track = self.object_tracks[track_id]
                        new_tracks[track_id] = {
                            'x': cx,
                            'y': cy,
                            'first_frame': old_track.get('first_frame', self.current_frame_count),
                            'last_frame': self.current_frame_count,
                            'positions': old_track.get('positions', []) + [(cx, cy)],
                            'counted': old_track.get('counted', False),
                            'in_roi_frames': old_track.get('in_roi_frames', 0) + 1,
                            'max_y': max(old_track.get('max_y', cy), cy),
                            'min_y': min(old_track.get('min_y', cy), cy),
                            'grid_position': grid_pos,  # è¨˜éŒ„ç¶²æ ¼ä½ç½®
                        }
                        used_track_ids.add(track_id)

                        # ä½”ç”¨ç¶²æ ¼
                        if self.position_based_tracking:
                            self.spatial_grid[grid_pos] = track_id

                        logger.debug(f"ğŸ”— ç‰©ä»¶{obj_idx}åŒ¹é…åˆ°è¿½è¹¤{track_id}, è·é›¢={distance:.1f}px, ç¶²æ ¼={grid_pos}")
                    else:
                        # æœ‰ç¶²æ ¼è¡çªï¼Œè¨˜éŒ„ä¸¦è·³éï¼Œé˜²æ­¢é‡è¤‡å‰µå»º
                        conflicted_track = self.spatial_grid[grid_pos]
                        # grid_conflicted_objects.add(obj_idx)  # ğŸ”§ è¨˜éŒ„è¡çªç‰©ä»¶
                        logger.warning(f"âš ï¸ ç¶²æ ¼è¡çª: ç‰©ä»¶{obj_idx}èˆ‡è¿½è¹¤{conflicted_track}åœ¨ç¶²æ ¼{grid_pos}è¡çªï¼Œè·³éåŒ¹é…")

            # ğŸ¯ ç¬¬å››éšæ®µï¼šç‚ºæœªåŒ¹é…çš„ç‰©ä»¶ï¼ˆåŒ…æ‹¬è™›æ“¬ç‰©ä»¶ï¼‰å‰µå»ºæ–°è¿½è¹¤æˆ–å˜—è©¦æ¢å¾©
            matched_objects = {match[0] for match in object_track_matches if match[1] in used_track_ids}

            for obj_idx, obj in enumerate(all_objects):
                if obj_idx not in matched_objects:
                    x, y, w, h, centroid, area, radius = obj
                    cx, cy = centroid

                    # ğŸ”„ è¿½è¹¤æ¢å¾©æ©Ÿåˆ¶ï¼šå˜—è©¦å¾lost_tracksä¸­æ¢å¾©åŒ¹é…çš„è¿½è¹¤
                    recovered_track_id = None
                    best_recovery_distance = float('inf')
                    best_recovery_track_id = None

                    # éæ­·å¤±å»çš„è¿½è¹¤å°‹æ‰¾å¯èƒ½çš„æ¢å¾©åŒ¹é…
                    for lost_track_id, lost_track in self.lost_tracks.items():
                        # è¨ˆç®—ç©ºé–“è·é›¢
                        spatial_distance = np.sqrt((cx - lost_track['x'])**2 + (cy - lost_track['y'])**2)
                        # è¨ˆç®—æ™‚é–“é–“éš”
                        temporal_distance = self.current_frame_count - lost_track['last_frame']

                        # ğŸ”§ ç²¾å¯†å¾®èª¿æ¢å¾©æ¢ä»¶ï¼šé©åº¦æ“´å¤§æ¢å¾©ç¯„åœä»¥æ¸›å°‘IDè®Šæ›´
                        recovery_tolerance_x = self.crossing_tolerance_x * 1.4  # 35*1.4=49px
                        recovery_tolerance_y = self.crossing_tolerance_y * 1.3  # 50*1.3=65px

                        if (abs(cx - lost_track['x']) < recovery_tolerance_x and
                            abs(cy - lost_track['y']) < recovery_tolerance_y and
                            temporal_distance <= self.temporal_tolerance and
                            spatial_distance < best_recovery_distance):

                            best_recovery_distance = spatial_distance
                            best_recovery_track_id = lost_track_id

                    # å¦‚æœæ‰¾åˆ°åˆé©çš„æ¢å¾©åŒ¹é…
                    if best_recovery_track_id is not None:
                        recovered_track_id = best_recovery_track_id
                        recovered_track = self.lost_tracks[recovered_track_id]

                        # ğŸ¯ æª¢æŸ¥æ¢å¾©ä½ç½®çš„ç¶²æ ¼è¡çª
                        recovery_grid_pos = self._get_grid_position(cx, cy)
                        if recovery_grid_pos not in self.spatial_grid or not self.position_based_tracking:
                            # ğŸ¯ é—œéµä¿®æ­£ï¼šæ¢å¾©è¿½è¹¤æ™‚ä¿æŒå®Œæ•´ç‹€æ…‹ï¼Œç‰¹åˆ¥æ˜¯è¨ˆæ•¸ç‹€æ…‹
                            was_counted = recovered_track.get('counted', False)
                            new_tracks[recovered_track_id] = {
                                'x': cx,
                                'y': cy,
                                'first_frame': recovered_track.get('first_frame', self.current_frame_count),
                                'last_frame': self.current_frame_count,
                                'positions': recovered_track.get('positions', []) + [(cx, cy)],
                                'counted': was_counted,  # ğŸ›¡ï¸ åš´æ ¼ä¿æŒåŸå§‹è¨ˆæ•¸ç‹€æ…‹
                                'in_roi_frames': recovered_track.get('in_roi_frames', 0) + 1,
                                'max_y': max(recovered_track.get('max_y', cy), cy),
                                'min_y': min(recovered_track.get('min_y', cy), cy),
                                'grid_position': recovery_grid_pos,
                                'recovered': True,  # ğŸ†• æ¨™è¨˜ç‚ºæ¢å¾©çš„è¿½è¹¤
                                'recovery_frame': self.current_frame_count
                            }

                            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„æ¢å¾©ç‹€æ…‹
                            if was_counted:
                                logger.debug(f"ğŸ”„ æ¢å¾©å·²è¨ˆæ•¸è¿½è¹¤{recovered_track_id}ï¼Œè·³éé‡è¤‡è¨ˆæ•¸")

                            # ä½”ç”¨ç¶²æ ¼
                            if self.position_based_tracking:
                                self.spatial_grid[recovery_grid_pos] = recovered_track_id
                        else:
                            # æ¢å¾©ä½ç½®æœ‰ç¶²æ ¼è¡çªï¼Œæ”¾æ£„æ¢å¾©
                            recovered_track_id = None
                            logger.warning(f"âš ï¸ è¿½è¹¤æ¢å¾©å¤±æ•—: ç¶²æ ¼{recovery_grid_pos}å·²è¢«ä½”ç”¨")

                        # å¾lost_tracksä¸­ç§»é™¤å·²æ¢å¾©çš„è¿½è¹¤
                        del self.lost_tracks[recovered_track_id]

                        logger.info(f"ğŸ”„ æˆåŠŸæ¢å¾©è¿½è¹¤{recovered_track_id}(counted={recovered_track.get('counted', False)}): è·é›¢={best_recovery_distance:.1f}px, æ™‚é–“é–“éš”={self.current_frame_count - recovered_track['last_frame']}å¹€")

                    if not recovered_track_id:

                        # ğŸ¯ æª¢æŸ¥æ–°è¿½è¹¤ä½ç½®çš„ç¶²æ ¼è¡çªï¼ˆåƒ…å°çœŸå¯¦ç‰©ä»¶ï¼‰
                        new_grid_pos = self._get_grid_position(cx, cy)
                        if new_grid_pos not in self.spatial_grid or not self.position_based_tracking:
                            # å‰µå»ºæ–°çš„è¿½è¹¤
                            new_track_id = max(list(self.object_tracks.keys()) + list(new_tracks.keys()) + [0]) + 1
                            new_tracks[new_track_id] = {
                                'x': cx,
                                'y': cy,
                                'first_frame': self.current_frame_count,
                                'last_frame': self.current_frame_count,
                                'positions': [(cx, cy)],
                                'counted': False,
                                'in_roi_frames': 1,
                                'max_y': cy,
                                'min_y': cy,
                                'grid_position': new_grid_pos
                            }

                            # ä½”ç”¨ç¶²æ ¼
                            if self.position_based_tracking:
                                self.spatial_grid[new_grid_pos] = new_track_id

                            logger.debug(f"ğŸ†• ç‰©ä»¶{obj_idx}å‰µå»ºæ–°è¿½è¹¤{new_track_id}, ç¶²æ ¼={new_grid_pos}")
                        else:
                            # æ–°ä½ç½®æœ‰ç¶²æ ¼è¡çªï¼Œè·³éå‰µå»º
                            conflicted_track = self.spatial_grid[new_grid_pos]
                            logger.warning(f"âš ï¸ æ–°è¿½è¹¤å‰µå»ºå¤±æ•—: ç‰©ä»¶{obj_idx}åœ¨ç¶²æ ¼{new_grid_pos}èˆ‡è¿½è¹¤{conflicted_track}è¡çª")
                    else:
                        logger.debug(f"ğŸ”„ ç‰©ä»¶{obj_idx}æ¢å¾©è¿½è¹¤{recovered_track_id}")

            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„è»Œè·¡ç‹€æ…‹å’Œç¶²æ ¼è¡çªçµ±è¨ˆ (æ¯20å¹€è¨˜éŒ„ä¸€æ¬¡)
            if self.current_frame_count % 20 == 0:
                logger.debug(f"ğŸ¯ è»Œè·¡ç‹€æ…‹: ç¸½è»Œè·¡æ•¸={len(new_tracks)}, ç•¶å‰ç©¿è¶Šè¨ˆæ•¸={self.crossing_counter}")

            # ğŸ¯ å¢å¼·çš„ç©¿è¶Šè¨ˆæ•¸é‚è¼¯ - åŠ å…¥æ¢å¾©è¿½è¹¤å®‰å…¨æª¢æŸ¥
            for track_id, track in new_tracks.items():
                # ğŸ›¡ï¸ å¤šé‡å®‰å…¨æª¢æŸ¥ï¼šé˜²æ­¢æ¢å¾©çš„å·²è¨ˆæ•¸è¿½è¹¤è¢«é‡è¤‡è¨ˆæ•¸
                is_recovered = track.get('recovered', False)
                already_counted = track.get('counted', False)

                if not already_counted and track['in_roi_frames'] >= self.min_track_frames:
                    # ç°¡åŒ–æª¢æŸ¥ï¼šåªè¦ç‰©ä»¶åœ¨ROIä¸­å‡ºç¾å°±è¨ˆæ•¸
                    y_travel = track['max_y'] - track['min_y']

                    # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡è¨ˆæ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    is_duplicate = self._check_duplicate_detection_simple(track)

                    # ğŸ¯ èˆ‡ MVC ä¸€è‡´çš„è¨ˆæ•¸æ¢ä»¶
                    valid_crossing = (
                        y_travel >= 8 and           # ğŸ¯ èˆ‡ MVC ä¸€è‡´ï¼šç¢ºä¿çœŸå¯¦ç©¿è¶Š
                        track['in_roi_frames'] >= self.min_track_frames and  # ç¢ºä¿ç©©å®šæª¢æ¸¬
                        not is_duplicate            # éé‡è¤‡æª¢æ¸¬
                    )

                    # ğŸ” å¢å¼·èª¿è©¦ï¼šè¨˜éŒ„è¨ˆæ•¸é‚è¼¯å’Œæ¢å¾©ç‹€æ…‹ (æ¯10å¹€è¨˜éŒ„ä¸€æ¬¡)
                    if self.current_frame_count % 10 == 0 and track_id in list(new_tracks.keys())[:2]:
                        logger.debug(f"ç‰©ä»¶{track_id}: Yç§»å‹•={y_travel}px, é‡è¤‡={is_duplicate}, åœ¨ROIå¹€æ•¸={track['in_roi_frames']}, æ¢å¾©={is_recovered}, æœ‰æ•ˆç©¿è¶Š={valid_crossing}")

                    if valid_crossing:
                        # ğŸ›¡ï¸ æœ€çµ‚å®‰å…¨æª¢æŸ¥ï¼šå†æ¬¡ç¢ºèªæœªè¨ˆæ•¸
                        if not track.get('counted', False):
                            # è¨˜éŒ„åˆ°æ­·å²ä¸­é˜²æ­¢é‡è¤‡
                            self._add_to_history(track)

                            self.crossing_counter += 1
                            track['counted'] = True

                            # ğŸ” é‡è¦ï¼šè¨˜éŒ„æ¯æ¬¡æˆåŠŸè¨ˆæ•¸ (æ€§èƒ½å½±éŸ¿å°ä½†å¾ˆé‡è¦)
                            recovery_status = "æ¢å¾©" if is_recovered else "æ–°å»º"
                            logger.info(f"âœ… æˆåŠŸè¨ˆæ•¸ #{self.crossing_counter} - ç‰©ä»¶{track_id}({recovery_status}) (Yç§»å‹•: {y_travel}px)")
                        else:
                            logger.warning(f"âš ï¸ é˜»æ­¢é‡è¤‡è¨ˆæ•¸: ç‰©ä»¶{track_id}å·²è¢«è¨ˆæ•¸")

            # ğŸ”§ æ”¹é€²çš„è¿½è¹¤ç”Ÿå‘½é€±æœŸç®¡ç†ï¼šç§»å‹•å¤±å»çš„è¿½è¹¤åˆ°lost_tracks
            current_time = self.current_frame_count

            # ğŸ”§ æ”¹é€²çš„è¿½è¹¤ç”Ÿå‘½é€±æœŸç®¡ç†ï¼šç¢ºä¿å®Œæ•´ç‹€æ…‹ä¿å­˜
            for track_id, track in self.object_tracks.items():
                if track_id not in new_tracks:
                    # ğŸ›¡ï¸ ç¢ºä¿å®Œæ•´ç‹€æ…‹ä¿å­˜ï¼Œç‰¹åˆ¥æ˜¯è¨ˆæ•¸ç‹€æ…‹
                    self.lost_tracks[track_id] = {
                        **track,  # ä¿ç•™æ‰€æœ‰åŸå§‹ç‹€æ…‹
                        'lost_frame': current_time,  # è¨˜éŒ„å¤±å»çš„æ™‚é–“
                        'lost_reason': 'no_detection'  # è¨˜éŒ„å¤±å»åŸå› 
                    }
                    logger.debug(f"ğŸ”„ è¿½è¹¤{track_id}å¤±å»åŒ¹é…(counted={track.get('counted', False)})ï¼Œç§»å‹•åˆ°lost_tracks")

            # æ¸…ç†éæœŸçš„lost_tracks
            for track_id in list(self.lost_tracks.keys()):
                track = self.lost_tracks[track_id]
                if current_time - track['last_frame'] > self.temporal_tolerance:
                    del self.lost_tracks[track_id]
                    logger.debug(f"ğŸ—‘ï¸ æ¸…ç†éæœŸlost_track {track_id}")

            # æ›´æ–°è¿½è¹¤ç‹€æ…‹
            self.object_tracks = new_tracks

        except Exception as e:
            logger.error(f"ç‰©ä»¶è¿½è¹¤æ›´æ–°éŒ¯èª¤: {str(e)}")

    def _check_duplicate_detection_simple(self, track: Dict) -> bool:
        """ğŸ”§ å¢å¼·ç‰ˆé‡è¤‡æª¢æ¸¬ - åŠ å…¥æ™‚é–“èˆ‡ç©ºé–“é›™é‡è€ƒé‡ ğŸ” ç‰¹åˆ¥é‡å°IDè®Šæ›´çš„é‡è¤‡è¨ˆæ•¸å•é¡Œ"""
        try:
            current_pos = (track['x'], track['y'])
            current_frame = self.current_frame_count

            # ğŸ›¡ï¸ ç‰¹åˆ¥æª¢æŸ¥: å¦‚æœæ˜¯æ¢å¾©çš„è¿½è¹¤ï¼Œé©åº¦æ”¾å¯¬æª¢æŸ¥ç¯„åœ
            is_recovered = track.get('recovered', False)
            detection_threshold = self.duplicate_distance_threshold * (1.2 if is_recovered else 1.0)

            # ğŸ†• æª¢æŸ¥æ­·å²è¨˜éŒ„ä¸­çš„æ™‚ç©ºé‡è¤‡
            for hist_entry in self.counted_objects_history:
                if isinstance(hist_entry, tuple) and len(hist_entry) == 2:
                    # æ–°æ ¼å¼ï¼š(position, frame_number)
                    hist_pos, hist_frame = hist_entry

                    # ğŸ¯ æ™‚ç©ºè·é›¢æª¢æ¸¬ï¼šåŒæ™‚è€ƒæ…®ç©ºé–“è·é›¢å’Œæ™‚é–“é–“éš”
                    spatial_distance = abs(current_pos[0] - hist_pos[0]) + abs(current_pos[1] - hist_pos[1])
                    temporal_distance = current_frame - hist_frame

                    # ğŸ›¡ï¸ ç²¾å¯†å¾®èª¿çš„é‡è¤‡æª¢æ¸¬ï¼šä½¿ç”¨å‹•æ…‹é—¾å€¼
                    if (spatial_distance < detection_threshold and
                        temporal_distance <= self.temporal_tolerance):
                        status = "æ¢å¾©" if is_recovered else "æ–°å»º"
                        logger.debug(f"ğŸš« æª¢æ¸¬åˆ°é‡è¤‡({status}): ç©ºé–“è·é›¢={spatial_distance:.1f}<{detection_threshold:.1f}, æ™‚é–“é–“éš”={temporal_distance}å¹€")
                        return True

                elif isinstance(hist_entry, tuple) and len(hist_entry) == 2 and isinstance(hist_entry[0], (int, float)):
                    # èˆŠæ ¼å¼ï¼š(x, y) - å‘å¾Œç›¸å®¹
                    hist_pos = hist_entry
                    spatial_distance = abs(current_pos[0] - hist_pos[0]) + abs(current_pos[1] - hist_pos[1])

                    # ğŸ”§ ä½¿ç”¨å‹•æ…‹é—¾å€¼è™•ç†èˆŠæ ¼å¼è¨˜éŒ„
                    if spatial_distance < detection_threshold:
                        status = "æ¢å¾©" if is_recovered else "æ–°å»º"
                        logger.debug(f"ğŸš« æª¢æ¸¬åˆ°èˆŠæ ¼å¼é‡è¤‡({status}): ç©ºé–“è·é›¢={spatial_distance:.1f}<{detection_threshold:.1f}")
                        return True

            return False

        except Exception as e:
            logger.debug(f"é‡è¤‡æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return False

    def _add_to_history(self, track: Dict):
        """ğŸ”§ æ·»åŠ å·²è¨ˆæ•¸ç‰©ä»¶åˆ°æ­·å²è¨˜éŒ„ - åŒ…å«æ™‚é–“ä¿¡æ¯"""
        try:
            position = (track['x'], track['y'])
            frame_number = self.current_frame_count

            # ğŸ†• æ–°æ ¼å¼ï¼šåŒæ™‚è¨˜éŒ„ä½ç½®å’Œæ™‚é–“
            history_entry = (position, frame_number)
            self.counted_objects_history.append(history_entry)

            # ä¿æŒæ­·å²è¨˜éŒ„åœ¨é™åˆ¶ç¯„åœå…§
            if len(self.counted_objects_history) > self.history_length:
                self.counted_objects_history.pop(0)

            logger.debug(f"ğŸ“ æ·»åŠ åˆ°æ­·å²: ä½ç½®={position}, å¹€è™Ÿ={frame_number}")

        except Exception as e:
            logger.error(f"æ·»åŠ æ­·å²è¨˜éŒ„éŒ¯èª¤: {str(e)}")

    def _get_grid_position(self, x: int, y: int) -> Tuple[int, int]:
        """å°‡åƒç´ åº§æ¨™è½‰æ›ç‚ºç¶²æ ¼åº§æ¨™"""
        grid_x = x // self.grid_cell_size
        grid_y = y // self.grid_cell_size
        return (grid_x, grid_y)

    def _update_object_tracking_sort(self, detected_objects: List[Dict]):
        """
        ä½¿ç”¨ SORT ç®—æ³•æ›´æ–°ç‰©ä»¶è¿½è¹¤ï¼ˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨ + åŒˆç‰™åˆ©ç®—æ³•ï¼‰

        Args:
            detected_objects: æª¢æ¸¬åˆ°çš„ç‰©ä»¶åˆ—è¡¨ [{'x': cx, 'y': cy, 'w': w, 'h': h, ...}, ...]
        """
        if not self.use_sort:
            logger.warning("SORT è¿½è¹¤æœªå•Ÿç”¨")
            return

        try:
            self.current_frame_count += 1

            # ğŸ› èª¿è©¦ï¼šæ¯ 50 å¹€è¼¸å‡ºä¸€æ¬¡ SORT ç‹€æ…‹
            if self.current_frame_count % 50 == 0:
                logger.info(f"ğŸ¯ SORT è¿½è¹¤ (ç¬¬ {self.current_frame_count} å¹€): "
                          f"æª¢æ¸¬={len(detected_objects)}, "
                          f"è¿½è¹¤å™¨={len(self.kalman_trackers)}, "
                          f"è¨ˆæ•¸={self.crossing_counter}")

            # 1. æº–å‚™æª¢æ¸¬çµæœï¼šè½‰æ›ç‚º numpy é™£åˆ— [x, y, w, h]
            detections = np.array([[obj['x'], obj['y'], obj['w'], obj['h']]
                                   for obj in detected_objects])

            # 2. å°æ‰€æœ‰è¿½è¹¤å™¨é€²è¡Œé æ¸¬
            trackers_pred = np.zeros((len(self.kalman_trackers), 4))
            to_del = []

            for t, trk in enumerate(self.kalman_trackers):
                pred = trk.predict()
                trackers_pred[t] = pred

                # æ¨™è¨˜ç„¡æ•ˆçš„è¿½è¹¤å™¨
                if np.any(np.isnan(pred)):
                    to_del.append(t)

            # ç§»é™¤ç„¡æ•ˆè¿½è¹¤å™¨
            for t in reversed(to_del):
                self.kalman_trackers.pop(t)
            trackers_pred = np.delete(trackers_pred, to_del, axis=0)

            # 3. ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•é€²è¡Œæœ€å„ªåŒ¹é…
            if len(trackers_pred) > 0:
                matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(
                    detections, trackers_pred, self.iou_threshold
                )
            else:
                matched = np.empty((0, 2), dtype=int)
                unmatched_dets = np.arange(len(detections))
                unmatched_trks = np.empty((0,), dtype=int)

            # 4. æ›´æ–°å·²åŒ¹é…çš„è¿½è¹¤å™¨
            for m in matched:
                det_idx, trk_idx = m[0], m[1]
                self.kalman_trackers[trk_idx].update(detections[det_idx])

            # 5. ç‚ºæœªåŒ¹é…çš„æª¢æ¸¬å‰µå»ºæ–°è¿½è¹¤å™¨
            for i in unmatched_dets:
                trk = KalmanBoxTracker(detections[i])
                self.kalman_trackers.append(trk)

            # 6. æ›´æ–°è¿½è¹¤å™¨åˆ—è¡¨ä¸¦åŸ·è¡Œè¨ˆæ•¸é‚è¼¯
            i = len(self.kalman_trackers)
            for trk in reversed(self.kalman_trackers):
                i -= 1

                # ç§»é™¤é•·æ™‚é–“æœªæ›´æ–°çš„è¿½è¹¤å™¨
                if trk.time_since_update > self.max_age:
                    self.kalman_trackers.pop(i)
                    continue

                # è¨ˆæ•¸é‚è¼¯ï¼šåªå°ç©©å®šè¿½è¹¤ä¸”æœªè¨ˆæ•¸çš„ç‰©ä»¶è¨ˆæ•¸
                if (trk.time_since_update == 0 and
                    trk.hit_streak >= self.min_hits and
                    not trk.counted):

                    # æª¢æŸ¥ç©¿è¶Šæ¢ä»¶
                    y_travel = trk.get_y_travel()

                    # æª¢æŸ¥é‡è¤‡ï¼ˆåŸºæ–¼ä½ç½®ï¼‰
                    current_pos = trk.get_position()
                    is_duplicate = self._check_duplicate_simple(current_pos)

                    # é©—è­‰ç©¿è¶Š
                    valid_crossing = (
                        y_travel >= 8 and  # Yè»¸ç§»å‹•è·é›¢
                        trk.hit_streak >= self.min_hits and  # ç©©å®šè¿½è¹¤
                        not is_duplicate  # éé‡è¤‡
                    )

                    if valid_crossing:
                        self.crossing_counter += 1
                        trk.counted = True

                        # è¨˜éŒ„åˆ°æ­·å²
                        self._add_to_history_simple(current_pos)

                        logger.info(f"âœ… SORTè¨ˆæ•¸ #{self.crossing_counter} - è¿½è¹¤å™¨{trk.id} "
                                   f"(å‘½ä¸­:{trk.hit_streak}, Yç§»å‹•:{y_travel:.1f}px)")
                    else:
                        # ğŸ› èª¿è©¦ï¼šè¨˜éŒ„æœªè¨ˆæ•¸çš„åŸå› ï¼ˆæ¯ 100 æ¬¡æª¢æŸ¥è¼¸å‡ºä¸€æ¬¡ï¼‰
                        if self.current_frame_count % 100 == 0:
                            logger.debug(f"â­ï¸ è¿½è¹¤å™¨{trk.id}æœªè¨ˆæ•¸: "
                                       f"Yç§»å‹•={y_travel:.1f}px (éœ€è¦>=8), "
                                       f"å‘½ä¸­={trk.hit_streak} (éœ€è¦>={self.min_hits}), "
                                       f"é‡è¤‡={is_duplicate}")

            # 7. èª¿è©¦ï¼šè¨˜éŒ„è¿½è¹¤ç‹€æ…‹ (æ¯20å¹€)
            if self.current_frame_count % 20 == 0:
                active_trackers = len(self.kalman_trackers)
                counted_trackers = sum(1 for trk in self.kalman_trackers if trk.counted)
                logger.debug(f"ğŸ¯ SORTç‹€æ…‹: è¿½è¹¤å™¨={active_trackers}, "
                           f"å·²è¨ˆæ•¸={counted_trackers}, ç¸½è¨ˆæ•¸={self.crossing_counter}")

        except Exception as e:
            logger.error(f"SORT è¿½è¹¤æ›´æ–°éŒ¯èª¤: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

    def _check_duplicate_simple(self, position: Tuple[float, float]) -> bool:
        """ç°¡åŒ–çš„é‡è¤‡æª¢æ¸¬ï¼ˆç”¨æ–¼ SORTï¼‰"""
        try:
            current_x, current_y = position
            current_frame = self.current_frame_count

            for hist_entry in self.counted_objects_history:
                if isinstance(hist_entry, tuple) and len(hist_entry) == 2:
                    hist_pos, hist_frame = hist_entry
                    spatial_dist = abs(current_x - hist_pos[0]) + abs(current_y - hist_pos[1])
                    temporal_dist = current_frame - hist_frame

                    if (spatial_dist < self.duplicate_distance_threshold and
                        temporal_dist <= self.temporal_tolerance):
                        return True

            return False
        except Exception as e:
            logger.debug(f"é‡è¤‡æª¢æ¸¬éŒ¯èª¤: {str(e)}")
            return False

    def _add_to_history_simple(self, position: Tuple[float, float]):
        """ç°¡åŒ–çš„æ­·å²è¨˜éŒ„ï¼ˆç”¨æ–¼ SORTï¼‰"""
        try:
            frame_number = self.current_frame_count
            history_entry = (position, frame_number)
            self.counted_objects_history.append(history_entry)

            if len(self.counted_objects_history) > self.history_length:
                self.counted_objects_history.pop(0)

            logger.debug(f"ğŸ“ æ·»åŠ åˆ°æ­·å²: ä½ç½®={position}, å¹€è™Ÿ={frame_number}")
        except Exception as e:
            logger.error(f"æ·»åŠ æ­·å²è¨˜éŒ„éŒ¯èª¤: {str(e)}")
