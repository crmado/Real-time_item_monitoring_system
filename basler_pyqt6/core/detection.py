"""
å°é›¶ä»¶æª¢æ¸¬æ§åˆ¶å™¨ - åŸºæ–¼ basler_mvc çš„èƒŒæ™¯æ¸›é™¤ç®—æ³•
æ•´åˆ SORT è¿½è¹¤ç®—æ³•ï¼ˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨ + åŒˆç‰™åˆ©ç®—æ³•ï¼‰
"""

import cv2
import numpy as np
import logging
import os
from typing import List, Dict, Any, Tuple, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

# è™›æ“¬å…‰æŸµè¨ˆæ•¸æ³• - ç„¡éœ€é¡å¤–å°å…¥


class DetectionController:
    """å°é›¶ä»¶æª¢æ¸¬æ§åˆ¶å™¨ - èƒŒæ™¯æ¸›é™¤ + è™›æ“¬å…‰æŸµè¨ˆæ•¸"""

    def __init__(self):
        self.enabled = False
        self.detected_objects: List[Dict] = []

        # ğŸš€ é«˜é€Ÿæª¢æ¸¬æ¨¡å¼æ§åˆ¶
        self.ultra_high_speed_mode = False
        self.target_fps = 280

        # ğŸ¯ æ¥µå°é›¶ä»¶æª¢æ¸¬åƒæ•¸ - åŸºæ–¼ basler_mvc
        self.min_area = 2           # basler_mvc é©—è­‰åƒæ•¸
        self.max_area = 3000        # basler_mvc é©—è­‰åƒæ•¸

        # ç‰©ä»¶å½¢ç‹€éæ¿¾åƒæ•¸ - ç‚ºå°é›¶ä»¶æ”¾å¯¬æ¢ä»¶
        self.min_aspect_ratio = 0.001  # æ¥µåº¦å¯¬é¬†çš„é•·å¯¬æ¯”
        self.max_aspect_ratio = 100.0
        self.min_extent = 0.001        # æ¥µåº¦é™ä½å¡«å……æ¯”ä¾‹è¦æ±‚
        self.max_solidity = 5.0        # æ¥µåº¦æ”¾å¯¬çµå¯¦æ€§é™åˆ¶

        # ğŸ¯ è¶…ç©©å®šèƒŒæ™¯æ¸›é™¤ - å°ˆç‚ºå°é›¶ä»¶é•·æœŸæª¢æ¸¬å„ªåŒ–ï¼ˆbasler_mvc é©—è­‰åƒæ•¸ï¼‰
        self.bg_history = 1000          # basler_mvc é©—è­‰åƒæ•¸ï¼šå¤§å¹…å¢åŠ æ­·å²å¹€æ•¸é¿å…å¿«é€ŸèƒŒæ™¯æ›´æ–°
        self.bg_var_threshold = 3       # basler_mvc é©—è­‰åƒæ•¸ï¼šæ¥µä½é–¾å€¼ç¢ºä¿æœ€é«˜æ•æ„Ÿåº¦
        self.detect_shadows = False
        self.bg_learning_rate = 0.001   # basler_mvc é©—è­‰åƒæ•¸ï¼šæ¥µä½å­¸ç¿’ç‡é¿å…å°é›¶ä»¶è¢«ç´å…¥èƒŒæ™¯

        # ğŸš€ é«˜é€Ÿæ¨¡å¼åƒæ•¸
        self.high_speed_bg_history = 100
        self.high_speed_bg_var_threshold = 8
        self.high_speed_min_area = 1
        self.high_speed_max_area = 2000
        self.high_speed_binary_threshold = 3

        # ğŸ¯ æ¥µé«˜æ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
        self.gaussian_blur_kernel = (1, 1)  # æœ€å°æ¨¡ç³Šä¿ç•™æœ€å¤šç´°ç¯€
        self.canny_low_threshold = 2        # ğŸ”§ é€²ä¸€æ­¥é™ä½é–¾å€¼ (3â†’2)
        self.canny_high_threshold = 8       # ğŸ”§ é€²ä¸€æ­¥é™ä½é–¾å€¼ (10â†’8)
        self.binary_threshold = 1           # æ¥µä½é–¾å€¼æé«˜æ•æ„Ÿåº¦

        # ğŸ” åˆ†é›¢å„ªåŒ–çš„å½¢æ…‹å­¸è™•ç†
        self.dilate_kernel_size = (1, 1)    # æœ€å°æ ¸é¿å…éåº¦è†¨è„¹
        self.dilate_iterations = 0           # ç¦ç”¨è†¨è„¹ä»¥ä¿ç•™å°é›¶ä»¶
        self.close_kernel_size = (1, 1)     # ç¦ç”¨é–‰åˆé¿å…é›¶ä»¶ç²˜é€£
        self.enable_watershed_separation = True  # å•Ÿç”¨åˆ†æ°´å¶ºåˆ†é›¢ç®—æ³•

        # ğŸ¯ æœ€å°åŒ–é›œè¨Šéæ¿¾
        self.opening_kernel_size = (1, 1)   # æœ€å°é–‹é‹ç®—æ ¸
        self.opening_iterations = 0          # ç¦ç”¨é–‹é‹ç®—ä»¥ä¿ç•™å°é›¶ä»¶

        # é€£é€šçµ„ä»¶åƒæ•¸
        self.connectivity = 4  # 4-é€£é€šæˆ–8-é€£é€š

        # ğŸ¯ ROI æª¢æ¸¬å€åŸŸåƒæ•¸
        self.roi_enabled = True
        self.roi_height = 150  # ğŸ”§ æ“´å¤§ ROI å€åŸŸé«˜åº¦ (120â†’150)
        self.roi_position_ratio = 0.10  # ğŸ”§ ç¨å¾®ä¸Šç§» ROI ä½ç½® (0.12â†’0.10)
        self.current_roi_y = 0
        self.current_roi_height = 150

        # ğŸ¯ è™›æ“¬å…‰æŸµè¨ˆæ•¸åƒæ•¸ï¼ˆå·¥æ¥­ç´šæ–¹æ¡ˆï¼‰
        self.enable_gate_counting = True
        self.gate_line_position_ratio = 0.5  # å…‰æŸµç·šåœ¨ ROI ä¸­çš„ä½ç½®ï¼ˆ0.5 = ä¸­å¿ƒç·šï¼‰
        self.gate_trigger_radius = 20  # å»é‡åŠå¾‘ï¼ˆåƒç´ ï¼‰
        self.gate_history_frames = 8  # è§¸ç™¼æ­·å²ä¿æŒå¹€æ•¸ï¼ˆ280fpsä¸‹ç´„28msï¼‰

        # å…‰æŸµè§¸ç™¼ç‹€æ…‹
        self.triggered_positions = {}  # {(x,y): frame_number} è¨˜éŒ„è§¸ç™¼ä½ç½®å’Œå¹€è™Ÿ
        self.crossing_counter = 0
        self.frame_width = 640
        self.frame_height = 480
        self.current_frame_count = 0
        self.total_processed_frames = 0
        self.gate_line_y = 0  # å…‰æŸµç·šçš„å¯¦éš› Y åº§æ¨™

        # èƒŒæ™¯æ¸›é™¤å™¨
        self.bg_subtractor = None
        self._reset_background_subtractor()

        # ğŸ“¸ èª¿è©¦åœ–ç‰‡åŠŸèƒ½
        self.debug_save_enabled = False
        self.debug_save_dir = "basler_pyqt6/recordings/debug"
        self.debug_frame_counter = 0
        self.max_debug_frames = 100

        # è¼¸å‡ºåˆå§‹åŒ–ç‹€æ…‹
        logger.info("âœ… æª¢æ¸¬æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ - è™›æ“¬å…‰æŸµè¨ˆæ•¸æ³• (å·¥æ¥­ç´š)")
        logger.info(f"ğŸ¯ å…‰æŸµåƒæ•¸: ä½ç½®æ¯”ä¾‹={self.gate_line_position_ratio}, å»é‡åŠå¾‘={self.gate_trigger_radius}px, æ­·å²å¹€æ•¸={self.gate_history_frames}")

    def _reset_background_subtractor(self):
        """é‡ç½®èƒŒæ™¯æ¸›é™¤å™¨"""
        if self.ultra_high_speed_mode:
            history = self.high_speed_bg_history
            var_threshold = self.high_speed_bg_var_threshold
        else:
            history = self.bg_history
            var_threshold = self.bg_var_threshold

        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=history,
            varThreshold=var_threshold,
            detectShadows=self.detect_shadows
        )
        self.current_learning_rate = self.bg_learning_rate
        logger.debug(f"èƒŒæ™¯æ¸›é™¤å™¨å·²é‡ç½®: history={history}, var_threshold={var_threshold}")

    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        è™•ç†å¹€ä¸¦åŸ·è¡Œå°é›¶ä»¶æª¢æ¸¬

        Returns:
            (è™•ç†å¾Œçš„åœ–åƒ, æª¢æ¸¬çµæœåˆ—è¡¨)
        """
        if frame is None or not self.enabled:
            return frame, []

        try:
            self.total_processed_frames += 1
            self.frame_height, self.frame_width = frame.shape[:2]

            # ğŸ¯ ROI å€åŸŸæå–
            if self.roi_enabled:
                roi_y = int(self.frame_height * self.roi_position_ratio)
                process_region = frame[roi_y:roi_y + self.roi_height, :]
                self.current_roi_y = roi_y
                self.current_roi_height = self.roi_height
            else:
                process_region = frame
                self.current_roi_y = 0
                self.current_roi_height = self.frame_height

            # åŸ·è¡Œæª¢æ¸¬è™•ç†
            if self.ultra_high_speed_mode:
                processed = self._ultra_high_speed_processing(process_region)
            else:
                processed = self._standard_processing(process_region)

            # æª¢æ¸¬ç‰©ä»¶
            detected_objects = self._detect_objects(processed)

            # ğŸ› èª¿è©¦ï¼šæ¯ 500 å¹€è¼¸å‡ºå®Œæ•´è¨ºæ–·å ±å‘Š
            if self.total_processed_frames % 500 == 0:
                logger.info(f"{'='*60}")
                logger.info(f"ğŸ” è¨ºæ–·å ±å‘Š - ç¬¬ {self.total_processed_frames} å¹€")
                logger.info(f"{'='*60}")
                logger.info(f"ğŸ“Š [è™›æ“¬å…‰æŸµ] å¹€{self.total_processed_frames}: "
                          f"æª¢æ¸¬åˆ° {len(detected_objects)} å€‹ç‰©ä»¶, "
                          f"å…‰æŸµç·šY={self.gate_line_y}, "
                          f"ç•¶å‰è¨ˆæ•¸: {self.crossing_counter}")
                logger.info(f"{'='*60}")

            # ğŸ¯ è™›æ“¬å…‰æŸµè¨ˆæ•¸ï¼ˆå·¥æ¥­ç´šæ–¹æ¡ˆï¼‰
            if self.enable_gate_counting and len(detected_objects) > 0:
                self._virtual_gate_counting(detected_objects)

            # ç¹ªè£½çµæœ
            result_frame = self._draw_detection_results(frame.copy(), detected_objects)

            self.detected_objects = detected_objects
            return result_frame, detected_objects

        except Exception as e:
            logger.error(f"âŒ æª¢æ¸¬å¤±æ•—: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return frame, []

    def _standard_processing(self, process_region: np.ndarray) -> np.ndarray:
        """æ¨™æº–æ¨¡å¼è™•ç†æµç¨‹ - å®Œæ•´çš„å¤šé‡æª¢æ¸¬ç­–ç•¥ (åŸºæ–¼ basler_mvc)"""
        # 1. èƒŒæ™¯æ¸›é™¤ç²å¾—å‰æ™¯é®ç½©
        fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)

        # ğŸ› èª¿è©¦ï¼šæª¢æŸ¥å‰æ™¯é®ç½©
        if self.total_processed_frames % 500 == 0:
            fg_pixels = cv2.countNonZero(fg_mask)
            roi_total = process_region.shape[0] * process_region.shape[1]
            fg_ratio = (fg_pixels / roi_total * 100) if roi_total > 0 else 0
            logger.info(f"  âŠ [èƒŒæ™¯æ¸›é™¤] å‰æ™¯åƒç´ ={fg_pixels} ({fg_ratio:.2f}%), å­¸ç¿’ç‡={self.current_learning_rate}")

        # 2. é«˜æ–¯æ¨¡ç³Šæ¸›å°‘å™ªè²
        blurred = cv2.GaussianBlur(process_region, self.gaussian_blur_kernel, 0)

        # 3. Cannyé‚Šç·£æª¢æ¸¬
        edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)

        # 4. å¤šè§’åº¦æª¢æ¸¬ç­–ç•¥ï¼ˆå®Œæ•´ basler_mvc æµç¨‹ï¼‰
        # æ–¹æ³•1: å¢å¼·å‰æ™¯é®ç½©æ¿¾æ³¢ - æ¸›å°‘å™ªé»å¹²æ“¾åŒæ™‚ä¿ç•™å°é›¶ä»¶
        # Step 1: ä¸­å€¼æ¿¾æ³¢å»é™¤æ¤’é¹½å™ªé»
        fg_median = cv2.medianBlur(fg_mask, 5)

        # Step 2: å¢å¼·å½¢æ…‹å­¸é–‹é‹ç®—å»é™¤ç¨ç«‹å™ªé»
        enhanced_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fg_step1 = cv2.morphologyEx(fg_median, cv2.MORPH_OPEN, enhanced_kernel, iterations=1)

        # Step 3: é–‰é‹ç®—å¡«è£œç‰©ä»¶å…§éƒ¨ç©ºæ´
        close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        fg_step2 = cv2.morphologyEx(fg_step1, cv2.MORPH_CLOSE, close_kernel, iterations=1)

        # Step 4: æœ€çµ‚å¾®èª¿é–‹é‹ç®—ï¼Œç§»é™¤å‰©é¤˜å°å™ªé»ä½†ä¿ç•™çœŸå¯¦å°é›¶ä»¶
        final_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        fg_cleaned = cv2.morphologyEx(fg_step2, cv2.MORPH_OPEN, final_kernel, iterations=1)

        # æ–¹æ³•2: å¤šæ•æ„Ÿåº¦é‚Šç·£æª¢æ¸¬
        strong_edges = cv2.Canny(blurred, self.canny_low_threshold, self.canny_high_threshold)
        sensitive_edges = cv2.Canny(blurred, self.canny_low_threshold//2, self.canny_high_threshold//2)

        # æ–¹æ³•3: è‡ªé©æ‡‰é–¾å€¼æª¢æ¸¬
        gray_roi = cv2.cvtColor(process_region, cv2.COLOR_BGR2GRAY) if len(process_region.shape) == 3 else process_region
        adaptive_thresh = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                                cv2.THRESH_BINARY, 11, 2)

        # 5. é‚Šç·£å¢å¼·
        edge_enhanced = cv2.bitwise_and(sensitive_edges, sensitive_edges, mask=fg_cleaned)
        _, edge_thresh = cv2.threshold(edge_enhanced, 1, 255, cv2.THRESH_BINARY)

        adaptive_enhanced = cv2.bitwise_and(adaptive_thresh, adaptive_thresh, mask=fg_cleaned)
        _, adaptive_thresh_clean = cv2.threshold(adaptive_enhanced, 127, 255, cv2.THRESH_BINARY)

        # 6. ä¸‰é‡è¯åˆæª¢æ¸¬
        temp_combined = cv2.bitwise_or(fg_cleaned, edge_thresh)
        combined = cv2.bitwise_or(temp_combined, adaptive_thresh_clean)

        # 7. æ¥µåº¦ç°¡åŒ–å½¢æ…‹å­¸è™•ç† - æœ€å¤§åŒ–ä¿ç•™å°é›¶ä»¶
        if self.opening_kernel_size != (1, 1):
            opening_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.opening_kernel_size)
            opened_stage1 = cv2.morphologyEx(combined, cv2.MORPH_OPEN, opening_kernel, iterations=self.opening_iterations)
        else:
            opened_stage1 = combined.copy()

        # æœ€å°åŒ–è†¨è„¹
        if self.dilate_kernel_size != (1, 1) and self.dilate_iterations > 0:
            dilate_kernel = np.ones(self.dilate_kernel_size, np.uint8)
            dilated = cv2.dilate(opened_stage1, dilate_kernel, iterations=self.dilate_iterations)
        else:
            dilated = opened_stage1.copy()

        # é—œéµï¼šæœ€å°åŒ–é–‰åˆé‹ç®—
        if self.close_kernel_size != (1, 1):
            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.close_kernel_size)
            processed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, close_kernel, iterations=1)
        else:
            processed = dilated.copy()

        # ğŸ› èª¿è©¦ï¼šæª¢æŸ¥æœ€çµ‚è™•ç†çµæœ
        if self.total_processed_frames % 500 == 0:
            # æª¢æŸ¥å„éšæ®µåƒç´ æ•¸
            fg_cleaned_pixels = cv2.countNonZero(fg_cleaned)
            combined_pixels = cv2.countNonZero(combined)
            processed_pixels = cv2.countNonZero(processed)

            logger.info(f"  â‹ [å½¢æ…‹è™•ç†] æ¸…ç†å¾Œ={fg_cleaned_pixels}px, è¯åˆæª¢æ¸¬={combined_pixels}px, æœ€çµ‚={processed_pixels}px")

        return processed

    def _ultra_high_speed_processing(self, process_region: np.ndarray) -> np.ndarray:
        """è¶…é«˜é€Ÿè™•ç†æ¨¡å¼ - ç°¡åŒ–æµç¨‹"""
        fg_mask = self.bg_subtractor.apply(process_region, learningRate=self.current_learning_rate)
        kernel = np.ones((3, 3), np.uint8)
        processed = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        processed = cv2.dilate(processed, kernel, iterations=1)
        return processed

    def _detect_objects(self, processed: np.ndarray) -> List[Dict]:
        """æª¢æ¸¬ç‰©ä»¶ - ä½¿ç”¨é€£é€šçµ„ä»¶åˆ†æ"""
        if processed is None:
            return []

        try:
            # ä½¿ç”¨é€£é€šçµ„ä»¶åˆ†æ
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                processed, connectivity=self.connectivity
            )

            # ğŸ” èª¿è©¦ï¼šè¨˜éŒ„é€£é€šçµ„ä»¶ä¿¡æ¯
            if self.total_processed_frames % 500 == 0:
                min_area = self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area
                max_area = self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area

                # çµ±è¨ˆçµ„ä»¶é¢ç©åˆ†ä½ˆ
                if num_labels > 1:
                    all_areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]
                    areas_in_range = [a for a in all_areas if min_area <= a <= max_area]

                    logger.info(f"ğŸ“Š [é€£é€šçµ„ä»¶] å¹€{self.total_processed_frames}: "
                              f"ç¸½çµ„ä»¶={num_labels-1}, "
                              f"é¢ç©ç¯„åœå…§={len(areas_in_range)}, "
                              f"ç¯„åœ=[{min_area}, {max_area}]")

                    if all_areas:
                        area_stats = {
                            'æœ€å°': min(all_areas),
                            'æœ€å¤§': max(all_areas),
                            'å¹³å‡': int(sum(all_areas) / len(all_areas))
                        }
                        logger.info(f"   é¢ç©çµ±è¨ˆ: {area_stats}")
                        # é¡¯ç¤ºå‰10å€‹çµ„ä»¶çš„é¢ç©
                        sample_areas = sorted(all_areas)[:10]
                        logger.info(f"   å‰10å€‹çµ„ä»¶é¢ç©: {sample_areas}")
                else:
                    logger.warning(f"âš ï¸ [é€£é€šçµ„ä»¶] å¹€{self.total_processed_frames}: æ²’æœ‰æª¢æ¸¬åˆ°ä»»ä½•çµ„ä»¶ï¼")

            detected_objects = []
            min_area = self.high_speed_min_area if self.ultra_high_speed_mode else self.min_area
            max_area = self.high_speed_max_area if self.ultra_high_speed_mode else self.max_area

            # ğŸ” çµ±è¨ˆéæ¿¾ä¿¡æ¯
            filter_stats = {
                'total': num_labels - 1,
                'area_filtered': 0,
                'shape_filtered': 0,
                'passed': 0
            }

            for i in range(1, num_labels):  # è·³éèƒŒæ™¯ (label 0)
                area = stats[i, cv2.CC_STAT_AREA]

                # é¢ç©éæ¿¾
                if area < min_area or area > max_area:
                    filter_stats['area_filtered'] += 1
                    continue

                x = stats[i, cv2.CC_STAT_LEFT]
                y = stats[i, cv2.CC_STAT_TOP] + self.current_roi_y  # åŠ ä¸Š ROI åç§»
                w = stats[i, cv2.CC_STAT_WIDTH]
                h = stats[i, cv2.CC_STAT_HEIGHT]

                cx = int(centroids[i][0])
                cy = int(centroids[i][1]) + self.current_roi_y  # åŠ ä¸Š ROI åç§»

                # å½¢ç‹€é©—è­‰
                if not self._validate_shape(w, h, area):
                    filter_stats['shape_filtered'] += 1
                    continue

                filter_stats['passed'] += 1
                detected_objects.append({
                    'x': x,
                    'y': y,
                    'w': w,
                    'h': h,
                    'cx': cx,
                    'cy': cy,
                    'area': area
                })

            # ğŸ” è¼¸å‡ºéæ¿¾çµ±è¨ˆ
            if self.total_processed_frames % 500 == 0:
                logger.info(f"ğŸ“Š [ç‰©ä»¶éæ¿¾] å¹€{self.total_processed_frames}: "
                          f"ç¸½çµ„ä»¶={filter_stats['total']}, "
                          f"é¢ç©éæ¿¾={filter_stats['area_filtered']}, "
                          f"å½¢ç‹€éæ¿¾={filter_stats['shape_filtered']}, "
                          f"âœ…é€šé={filter_stats['passed']}")

            return detected_objects

        except Exception as e:
            logger.error(f"æª¢æ¸¬ç‰©ä»¶éŒ¯èª¤: {str(e)}")
            return []

    def _validate_shape(self, width: int, height: int, area: float) -> bool:
        """é©—è­‰å½¢ç‹€åƒæ•¸"""
        if width <= 0 or height <= 0:
            return False

        # é•·å¯¬æ¯”
        aspect_ratio = width / height if height > width else height / width
        if aspect_ratio < self.min_aspect_ratio or aspect_ratio > self.max_aspect_ratio:
            return False

        # å¡«å……åº¦
        extent = area / (width * height)
        if extent < self.min_extent:
            return False

        return True

    def _virtual_gate_counting(self, detected_objects: List[Dict]):
        """
        ğŸ¯ è™›æ“¬å…‰æŸµè¨ˆæ•¸æ³• - å·¥æ¥­ç´šé«˜é€Ÿè¨ˆæ•¸æ–¹æ¡ˆ

        åŸç†ï¼š
        - åœ¨ ROI ä¸­è¨­ç½®ä¸€æ¢è™›æ“¬å…‰æŸµç·šï¼ˆY è»¸æŸä¸€é«˜åº¦ï¼‰
        - æª¢æ¸¬ç‰©ä»¶ä¸­å¿ƒé»ç©¿è¶Šå…‰æŸµç·šæ™‚è§¸ç™¼è¨ˆæ•¸
        - ä½¿ç”¨æ™‚ç©ºå»é‡æ©Ÿåˆ¶é˜²æ­¢é‡è¤‡è¨ˆæ•¸

        å„ªé»ï¼š
        - ç¢ºå®šæ€§æ¥µå¼·ï¼šæ¯å€‹ç‰©é«”åªè§¸ç™¼ä¸€æ¬¡
        - è¨ˆç®—è¤‡é›œåº¦ O(n)ï¼šn = ç•¶å‰æª¢æ¸¬æ•¸
        - ç„¡éœ€è¿½è¹¤ IDï¼šå®Œå…¨ç„¡ç‹€æ…‹
        - é©åˆé«˜é€Ÿå ´æ™¯ï¼š280 FPS ç„¡å£“åŠ›
        """
        try:
            self.current_frame_count += 1

            # è¨ˆç®—å…‰æŸµç·šä½ç½®ï¼ˆROI å€åŸŸå…§çš„ç›¸å°ä½ç½®ï¼‰
            if self.roi_enabled:
                self.gate_line_y = self.current_roi_y + int(self.roi_height * self.gate_line_position_ratio)
            else:
                self.gate_line_y = int(self.frame_height * 0.5)

            # æ¸…ç†éæœŸçš„è§¸ç™¼è¨˜éŒ„
            expired_positions = []
            for pos, frame_num in self.triggered_positions.items():
                if self.current_frame_count - frame_num > self.gate_history_frames:
                    expired_positions.append(pos)

            for pos in expired_positions:
                del self.triggered_positions[pos]

            # éæ­·ç•¶å‰å¹€çš„æ‰€æœ‰æª¢æ¸¬ç‰©ä»¶
            for obj in detected_objects:
                cx, cy = obj['cx'], obj['cy']

                # æª¢æŸ¥ç‰©ä»¶ä¸­å¿ƒæ˜¯å¦ç©¿è¶Šå…‰æŸµç·šï¼ˆå¿…é ˆåœ¨å…‰æŸµç·šä¸‹æ–¹ï¼‰
                if cy >= self.gate_line_y:
                    # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡è§¸ç™¼
                    is_duplicate = self._check_gate_trigger_duplicate(cx, cy)

                    if not is_duplicate:
                        # æ–°ç‰©ä»¶ç©¿è¶Šå…‰æŸµç·šï¼Œè§¸ç™¼è¨ˆæ•¸
                        self.crossing_counter += 1
                        self.triggered_positions[(cx, cy)] = self.current_frame_count

                        logger.info(f"âœ… å…‰æŸµè¨ˆæ•¸ #{self.crossing_counter} - ä½ç½®:({cx},{cy}), å¹€:{self.current_frame_count}")

            # èª¿è©¦ä¿¡æ¯ï¼ˆæ¯ 100 å¹€è¼¸å‡ºä¸€æ¬¡ï¼‰
            if self.current_frame_count % 100 == 0:
                logger.debug(f"ğŸ¯ å…‰æŸµç‹€æ…‹ (ç¬¬{self.current_frame_count}å¹€): "
                           f"å…‰æŸµç·šY={self.gate_line_y}, "
                           f"è§¸ç™¼è¨˜éŒ„æ•¸={len(self.triggered_positions)}, "
                           f"ç¸½è¨ˆæ•¸={self.crossing_counter}")

        except Exception as e:
            logger.error(f"è™›æ“¬å…‰æŸµè¨ˆæ•¸éŒ¯èª¤: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

    def _check_gate_trigger_duplicate(self, cx: int, cy: int) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡è§¸ç™¼

        ä½¿ç”¨ç©ºé–“è·é›¢åˆ¤æ–·ï¼šå¦‚æœç•¶å‰ä½ç½®èˆ‡ä»»ä½•å·²è§¸ç™¼ä½ç½®çš„è·é›¢ < é–¾å€¼ï¼Œè¦–ç‚ºé‡è¤‡
        """
        for (tx, ty), frame_num in self.triggered_positions.items():
            distance = np.sqrt((cx - tx)**2 + (cy - ty)**2)

            if distance < self.gate_trigger_radius:
                # è·é›¢éè¿‘ï¼Œè¦–ç‚ºåŒä¸€ç‰©ä»¶çš„é‡è¤‡æª¢æ¸¬
                logger.debug(f"ğŸš« é‡è¤‡è§¸ç™¼: ç•¶å‰({cx},{cy}) èˆ‡ è§¸ç™¼({tx},{ty}) è·é›¢={distance:.1f}px < {self.gate_trigger_radius}px")
                return True

        return False

    def _draw_detection_results(self, frame: np.ndarray, objects: List[Dict]) -> np.ndarray:
        """ç¹ªè£½æª¢æ¸¬çµæœ"""
        try:
            # ç¹ªè£½ ROI å€åŸŸ
            if self.roi_enabled:
                cv2.rectangle(frame,
                            (0, self.current_roi_y),
                            (self.frame_width, self.current_roi_y + self.current_roi_height),
                            (255, 255, 0), 2)

            # ğŸ¯ ç¹ªè£½è™›æ“¬å…‰æŸµç·šï¼ˆå·¥æ¥­ç´šè¨ˆæ•¸ç·šï¼‰
            if self.enable_gate_counting and self.gate_line_y > 0:
                # ä¸»å…‰æŸµç·šï¼ˆç´…è‰²ï¼Œç²—ç·šï¼‰
                cv2.line(frame, (0, self.gate_line_y), (self.frame_width, self.gate_line_y),
                        (0, 0, 255), 3)

                # å…‰æŸµç·šæ¨™ç±¤
                cv2.putText(frame, f'GATE LINE (Y={self.gate_line_y})',
                          (10, self.gate_line_y - 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

            # ç¹ªè£½æª¢æ¸¬åˆ°çš„ç‰©ä»¶
            for obj in objects:
                x, y, w, h = obj['x'], obj['y'], obj['w'], obj['h']
                cx, cy = obj['cx'], obj['cy']
                area = obj['area']

                # åˆ¤æ–·ç‰©ä»¶æ˜¯å¦å·²ç©¿è¶Šå…‰æŸµç·šï¼ˆç”¨ä¸åŒé¡è‰²æ¨™ç¤ºï¼‰
                if cy >= self.gate_line_y:
                    box_color = (0, 255, 255)  # é»ƒè‰²ï¼šå·²ç©¿è¶Š
                else:
                    box_color = (0, 255, 0)    # ç¶ è‰²ï¼šæœªç©¿è¶Š

                # ç¹ªè£½é‚Šç•Œæ¡†
                cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 2)

                # ç¹ªè£½ä¸­å¿ƒé»
                cv2.circle(frame, (cx, cy), 3, (255, 0, 0), -1)

                # æ¨™è¨»é¢ç©
                cv2.putText(frame, f'{int(area)}',
                          (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
            info_text = f'Detections: {len(objects)} | Counted: {self.crossing_counter} | Gate: Y={self.gate_line_y}'
            cv2.putText(frame, info_text,
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            return frame

        except Exception as e:
            logger.error(f"ç¹ªè£½æª¢æ¸¬çµæœéŒ¯èª¤: {str(e)}")
            return frame

    def enable(self):
        """å•Ÿç”¨æª¢æ¸¬"""
        self.enabled = True
        self._reset_background_subtractor()
        logger.info("æª¢æ¸¬å·²å•Ÿç”¨")

    def disable(self):
        """ç¦ç”¨æª¢æ¸¬"""
        self.enabled = False
        logger.info("æª¢æ¸¬å·²ç¦ç”¨")

    def reset(self):
        """é‡ç½®æª¢æ¸¬ç‹€æ…‹"""
        self.crossing_counter = 0
        self.triggered_positions.clear()
        self.current_frame_count = 0
        self.total_processed_frames = 0
        self.gate_line_y = 0
        self._reset_background_subtractor()
        logger.info("ğŸ”„ æª¢æ¸¬ç‹€æ…‹å·²é‡ç½® - è™›æ“¬å…‰æŸµè¨ˆæ•¸å™¨å·²æ¸…é›¶")

    def get_count(self) -> int:
        """ç²å–è¨ˆæ•¸"""
        return self.crossing_counter

    def set_parameters(self, **kwargs):
        """è¨­ç½®æª¢æ¸¬åƒæ•¸"""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
                logger.info(f"åƒæ•¸æ›´æ–°: {key} = {value}")

        # å¦‚æœæ›´æ–°äº†èƒŒæ™¯åƒæ•¸ï¼Œé‡ç½®èƒŒæ™¯æ¸›é™¤å™¨
        bg_params = ['bg_history', 'bg_var_threshold', 'detect_shadows', 'bg_learning_rate']
        if any(key in kwargs for key in bg_params):
            self._reset_background_subtractor()

    def set_roi_enabled(self, enabled: bool):
        """è¨­ç½® ROI å•Ÿç”¨ç‹€æ…‹"""
        self.roi_enabled = enabled
        logger.info(f"ROI æª¢æ¸¬: {'å•Ÿç”¨' if enabled else 'ç¦ç”¨'}")

    def set_ultra_high_speed_mode(self, enabled: bool, target_fps: int = 280):
        """è¨­ç½®è¶…é«˜é€Ÿæ¨¡å¼"""
        self.ultra_high_speed_mode = enabled
        self.target_fps = target_fps
        self._reset_background_subtractor()
        logger.info(f"è¶…é«˜é€Ÿæ¨¡å¼: {'å•Ÿç”¨' if enabled else 'ç¦ç”¨'} (ç›®æ¨™ {target_fps} fps)")
